[
  {
    "url": "https://segment.com/docs/",
    "title": " Segment Documentation | Segment Documentation",
    "content": "Segment Documentation Learn how to use Segment to collect, responsibly manage, and integrate your customer data with hundreds of tools. Getting started with Segment Learn about Segment, plan and work through a basic implementation, and explore features and extensions. How can Segment help you? Simplify data collection Integrate the tools you need for analytics, growth, marketing, and more. Protect data integrity Prevent data quality issues with a tracking schema and enforcement with Protocols. Personalize experiences Build audiences and journeys from real-time customer data to personalize experiences on every channel. Respect users' privacy Keep customer data private with Segment's data discovery and policy enforcement tools. Get Data into Segment The Segment Spec helps you identify, capture, and format meaningful data for use with Segment libraries and APIs as well as downstream tools. Segment calls Use Track, Page, Identify, and other Segment tracking calls. Common traits Save time by letting Segment calls collect information for you. Use case specs Use our business-case specs to ensure that your tools get the most from your data. Learning about Segment Segment for Developers The basics of your Segment implementation. How-To Guides Over a dozen how-to guides that help you accomplish common tasks. Connect your app to Segment JavaScript Swift All other Sources Additional Resources Totally new to Analytics? Segment's Analytics Academy walks you through the wide world of analytics, including best practices, an overview of the most popular tools, and case studies of how other developers have achieved success. Want more hands-on guidance? For a more hands-on tutorial of Segment, check out Segment University. It offers step-by-step instructions, starting with first steps and going through some of our more advanced features. Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account",
    "headings": [
      {
        "level": 1,
        "text": "Segment Documentation"
      },
      {
        "level": 2,
        "text": "How can Segment help you?"
      },
      {
        "level": 2,
        "text": "Get Data into Segment"
      },
      {
        "level": 2,
        "text": "Learning about Segment"
      },
      {
        "level": 2,
        "text": "Connect your app to Segment"
      },
      {
        "level": 2,
        "text": "Additional Resources"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/intro-user/",
    "title": " Segment for Data Users | Segment Documentation",
    "content": "Home / Guides / Segment for Data Users Segment for Data Users On this page What is Segment? Environments and Labels Data inside Segment Set up a Destination Troubleshooting If you aren’t involved in setting up your Segment implementation, or are just starting to set up Destinations for your organization’s workspace, this guide is for you. What is Segment? If you read the detailed explanation of Segment on the previous page, you can skip ahead! Segment is a system for sending messages from your websites, mobile apps, and servers. These messages contain data about events on, or users of those systems, and these messages can sent on to other tools, and gathered together in a warehouse for later analysis. Segment can also bring in information about your users from external systems, such as helpdesks or CRM systems, and collate that information to help you analyze your data, build audiences of users, and personalize your users’ experiences. Once you (or your organizations’ developers) have your Segment Sources set up and sending data, you can log in to the Segment App and set up Destinations, which are how Segment sends that data to other tools (like Google Analytics, Mixpanel, and many others). Environments and Labels Depending on your organization’s configuration and access settings, you might be able to see one or multiple Environments (for example, “Production”, “Testing”, “Development”), or one or multiple Labels , which control access to different parts of your organization’s Segment system.  If you see several environments, contact your Segment administrator for more details so you can make sure you make your changes in the right place. Data inside Segment Data enters the Segment systems from Sources, but once data is in the system, your organization may have different tools configured to control and change it. This could change what data is available to you, or any destinations you set up. For example, Protocols makes sure that data coming into Segment follows specific formats and patterns, and might block and discard malformed or unwanted data. The Privacy tool can be configured to remove Personally Identifiable Information (PII) from the data. And several different methods are available to filter data so that it doesn’t send certain types of events, or reach specific destinations or warehouses. Set up a Destination Depending on the access level you have in your organization’s Segment workspace, you might be able to create new Destinations, or you might only be able to edit existing ones. To add a new Destination, you’ll usually need some information (such as a token or API key) from the destination tool to start. You’ll enter that into the Segment App so we can connect to and send data to that tool. You’ll also need to know which Source you’ll be sending data from. To set up a destination: Log in to the Segment App, and click Add Destination to go to the catalog of available destinations. Search for and select the destination you want to set up. On the description page that appears, click Configure . On the next page, select the source that you want the destination to get data from.\nYou can only select one source at at time. The list displays only the sources that are compatible with the destination you chose. If you don’t see a source that you expect, contact your administrator. Click Confirm Source . On the next page, configure your destination by entering the API key, token, and any other information.\nThe configuration page shows both required information, and any extra settings. Tip : Segment usually is able to translate data into a format that the destination expects, however some destinations (such as Adobe Analytics) may require manual mapping steps to configure properly. If you see additional fields for mapping configuration, read the documentation for that destination to learn more. Troubleshooting If you’re setting up a destination to use cloud-mode data (data that’s sent through Segment, rather than directly from a user’s device), you can use the Event Tester and Event Delivery tools to check that data is arriving, and being correctly delivered to the destination. Have suggestions for things to add to this guide? Drop us a line ! This page was last modified: 14 Jul 2021 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page What is Segment? Environments and Labels Data inside Segment Set up a Destination Troubleshooting Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Segment for Data Users"
      },
      {
        "level": 2,
        "text": "What is Segment?"
      },
      {
        "level": 2,
        "text": "Environments and Labels"
      },
      {
        "level": 2,
        "text": "Data inside Segment"
      },
      {
        "level": 2,
        "text": "Set up a Destination"
      },
      {
        "level": 2,
        "text": "Troubleshooting"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/privacy/consent-management/consent-in-unify/",
    "title": " Consent in Unify | Segment Documentation",
    "content": "Home / Privacy / Consent management / Consent in Unify Consent in Unify Free x Team x Business ✓ Addon x ? Consent Management is available to customers on Business tier plans. See the available plans , or contact Support . On this page Segment Consent Preference Updated event Consent in Unify and Twilio Engage is currently unavailable. However, Segment’s OneTrust consent wrappers automatically generate the Segment Consent Preference Updated Track event, which will be required for future integrations with Unify and Twilio Engage. Segment uses Profiles in Unify as the source of truth of an end user’s consent preference when enforcing consent in Twilio Engage. To get consent preference on the Profile, Segment requires the use of the Segment Consent Preference Updated event and Identify events to route events to Unify. The Segment Consent Preference Updated and Identify events should include the consent object . Segment Consent Preference Updated event Every time an end user provides or updates their consent preferences, Segment requires you to generate a Segment Consent Preference Updated event. If you are using Segment’s OneTrust consent wrappers , Segment automatically generates a Segment Consent Preference Updated event. This event is required to add the end user’s consent preference on their Profile in Unify. For example, if an end user agreed to share their information for functional and advertising purposes but not for analytics or data sharing, the Segment Consent Preference Updated Track call demonstrating their new consent preferences would have the following format: { \"anonymousId\" : \"23adfd82-aa0f-45a7-a756-24f2a7a4c895\" , \"type\" : \"track\" , \"event\" : \"Segment Consent Preference Updated\" , \"userId\" : \"u123\" , \"traits\" : { \"email\" : \"peter@example.com\" , \"phone\" : \"555-555-5555\" , } \"timestamp\" : \"2023-01-01T00:00:00.000Z\" , \"context\" : { \"consent\" : { \"categoryPreferences\" : { \"Advertising\" : true , \"Analytics\" : false , \"Functional\" : true , \"DataSharing\" : false } } } } If you use Protocols, the Segment app automatically adds the Segment Consent Preference Updated event to all your existing Tracking Plans and for every new Tracking Plan. Segment recommends you don’t edit or delete the default fields in the Segment Consent Preference Updated events, but you can add new fields as needed. Segment Consent Preference Updated is a reserved event name Segment has standardized a series of reserved event names that have special semantic meaning and maps these events to tools that support them. See the Semantic Events docs for more details. Sharing consent with Actions destinations In addition to enforcing consent in Connections, you may want these preferences to flow to each destination so your destinations can be aware when an end-user revokes their consent. You can use the Destination Actions framework to edit the destination’s mapping and copy the consent preferences from the Segment Consent Preference Updated event to a destination-specified consent field. If you use Destination Actions to send consent information to your destinations, the Segment Consent Preference Updated event should only include information about a user’s consent preferences because this event is sent regardless of an end-user’s consent preferences. Sharing consent with Classic Destinations is not available Segment only supports sharing consent with Actions Destinations. This page was last modified: 07 May 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Segment Consent Preference Updated event Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Consent in Unify"
      },
      {
        "level": 2,
        "text": "Segment Consent Preference Updated event"
      },
      {
        "level": 3,
        "text": "Sharing consent with Actions destinations"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/sources/",
    "title": " Sources Overview | Segment Documentation",
    "content": "Home / Connections / Sources Overview Sources Overview On this page What is a source? Types of sources Event streams sources Cloud app sources Reverse ETL sources Create a source Library tiers Related content Sources Catalog What is a source? A source is a website, server library, mobile SDK, or cloud application which can send data into Segment. It’s where your data originates. Add a source to collect data to understand who your customers are and how they’re using your product. Create a source for each website or app you want to track. While it’s not required that you have a single source for each server, site, or app, you should create a source for each unique source of data. Each source you create has a write key, which is used to send data to that source. For example, to load analytics.js , the Segment JavaScript library on your page, the snippet on the Quickstart Guide includes: analytics . identify ( ' user_123 ' , { email : ' jane.kim@example.com ' , name : ' Jane Kim ' }); If you don't see the source you're looking for in our catalog If a tool is not listed as a supported source in Segment’s catalog , then it is not possible to incorporate the integration out-of-the-box within a Segment workspace. However, as an alternative, you can use the HTTP API source to collect data from the tool’s API. You can also use Functions to send or receive data from other tools. Types of sources Segment has three types of sources: Event streams Cloud app sources Reverse ETL Event streams sources Event streams sources collect data from your website or app to monitor user actions. These sources include website libraries , mobile , and server sources . Source Overview The Source Overview page for an event stream source shows you a pipeline view of all events Segment receives from your source, events that failed on ingest, events that are filtered at the source level, and “eligible events”, which are the events that will flow into your destinations. If you select one of the steps in the pipeline view, you can see a line chart that reflects the fluctuations in volume alongside a breakdown table that has more details about the events impacted by the selected step. Pipeline view The pipeline view shows each of the four steps Segment encounters when processing data from your source: Events successfully received : All events that Segment received from your source. Failed on ingest : Events that failed at the Tracking API level. For more information about errors that might cause events to fail on ingest, see Delivery Overview’s Troubleshooting documentation. Filtered at source : Events that were filtered out by source schema controls, Tracking Plans, or a common JSON schema. Eligible events : Eligible events are the events that flow downstream to your Segment destinations. This value is read-only, but you can see the events that flow downstream to a particular destination using Delivery Overview . You can use the time picker located on the Source Overview page to specify a time period (last 10 minutes, 1 hour, 24 hours, 7 days, 2 weeks, or a custom date range over the last two weeks) for which you’d like to see data. Segment sets the time picker to show data for the last 24 hours by default. Breakdown table The breakdown table displays three tabs, Event type , Event name , and App version . Event type : The Segment Spec event type (Track call vs. Identify call, for example). This tab also contains a “% change” metric, which displays how the event counts differ from the last comparable time range, represented as a percentage. Event name : The event name, provided by you or the source. App version : The app/release version, provided by you or the source. Each of these tabs displays an event count, which is the total number of events that Segment received in a particular step. The Unnamed or batched events under the Event Name tab is a collection of all identify and page/screen calls in the source. Website libraries Analytics.js , the JavaScript library, is the most powerful way to track customer data from your website. If you’re just starting out, Segment recommends it over server-side libraries as the simplest installation for any website. The Analytics Quickstart Guide Analytics and data collection is a very broad topic and it can be quite overwhelming. How do you get started? Mobile Segment’s Mobile SDKs are the best way to simplify your iOS, Android, and Xamarin app tracking. Try them over server-side sources as the default installation for any mobile app. AMP Android Android Wear iOS Kotlin React Native Swift Xamarin Analytics-Flutter library The Analytics-Flutter library is currently only available in pilot phase and is governed by Segment’s First Access and Beta Preview Terms . If you’d like to try out this library, access the Analytics-Flutter GitHub repository . Server Segment’s server-side sources let you send analytics data directly from your servers. Segment recommends tracking from your servers when device-mode tracking (tracking on the client) doesn’t work. Check out the guide on server-side tracking if you’re not sure whether it makes sense for your use case. Clojure Go Java Node.js PHP Python Ruby .NET Cloud-mode tracking Server-side data management is when tag sends data to the Segment servers, which then passes that data to the destination system. Cloud app sources Cloud app sources empower you to pull together data from all of your different third-party tools into a Segment warehouse or to your other enabled integrated tools. They send data about your users from your connected web apps. There are two types of Cloud Apps: Object cloud sources and Event cloud sources . Comparing Cloud Sources Wondering which cloud-apps send which types of data? Check out the Cloud Sources comparison. Object Cloud Sources These Cloud App Sources can export data from its third party tool and import it directly into your Segment warehouse. Make sure you have a Segment warehouse enabled before you enable any of the following sources: Facebook Ads Google Ads HubSpot Intercom Mailchimp Mandrill Marketo Salesforce Salesforce Marketing Cloud SendGrid Stripe Twilio Zendesk Event Cloud Sources These Cloud App Sources can not only export data into your Segment warehouse, but they can also federate the exported data into your other enabled Segment integrations: ActiveCampaign Aircall Airship Alloy Flow Amazon S3 Amplitude Cohorts Antavo Authvia AutopilotHQ Beamer Blip Bluedot Blueshift Braze Candu Chatlio CleverTap CommandBar ConfigCat Customer.io Delighted Drip Elastic Path Elastic Path CX Studio Facebook Lead Ads Factual Engine Foursquare Movement Freshchat Friendbuy Gladly GWEN Webhooks Herow IBM Watson Assistant Inflection Insider Iterable Jebbit Klaviyo Klenty LaunchDarkly Leanplum Listrak LiveLike (Source) Looker Mailjet Mailmodo Mixpanel Cohorts MoEngage (Source) Moesif API Analytics Navattic Nudgespot One Creation OneSignal OneTrust Paytronix Pendo ProveSource Pushwoosh Source Qualtrics Quin AI Radar Refiner Selligent Marketing Cloud SendGrid Marketing Campaigns Shopify (by Littledata) Shopify - Powered by Fueled Statsig Synap Upollo UserGuiding Vero Voucherify White Label Loyalty WorkRamp Yotpo HTTP If Segment doesn’t have a library for your environment, you can send your data directly to the HTTP Tracking API . All of Segment’s other sources and platforms use the HTTP API to work their magic behind the scenes. Pixel Segment’s Pixel Tracking API lets you track events from environments where you can’t execute code, like tracking email opens. Event name Description Email Delivered The message has been successfully delivered to the receiving server. Email Opened The recipient has opened the HTML message. You need to enable Open Tracking for getting this type of event. Email Link Clicked The recipient clicked on a link within the message. You need to enable Click Tracking for getting this type of event. Email Bounced The receiving server could not or would not accept message. Email Marked as Spam The recipient marked message as spam. Unsubscribe The recipient clicked on message’s subscription management link. Reverse ETL sources Reverse ETL sources are data warehouses that enable you to use Reverse ETL to send data from your warehouse source to your destinations. Reverse ETL supports these sources: BigQuery Databricks Postgres Redshift Snowflake Segment is actively working on adding more sources. If you’d like to request Segment to add a particular source, please note it on the feedback form . Create a source To create a source: Navigate to Connections and click Add Source . Click the Source you’d like to add. Note: More than 80% of workspaces start by adding their JavaScript website. Click Add Source . Enter a name for your source as well as any information on the setup page. Click Add Source . Once you’ve created a source, the source is automatically enabled and can immediately receive events. You can review your new events in that source’s Debugger tab. Sources not connected to an enabled destination are disabled after 14 days If your source is not connected to any destinations or is only connected to disabled destinations, Segment automatically disables this source after 14 days, even if the source is receiving events. Disabled sources will no longer receive data. \nYou can view when Segment disables your destination in your workspace’s Audit Trail as Event : Source Disabled with Actor : Segment .\nWorkspace members receive an email notification before Segment disables your source so that your team has time to take action.\nIf you would like to prevent this behavior in your workspace, fill out this Airtable form . One source or multiple sources? Segment suggests that you create one source for each type of data you want to collect. For example, you might have one source for all of your website tracking and a different source for any mobile tracking. Creating one source per data type provides the following benefits: Debugger ease of use - mixing libraries/sources on a single API key means you’re heavily reliant on filtering to actually test events Flexibility sending data to different projects - if you want to have different warehouse schemas, analytics projects, etc, having multiple sources would create this separation More control - as your account grows with the number of destinations you enable, having separate sources allows you to have more control A source type cannot be changed after it is created. You must create a new source if you would like to use a different source type. Library tiers Segment has defined three tiers for libraries: Flagship, Maintenance, and Community. These tiers indicate the level of support, enhancements, and maintenance each library receives from Segment. The criteria for assigning a library to a tier include its overall usage by customers and the availability of newer versions. Here’s how Segment defines each tier: Flagship libraries offer the most up-to-date functionality on Segment’s most popular platforms. Segment actively maintains Flagship libraries, which benefit from new feature releases and ongoing development and support. Maintenance libraries send data as intended but receive no new feature support and only critical maintenance updates from Segment. When possible, Segment recommends using a Flagship version of these libraries. Community libraries are neither managed nor updated by Segment. These libraries are available on GitHub under the MIT License for the open-source community to fork or contribute. If a library falls into one of these tiers, you’ll see the tier label at the beginning of the library’s page. This page was last modified: 18 Nov 2024 Further reading Sources Catalog A list of the available sources on the Segment platform. Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page What is a source? Types of sources Event streams sources Cloud app sources Reverse ETL sources Create a source Library tiers Related content Sources Catalog Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Sources Overview"
      },
      {
        "level": 2,
        "text": "What is a source?"
      },
      {
        "level": 2,
        "text": "Types of sources"
      },
      {
        "level": 2,
        "text": "Event streams sources"
      },
      {
        "level": 3,
        "text": "Source Overview"
      },
      {
        "level": 3,
        "text": "Website libraries"
      },
      {
        "level": 3,
        "text": "Mobile"
      },
      {
        "level": 3,
        "text": "Server"
      },
      {
        "level": 2,
        "text": "Cloud app sources"
      },
      {
        "level": 3,
        "text": "Object Cloud Sources"
      },
      {
        "level": 3,
        "text": "Event Cloud Sources"
      },
      {
        "level": 3,
        "text": "HTTP"
      },
      {
        "level": 3,
        "text": "Pixel"
      },
      {
        "level": 2,
        "text": "Reverse ETL sources"
      },
      {
        "level": 2,
        "text": "Create a source"
      },
      {
        "level": 2,
        "text": "Library tiers"
      },
      {
        "level": 2,
        "text": "Further reading"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/",
    "title": " Engage Introduction | Segment Documentation",
    "content": "Home / Engage Introduction Engage Introduction Free x Team x Business ✓ + Engage Foundations ✓ ? Engage Foundations requires a Business tier account and includes Unify. See the available plans , or contact Support . On this page What can you do with Engage? Market to customers with Engage Premier and Channels Powered by real-time data, Twilio Engage is a customizable personalization platform with which you can build, enrich, and activate Audiences. Engage Channels builds on top of these Audiences, helping you connect with and market to your customers through email, SMS, and WhatsApp campaigns. What can you do with Engage? Create unified customer profiles Engage uses Segment Identity Resolution to take event data from across devices and channels and intelligently merge it into complete user- or account-level profiles. This gives your organization a single view of your customer base. To learn more, read the Identity Resolution documentation . Personalizing customer interactions Support teams rely on Segment's unified profiles to make real-time and informed decisions about customers when answering tickets or taking support calls. Read about how the support team at Frame.io reduced ticket response time by 80%. Enrich profiles with new traits Add detail to user profiles with new traits and use them to power personalized marketing campaigns. You can add new traits to your user or account profiles in Engage using: Computed Traits: Use the Engage drag-and-drop interface to build per-user (B2C) or per-account (B2B) metrics on user profiles (for example, “lifetime value” or “lead score”). SQL Traits: Run custom queries on your data warehouse using the Engage SQL editor, and import the results into Segment. With SQL Traits, you can pull rich, uncaptured user data back into Segment. Predictions : Predict the likelihood that users will perform custom events tracked in Segment, like LTV, churn, and purchase. Build Audiences Create lists of users or accounts that match specific criteria. For example, after creating an inactive accounts audience that lists paid accounts with no logins in 60 days, you can push the audience to your analytics tools or send an SMS, email, or WhatsApp campaign with Engage Channels. Learn more about Engage audiences . Sync audiences to downstream tools Once you create your Computed Traits and Audiences, Engage sends them to your Segment Destinations in just a few clicks. You can use these Traits and Audiences to personalize messages across channels, optimize ad spend, and improve targeting. You can also use the Profile API to build in-app and onsite personalization. Learn more about using Engage data and the Profile API . Personalizing marketing campaigns Marketing teams use Engage to run real-time multi-channel marketing campaigns based off specific user attributes they've computed in Engage. Read about how Drift used Engage to increase prospect engagement by 150% in two months. Market to customers with Engage Premier and Channels To send email, SMS, and WhatsApp campaigns with Engage Channels, you’ll connect a Twilio messaging service , SendGrid subuser account , and WhatsApp messaging service to your Segment Engage space. Use existing accounts, or create new ones. View the onboarding steps for more on how to connect Twilio and SendGrid accounts. Send email, SMS, and WhatsApp messages in Journeys Use Engage to build email, SMS, and WhatsApp campaigns within Journeys . Send campaigns to subscribed users based on event behavior and profile traits. With message analytics , you can track the performance of your campaigns. Send Email : Build email campaigns with existing templates, or create a new email template within Journeys. Before you send the email, test the template and set conversion goals . Send SMS messages : Build SMS campaigns to message users in real-time as a step in a Journey. For example, create an abandoned cart campaign that texts users a reminder to complete their purchase, along with a promo code. Add merge tags and set conversion goals. Send WhatsApp messages : Build WhatsApp campaigns that deliver messages to your customers on the world’s most used messaging app. To learn more, visit the CSV Uploader documentation. Build Email, SMS, and WhatsApp message templates Build personalized email , SMS , and WhatsApp templates in Twilio Engage for use in your campaigns. Design email templates with a WYSIWYG Drag and Drop Editor or the HTML Editor . Engage saves the templates for you to preview, edit, and reuse throughout Journeys. Personalize with merge tags Insert real-time user profile traits from merge tags to personalize each message. For example, address recipients by name or highlight new products from a user’s favorite brand. CSV Uploader Use the CSV uploader to add or update user profiles and subscription states . To learn more, visit the CSV Uploader documentation. User subscriptions Set user subscription states in two ways: Upload a CSV file with lists of users along with their phone, email, and WhatsApp subscription states. Programmatically with Segment’s Public API Use Engage to add subscription states to user email addresses and phone numbers. Subscription states help determine which users you can send campaigns to in Engage. You can set user subscription states with a CSV file upload , or programmatically with Segment’s Public API . Message Analytics With analytics in Engage, you can monitor real-time conversion data. Track message performance and customer interaction beyond clicks and opens. Use campaign dashboards to view events such as Email Delivered , Unsubscribed , Spam Reported , and more. Conversion Goals For each message step in a Journey, you can set conversion conditions with events and properties in your Segment space. Then, define a duration after message delivery to track goals. For example, track users who perform the event Order Completed with a promo code that you send them. Visit Message Analytics to learn more. This page was last modified: 23 Aug 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page What can you do with Engage? Market to customers with Engage Premier and Channels Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Engage Introduction"
      },
      {
        "level": 2,
        "text": "What can you do with Engage?"
      },
      {
        "level": 2,
        "text": "Market to customers with Engage Premier and Channels"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/sources/schema/destination-data-control/",
    "title": " Using Schema Controls | Segment Documentation",
    "content": "Home / Connections / Sources / Schema / Using Schema Controls Using Schema Controls On this page Filter specific events from being sent to specific destinations Block or disable specific events and properties from being sent to all destinations Add a new event using the New Event button Export your Source Schema Once you have enabled destinations for a given source, all of the data you track will be routed to your connected tools and warehouses. If you no longer wish to send all data to a particular destination, you can disable the destination from the Source overview page. Segment gives you the power to control exactly what data is allowed into your destinations, so you can protect the integrity of your data, and the decisions you make with it. You can send all of your data to a warehouse and only two specific events to an analytics tool. You can also block rogue events from all of your warehouses and end tools. Filter specific events from being sent to specific destinations An integrations object may be passed in the options of group , identify , page and track methods, allowing selective destination filtering. By default all destinations are enabled. All customers can filter specific events from being sent to specific destinations (except for warehouses) by updating their tracking code. Here is an example showing how to send a single message only to Intercom and Google Analytics: analytics . identify ( ' user_123 ' , { email : ' jane.kim@example.com ' , name : ' Jane Kim ' }, { integrations : { ' All ' : true , ' Intercom ' : true , ' Google Analytics ' : true , ' Mixpanel ' : false } }); Destination flags are case sensitive and match the Destination’s name in the docs (for example, “AdLearn Open Platform”, “awe.sm”, “MailChimp”, etc.). If you’re on Segment’s Business plan, you can filter track calls right from the Segment UI on your Source Schema page by clicking on the field in the Integrations column and then adjusting the toggle for each tool. Segment recommends using the UI if possible since it’s a much simpler way of managing your filters and can be updated with no code changes on your side. Block or disable specific events and properties from being sent to all destinations If you no longer want to track an event, you can either remove it from your code or, if you’re on the Business plan, you can block track calls right from the Segment UI on your Source Schema page by adjusting the toggle for each event. Once you block an event in Segment, Segment stops forwarding it to all of your destinations, including your warehouses. You can remove it from your code at your leisure. In addition to blocking track calls, Business plan customers can block all Page and Screen calls, as well as Identify traits and Group properties. Add a new event using the New Event button The New Event button in your source schema adds the event to the source schema only. It does not add any events to your tracking code. If you want to track an event, you still need to manually add it to your source code. A use case for this feature might be to enable schema filtering for a new event before it arrives in the source to prevent it from reaching specific downstream destinations. Export your Source Schema Segment allows users with Source Read-only permissions to download Source Schemas as a CSV file, maximizing portability and access to event data. You can download a copy of your schema by visiting the Source Schema page. You can export Track, Identify, and Group Source Schemas. Download a CSV You can only download one Source Schema CSV schema type (Track, Identify, or Group) per source at the same time. To download a Source Schema CSV file: Sign in to Segment and select a source. Click the Schema tab in the source header. On the Source Schema page, select a schema type (Track, Identify, or Group) and a timeframe (7 days or 30 days). Click the Download CSV button. A toast pops up on the top of the page, with the message “Your file is processing. When your file is ready it will be available to download from the Download History page.” Open the Download History page by clicking the link in the toast or following the instructions in the view download history section. Once the file status column indicates that the download was successful, click the Download CSV link to download your CSV to your computer. If the file status column shows that the download has failed, return to the Source Schema page and try the download again. The Source Schema CSV name has the following format: workspaceSlug-sourceSlug-schemaType--yyyy-mm-dd--hh-mm-utc All events and properties are now included in the CSV file When you export a Source Schema, all events and properties are included in the CSV file regardless of the filters or search parameters currently applied to the Source Schema view. View download history You can view the Source Schema exports from the last 14 days on the Download History page. To access the Download History page: Sign in to Segment and select a source. Click the Schema tab in the source header. Click the View Download History link. Track event CSV format The Track event CSV file contains the following columns: Event Name Last Seen At (UTC) If greater than your selected timeframe (7 days or 30 days) the value is “more than 7 days ago” or “more than 30 days ago” Property Name Allowed Blocked Total Planned (available for Protocols customers with a connected Tracking Plan) Values are “planned” or “unplanned” Labels in your exported CSV If you use labels , they appear as columns in your CSV. The column headers are keys, and the column data contains values. Identity and Group event CSV format The Identify and Group CSV files contain the following columns: Trait Name Last Seen At (UTC) If greater than your selected timeframe (7 days or 30 days) the value is “more than 7 days ago” or “more than 30 days ago” Allowed Blocked Total Planned (available for Protocols customers with a connected Tracking Plan) Values are “planned” or “unplanned” The exported schema doesn’t include actual values (for example, personal data) for the events, properties, and traits you are tracking for a specific source. See the Segment Schema Limits for more information on how to manage the Source Schema. This page was last modified: 22 Jun 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Filter specific events from being sent to specific destinations Block or disable specific events and properties from being sent to all destinations Add a new event using the New Event button Export your Source Schema Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Using Schema Controls"
      },
      {
        "level": 2,
        "text": "Filter specific events from being sent to specific destinations"
      },
      {
        "level": 2,
        "text": "Block or disable specific events and properties from being sent to all destinations"
      },
      {
        "level": 2,
        "text": "Add a new event using theNew Eventbutton"
      },
      {
        "level": 2,
        "text": "Export your Source Schema"
      },
      {
        "level": 3,
        "text": "Download a CSV"
      },
      {
        "level": 3,
        "text": "View download history"
      },
      {
        "level": 3,
        "text": "Track event CSV format"
      },
      {
        "level": 3,
        "text": "Identity and Group event CSV format"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/trait-activation/",
    "title": " Trait Activation Overview | Segment Documentation",
    "content": "Home / Engage / Trait Activation Overview Trait Activation Overview Free x Team x Business ✓ + Engage Foundations ✓ ? Engage Foundations requires a Business tier account and includes Unify. See the available plans , or contact Support . On this page Trait Activation setup Use cases Next steps Use Trait Activation to configure sync payloads that you send from Engage Audiences and Journeys to a Destination or Destination Function. Map traits from user profiles to Destinations, configure identifiers to sync, and choose a sync strategy that fits your use cases. Trait Activation includes both Trait Enrichment and ID Sync . With Trait Enrichment, use custom, SQL, computed, and predictive traits to enrich the data you map to your destinations or destination functions. Use ID Sync to select identifiers and a sync strategy for each identifier when syncing Engage Audiences to Destinations. Trait Activation setup To get started with Trait Activation, you’ll need to set up the destination that you’ll use with Trait Enrichment and ID Sync . Set up your destination Select your destination, view its Segment documentation, then follow the corresponding required setup steps. Destination Type Compatible with Trait Enrichment Compatible with ID Sync Facebook Custom Audiences List Google Ads Remarketing Lists List Destination Actions Actions Destination Functions Function Classic Destinations Classic Resyncs Segment recommends creating a new audience for Trait Enrichment and ID Sync. For existing audience destinations, both Trait Enrichment and ID Sync won’t resync the entire audience. Only new data flowing into Segment will adhere to new trait settings. Contact Segment support if you’d like your Audience resynced with Trait Enrichment and ID Sync. For Audiences larger than 50 million users, it may take several hours, or even days, to sync. Only one resync is allowed at a time for each workspace. Use cases Trait Enrichment and ID Sync can help you: Increase advertising match rates : Expand the pool of users you advertise to and increase match rates by using traits and identifiers to find the right customers. Include more personalized message content : Include traits in your payload for more up-to-date, accurate data. Configure how you send identifiers to Destinations : Send the right identifiers to your destinations. For profiles with multiple identifiers, choose a strategy to select identifiers and send them downstream. Next steps To learn more about Trait Activation, visit the following docs: Learn more about how to access Segment profile traits when you sync Audiences and Journeys to Destinations or Destination Functions with Trait Enrichment . Learn how to sync select identifiers and create a sync strategy with ID Sync . This page was last modified: 10 Sep 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Trait Activation setup Use cases Next steps Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Trait Activation Overview"
      },
      {
        "level": 2,
        "text": "Trait Activation setup"
      },
      {
        "level": 3,
        "text": "Set up your destination"
      },
      {
        "level": 3,
        "text": "Resyncs"
      },
      {
        "level": 2,
        "text": "Use cases"
      },
      {
        "level": 2,
        "text": "Next steps"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/find-writekey/",
    "title": " Locate your Write Key | Segment Documentation",
    "content": "Home / Connections / Locate your Write Key Locate your Write Key On this page Find the write key for a source Locate a source using your write key The write key is a unique identifier for each source. It lets Segment know which source is sending the data and which destinations should receive that data. Find the write key for a source To find a write key, you first need to create an event streams source like a website, server, or mobile source. ( Cloud-sources do not have write keys, as they use a token or key from your account with that service.) Then, in the Source, go to Settings and select API Keys . Now you can add the source’s write key to your app and begin sending data to Segment. Locate a source using your write key To find the source given a write key within your workspace, open your workspace and select the search icon. Enter your write key into the search bar. If the write key exists in the workspace and is connected to a source, the source shows up in the list of results. This method is only available to locate event streams sources This method cannot be used to find a destination or cloud event source. This page was last modified: 20 Nov 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Find the write key for a source Locate a source using your write key Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Locate your Write Key"
      },
      {
        "level": 2,
        "text": "Find the write key for a source"
      },
      {
        "level": 2,
        "text": "Locate a source using your write key"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/storage/warehouses/",
    "title": " Data Warehouses | Segment Documentation",
    "content": "Home / Connections / Storage / Data Warehouses Data Warehouses Free ✓ Team ✓ Business ✓ Add-on x ? Free and Team plan workspaces can have 1 warehouse. Business plans can have more than one, and include custom sync schedules and filtering. See the available plans , or contact Support . On this page What’s a Warehouse? FAQs What’s a Warehouse? A warehouse is a central repository of data collected from one or more sources. This is what commonly comes to mind when you think about a relational database: structured data that fits neatly into rows and columns. In Segment, a Warehouse is a special type of destination. Instead of streaming data to the destination all the time, we load data to them in bulk at regular intervals. When we load data, we insert and update events and objects, and automatically adjust their schema to fit the data you’ve sent to Segment. When selecting and building a data warehouse, consider three questions: What type of data will be collected? How many data sources will there be? How will the data be used? Relational databases are great when you know and predefine the information collected and how it will be linked. This is usually the type of database used in the world of user analytics. For instance, a users table might be populated with the columns name , email_address , or plan_name . Examples of data warehouses include Amazon Redshift, Google BigQuery, and Postgres. When Segment loads data into your warehouse, each sync goes through two steps: Ping: Segment servers connect to your warehouse. For Redshift warehouses, Segment also runs a query to determine how many slices a cluster has. Common reasons a sync might fail at this step include a blocked VPN or IP, a warehouse that isn’t set to be publicly accessible, or an issue with user permissions or credentials. Load: Segment de-duplicates the transformed data and loads it into your warehouse. If you have queries set up in your warehouse, they run after the data is loaded into your warehouse. Looking for the Warehouse Schemas docs? They’ve moved: Warehouse Schemas . Analytics Academy: When to use SQL for analysis When your existing analytics tools can't answer your questions, it's time to level-up and use SQL for analysis. More Help How do I send custom data to my warehouse? How do I give users permissions to my warehouse? Check out the Frequently Asked Questions about Warehouses page and a list of helpful SQL queries to get you started with Redshift . FAQs How do I decide between Redshift, Postgres, and BigQuery? What do you recommend for Postgres: Amazon or Heroku? How do I give users permissions? What are the limitations of Redshift clusters and warehouses connectors? Where do I find my source slug? Setting up a warehouse How do I create a user, grant usage on a schema and then grant the privileges that the user will need to interact with that schema? Which IPs should I allowlist? Will Segment sync my historical data? Can I load in my own data into my warehouse? Can I control what data is sent to my warehouse? Managing a warehouse How fresh is the data in my warehouse? Can I add, tweak, or delete some of the tables? Can I transform or clean up old data to new formats or specs? What are common errors and how do I debug them? How do I speed up my Redshift queries? Analyzing with SQL How do I forecast LTV with SQL and Excel for e-commerce businesses? How do I measure the ROI of my Marketing Campaigns? This page was last modified: 12 Aug 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page What’s a Warehouse? FAQs Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Data Warehouses"
      },
      {
        "level": 2,
        "text": "What’s a Warehouse?"
      },
      {
        "level": 3,
        "text": "More Help"
      },
      {
        "level": 2,
        "text": "FAQs"
      },
      {
        "level": 3,
        "text": "Setting up a warehouse"
      },
      {
        "level": 3,
        "text": "Managing a warehouse"
      },
      {
        "level": 3,
        "text": "Analyzing with SQL"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/help/",
    "title": " Segment Resources | Segment Documentation",
    "content": "Home / Segment Resources Segment Resources Technical Support Email support is available for all Segment support plans . If you’re experiencing problems, have questions about implementing Segment, or want to report a bug, you can fill out the support contact form and the Success Engineering team will get back to you. You need a Segment account to file a support request. If you don’t have one, sign up for a free workspace and then send your request. Segment Support Business Hours For more information about the  Segment Support Team’s hours and holidays see Twilio Support business hours . Segment University Segment University is Segment’s free, online classroom for learning the basics of Segment. Analytics Academy Analytics Academy is a series of lessons designed to help you understand the value of analytics as a discipline. Analytics Academy will help you think through your analytics needs so you can start creating robust and flexible analytics systems. Recipes Wondering what you can do with Segment? Check out Segment Recipes for inspiration on what you can achieve by connecting your Segment workspace to different Destinations, from tailored onboarding emails to joining and cleaning your data with third-party tools. Other Resources Head over to Segment Resources for Segment case studies, webinars, courses, and more. Status Page The Segment Status Page offers details about system metrics and reports on uptime for each part of the Segment product. You can subscribe to receive updates about ongoing incidents and view information about past incidents . This page was last modified: 28 Jun 2023 Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change",
    "headings": [
      {
        "level": 1,
        "text": "Segment Resources"
      },
      {
        "level": 2,
        "text": "Technical Support"
      },
      {
        "level": 3,
        "text": "Segment Support Business Hours"
      },
      {
        "level": 2,
        "text": "Segment University"
      },
      {
        "level": 2,
        "text": "Analytics Academy"
      },
      {
        "level": 2,
        "text": "Recipes"
      },
      {
        "level": 2,
        "text": "Other Resources"
      },
      {
        "level": 2,
        "text": "Status Page"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/data-export-options/",
    "title": " Data Export Options | Segment Documentation",
    "content": "Home / Connections / Data Export Options Data Export Options There are a few ways to export your Segment data. Segment Business customers have the most data flexibility, but our self-service customers also have options. Business plan customers Customers on our business plan can take advantage of Replay when they change vendors or add a vendor to their marketing and analytics stack. Replay When you want to trial or start using a new vendor, Segment can replay your timestamped, historical data so it’s like you’ve been using that app all along. Eliminate vendor lock-in Take your data to new tools Increase advantage in vendor negotiations Replay works for all server-side destinations that have or accept timestamps, including our Amazon S3 destination, so you can get all your data history since the first event you sent to Segment. Free, Team, and Business plan customers If you are on any of our plans, there are multiple options available to you to gain access to your raw data. Warehouses All customers can connect a data warehouse to Segment – Free and Team customers can connect one, while Business customers can connect as many as they need. We translate and load your raw data logs into your warehouse for more powerful analysis in SQL. S3 Logs We store all your API calls as line-separated JSON objects in Amazon S3. If you enable Amazon S3 in your destinations catalog, we will copy the same data to your own S3 bucket. The data copied will only include data sent to Segment after you turn on the destination. Read our Amazon S3 docs to learn more about how we structure that data. Webhooks You can use our webhooks destination to fire off requests in realtime to an endpoint that you would need to spin up and manage on your side. This is basically re-creating how our business system works but takes a bit of work on your side. If your event volume is high it can be difficult to keep a server up to receive those messages in realtime. Iron.io Another one of our destinations is Iron.io . They function similar to webhooks, but they will manage the message queue and allow you to run scripts on your data before routing it to another end point. Again this is similar to what Segment does for our business customers, but will require a decent amount of work from your team, however it will be much more reliable if your event volume gets high. 3rd Party Reporting APIs This option is the most restrictive but might be the easiest if you need only basic data to be exported. A few examples would be to use the reporting APIs Clicky or Google Analytics provide (after turning those tools on in Segment and sending them data). Those APIs aren’t super flexible and you won’t see all the data from Segment, but for basic metrics they should work. One tool that’s a bit more flexible when it comes to a reporting API is Keen.io , which is also available on the Segment platform. This page was last modified: 01 Dec 2022 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Data Export Options"
      },
      {
        "level": 3,
        "text": "Business plan customers"
      },
      {
        "level": 3,
        "text": "Free, Team, and Business plan customers"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/onboarding/",
    "title": " Twilio Engage Premier Onboarding Guide | Segment Documentation",
    "content": "Home / Engage / Twilio Engage Premier Onboarding Guide Twilio Engage Premier Onboarding Guide Free x Team x Business ✓ + Engage Premier ✓ ? Engage Premier requires a Business tier account and includes Engage Foundations and Unify. See the available plans , or contact Support . On this page Before you begin: overview and task checklist Stage 1: Configure Engage Identifiers in Unify Stage 2: Create and configure a SendGrid account Stage 3: Create and configure Twilio SMS services Stage 4: Create and configure Twilio WhatsApp services Regional Segment Next steps Engage Premier entered an End of Sale (EOS) period effective  June 10, 2024. Existing Segment customers will continue to have access and support to Engage Premier until an end-of-life (EOL) date is announced. We recommend exploring the following pages in preparation of a migration or future MCM needs: Twilio Marketing Campaigns Preferred ISV Partners: Airship Blog Bloomreach Blog Braze Blog Insider Blog Klaviyo Blog Twilio Engage Foundations Documentation Twilio Engage brings Segment, Twilio, SendGrid, and WhatsApp together to help you create and send email, SMS, and WhatsApp campaigns to your customers. Before sending your first Engage campaign, though, you’ll need to configure and connect accounts with all four platforms. This guide lists all required onboarding steps and walks you through Engage setup. By the end of the onboarding process, you’ll be ready to send your first campaign. The steps in this guide are only required if you plan to send email, SMS, and WhatsApp messages with Engage. Visit the Engage Foundations Onboarding Guide for general onboarding steps to set up your Engage space, connect sources, create audiences, and more. Regional Segment You can use Engage Premier on Segment’s regional infrastructure in the EU . Twilio Engage ensures data residency in the EU, but the channels you connect to, may not guarantee the same level of data residency. Check directly with the providers of the channels you use for information about data residency in their applications. Native channels like email and SMS, which use Twilio, are not data resident. Twilio is GDPR compliant, and has Binding Corporate Rules to ensure that data is protected when it’s transferred between countries. Before you begin: overview and task checklist You’ll set up Twilio Engage in four stages: Configure Engage identifiers in Unify. Create and configure a SendGrid account. Create and configure Twilio SMS services. Create and configure Twilio WhatsApp services. The following table shows a high-level checklist of tasks you’ll need to complete in each platform: Platform Tasks Segment 1. Verify Engage identifiers in your Segment workspace. 2. Add any missing identifiers. SendGrid 1. Create a SendGrid account. 2. Upgrade your account to a Pro plan. 3. Configure an IP. 4. Create a SendGrid subuser. 5. Authenticate your domain. 6. Enable subscription tracking. 7. Enable an event webhook. 8. Generate API credentials, then copy them into Engage settings. 9. Warm up your IP. 10. Contact SendGrid support. Twilio 1. Create a Twilio account. 2. Purchase phone number(s). 3. If necessary, register phone number(s). 4. Create a messaging service. 5. Generate an API key, then copy it into the Engage settings. WhatsApp 1. Register a Twilio number with WhatsApp. 2. Connect your Facebook account. 2. Create the WhatsApp messaging service. Several onboarding steps require copying and pasting information between Segment and SendGrid or Twilio. To streamline setup, open your Segment workspace in one browser tab and open two others for tasks you’ll carry out in SendGrid and Twilio. Continue reading for a detailed, step-by-step breakdown of each onboarding stage. Stage 1: Configure Engage Identifiers in Unify Through identity resolution , Segment uses the phone and email traits to identify users who can receive your Engage campaigns. To begin using Engage, you’ll need to verify that these identifiers exist in your workspace and add them if they don’t. Follow these steps to configure the traits: In your Segment workspace, navigate to Unify > Unify settings > Identity resolution . Under the Identity resolution configuration table, verify that phone and email appear under the Identifier column. If so, the Engage identifiers are configured correctly; skip to create and configure a SendGrid account . If either identifier is missing, click the Add identifier button, then click Custom identifiers . In the New Custom Identifier modal, add the first missing trait ( phone or email ) in the Trait/Property key field, then click Add Identifier . If both traits were missing, repeat Step 4 and add the other missing trait ( phone or email ). Finish by clicking Add New Identifier . Your Segment workspace is now configured for Engage.  Next, you’ll create a SendGrid account and connect it to Segment. Stage 2: Create and configure a SendGrid account SendGrid powers delivery of your Engage email campaigns. During this stage of onboarding, you’ll create and set up a SendGrid Pro account. You’ll then configure SendGrid and Engage to enable both subscription tracking and an event webhook. Create your SendGrid Pro account Start by creating a SendGrid account and then upgrading to the SendGrid Pro Plan: Visit the SendGrid website and sign up for an account. Within your SendGrid space, navigate to Settings > Account Details > Your Products . Under the Email API section, select Change Plan . On the Email API Plans page, select a Pro option that fits your anticipated sending needs. Add the Pro option to your cart, and complete checkout. Upgrading to SendGrid Pro Upgrading to a SendGrid Pro account may require additional action on your part. Follow the instructions in SendGrid’s account upgrade guide to complete your upgrade. Create a subuser and check the dedicated IP address Next, you’ll create a SendGrid subuser and ensure that a dedicated IP has been assigned: In your SendGrid space, navigate to Settings > Subuser Management , then click Create New Subuser . In the Create New Subuser window, create a username for the subuser, then add an email address and password. Your SendGrid subuser username must begin with the prefix twilio_engage_app_ . Add a unique identifier to the end of the prefix, for example, twilio_engage_app_someusername . In the same window, click the checkbox next to the dedicated IP address you’ll user for the subuser. Segment recommends that you choose an IP address that you’ll only use for Engage. Fill out the remaining fields in the window, then click Create Subuser . Using SendGrid’s documentation , warm up the IP address. Authenticate your domain SendGrid parent account In this section, you’ll authenticate your domain and set up reverse DNS with your SendGrid parent account. Now, you’ll authenticate your domain with SendGrid and your DNS provider and enable link branding . Domain authentication protects your sending reputation by showing email providers that you’ve given SendGrid permission to send email campaigns for you. To authenticate your domain, you’ll copy CNAME records given to you by SendGrid and paste them into your DNS provider. Before you begin, verify that you have the necessary permissions to add CNAME records to your DNS. If you’re not sure if you have the right permissions, reach out to your organization’s IT department. You’ll authenticate your domain using the SendGrid platform and your DNS provider: From your SendGrid parent account , follow SendGrid’s domain authentication guide . During the authentication process, SendGrid asks if you would like to brand links for your domain. Select Yes . SendGrid provides you with five CNAME records.  Add them to your DNS host. Return to SendGrid and verify your DNS . Complete authentication by setting up reverse DNS: From your SendGrid parent account , follow SendGrid’s reverse DNS (rDNS) documentation . SendGrid provides you with one A record. Add it to your DNS host, along with the five CNAME records from the previous steps. Return to SendGrid and verify your DNS . Enable subscription tracking You’ll also need to enable subscription tracking , which keeps records of users who unsubscribe from your email campaigns: Within your SendGrid space, navigate to Settings > Tracking . On the Tracking Settings page , click Subscription Tracking in the Settings column. At the end of the Subscription Tracking window, toggle Setting State to enabled . Click Save . Enable event webhook Subuser Step This step takes place in the subuser space. You’ll now need to enable event webhooks, which trigger webhook notifications for campaign-related events like clicks and opens: Within your SendGrid subuser space, navigate to Settings > Mail Settings . Click the pencil edit icon next to Event Webhook . On the Event Webhook page, set authorization method to none. Copy and paste the following URL, depending on your region,  into the HTTP Post URL field: US: https://engage-ma-webhook-api.engage.segment.com/sendgrid EU: https://engage-ma-webhook-api.euw1.engage.segment.com/sendgrid Check Select All under both Deliverability Data and Engagement Data . Toggle the Event Webhook Status to Enabled . Click Save . Generate an API key Copying SendGrid Credentials This step creates an API key and API Key ID that you’ll immediately add to Segment. Make sure you’re ready to copy and save the API key before proceeding; SendGrid only displays the API key once. You must follow these steps from within the SendGrid subuser account you created for use with Twilio Engage . Re-using API Keys It is not possible to re-use API Keys in different Engage spaces. For each space, a new API Key is required. Now, you’ll generate an API key and API Key ID within SendGrid. With your SendGrid account open in one tab, open your Segment workspace open in another. You’ll need both open to copy and paste the API credentials into your Engage settings. SendGrid Subuser Step Carry out the following steps in your SendGrid subuser space. Within your SendGrid subuser space , navigate to Settings > API Keys . Click the Create API Key button. In the Create API Key window, name your API key using the prefix twilio_engage_app_ , with a suffix of your choice added to the end, like twilio_engage_app_somekey . Under API Key Permissions, select the Full Access radio button, then click Create & View . SendGrid displays your API Key. Click the API key to copy it to your computer’s clipboard , then select Done . SendGrid returns you to the API Keys page; leave this tab open. To finish linking the API credentials to your Segment account, follow these steps: Switch to the browser tab with your Segment workspace open. Navigate to Engage > Engage settings > Channels . Under Email Service with SendGrid , select the Get Started button. In the Set up and validate your SendGrid account window (shown below), enter the subuser username you previously created into the Subuser Name field. Paste the Subuser API Key you just copied from SendGrid into the Subuser API Key field. Leave this tab open. Return to the tab showing your SendGrid API Keys. Copy the key displayed after API Key ID. Return to the tab with your Segment workspace. Paste the copied API Key ID into the Subuser API Key ID field. Click Verify . Warm up your IP If you already send emails regularly on your chosen IP, proceed to Stage 3 . To finish configuring your SendGrid account for usage with Twilio Engage, you’ll warm up your IP . IP warmup protects your sender reputation and ensures that you avoid email deliverability issues. As a best practice, only warm up your IP when you’re ready to begin sending campaigns. Automated IP warmup You can enable automated IP warmup by following these steps: Within your SendGrid space, navigate to Settings > IP Addresses . Click the action menu for the IP you want to warmup, which brings up the Edit Your Dedicated IP Address screen. Select Use Automated IP warmup , then click Save . Once you’ve enabled IP warmup, you’re ready to send as many campaigns as you’d like. SendGrid will begin sending your campaigns through a shared pool of IP addresses, including your own. Over the next 30 days, SendGrid will gradually increase the number of campaigns sent through your chosen IP. After 30 days, SendGrid will send all your emails from your dedicated IP. IP warmup best practices Keep the following in mind once you’ve enabled automated IP warmup: Use the IP you warmed up for marketing campaigns; avoid using the IP for transactional emails. Segment recommends that you start by sending low-volume campaigns before high-volume campaigns. This will help establish your domain reputation with SendGrid. Once you’ve completed IP warmup, your SendGrid account will be fully configured and ready to use with Engage.  You’re ready to move to Stage 3 and set up Twilio SMS. Stage 3: Create and configure Twilio SMS services To add the ability to send SMS campaigns in Engage, you’ll now create a Twilio account, set up a phone number and messaging service, and generate an API key. Set up a Twilio Messaging Service Phone Number Registration You’ll need to purchase a phone number to set up Twilio Messaging . Depending on the phone number type you purchase, you may have to register the number. Before completing this section, read Twilio’s documentation on short code , long code , and toll free numbers . Once you’ve identified the type of phone number you’ll use with Twilio Engage, follow these steps to create a Twilio Messaging Service: Visit the Twilio website and sign up for a paid account . Trial accounts generate sending errors. Purchase a phone number within your Twilio Console. If necessary, register the number . In the Twilio Console side menu, navigate to Messaging > Services . On the Messaging Services page, click Create Messaging Service . Enter a name for your Messaging Service. Under the Messaging use dropdown, select Market my services . From the Sender Pool tab, click Add Senders , then select the phone number you purchased in Step 1. Click Step 3: Set up Integration . Leave this tab open. Verify that the dropdown next to the Request URL field is set to HTTP Post . (If applicable:) Click Step 4: Add compliance info . Finish compliance setup, then click Complete Messaging Service Setup . Generate an API key, and select your messaging service(s) Copying Twilio Credentials This step generates an Account SID, API key SID, and API key secret that you’ll later add to Segment. Make sure you’re ready to copy and save both before proceeding. Start by creating your Twilio account and getting an API key for Engage: In your Twilio console, select the Account dropdown menu, then API keys & tokens . On the Auth tokens & API keys page, click Create API key . Enter a name for the API key in the Friendly name field. Set the region to United States (US1) - Default and key type to Main . Click Create API Key . Copy and save both the SID and Secret field contents. Return to the API keys & tokens page. In the Live credentials section, copy the Account SID credentials. Switch to the browser tab with your Segment workspace. Navigate to Engage > Engage settings > Channels .  Under SMS Service with Twilio , click the Get Started button. The Set up and validate your Twilio account page appears. Under Enter your Twilio API Key information (shown below), paste the Account SID, API Key SID, and API Key Secret you copied above into their corresponding fields. Click Verify , then select the messaging services you want to use in your space. Click Save Twilio Account. If you’re unable to verify your Account SID, SID, or API Key secret, you may have copied an extra space at the end of one or the other. Verify that you’ve not added any extra characters or spaces, then try to verify again. Stage 4: Create and configure Twilio WhatsApp services To send WhatsApp messages in Twilio Engage, you’ll register a Twilio number with WhatsApp, connect your Facebook account, and create a WhatsApp messaging service. Register a Twilio number with WhatsApp Purchase an SMS-capable phone number within your Twilio Console. For international numbers, view Twilio’s Phone Number Regulations guidelines. From the Twilio side menu, navigate to Messaging > Senders > WhatsApp Senders . Select Create new sender . From the New Sender builder, find Twilio phone number , then choose the phone number you purchased in Step 1. Select Continue . Select Continue with Facebook . A Facebook popup window appears; leave it and the Twilio console open. Connect your Facebook account In the Facebook popup from the previous section, carry out these steps: Follow Facebook’s instructions to log in to your Facebook account. When you reach the Fill in your business information page, choose your WhatsApp Business Account or create a new account. Select Next . Create a new WhatsApp Business Profile that follows Meta’s display name guidelines . Fill out all fields, then select Next . In your Twilio console, copy the number shown in the Number to register with WhatsApp field. Paste it into the Phone number field on the Facebook Add a phone number for WhatsApp page, then select Next . Facebook prompts you to verify your phone number. Select the Text message radio button, then select Next . In your Twilio console, copy the code in the Verify via text messages section, then enter it into the Facebook Verification code field. Select Next . Facebook displays You're now ready to chat with people on WhatsApp . Click Finish to close the window. Create the WhatsApp messaging service You’ll now create a messaging service to connect your number to Engage: In the Twilio Console side menu, navigate to Messaging > Services . On the Messaging Services page, click Create Messaging Service . Enter a name for your Messaging Service. You must include the word WhatsApp in the messaging service name , for example, My New Service WhatsApp . Under the Messaging use dropdown, select Market my services , then select Create messaging service . From the Sender Pool tab, click Add Senders > Add WhatsApp Numbers > Confirm . Twilio confirms that the WhatsApp number has been assigned to the service. Your WhatsApp messaging service is now created. Regional Segment You can use Engage Premier on Segment’s regional infrastructure in the EU . Twilio Engage ensures data residency in the EU, but the channels you connect to, may not guarantee the same level of data residency. Check directly with the providers of the channels you use for information about data residency in their applications. Native channels like email and SMS, which use Twilio, are not data resident. Twilio is GDPR compliant, and has Binding Corporate Rules to ensure that data is protected when it’s transferred between countries. Next steps With configured accounts and services for all platforms, you’ve completed Engage onboarding and are ready to create and send campaigns to your users. Not sure where to start? Read the Engage documentation on sending email campaigns , SMS campaigns , and WhatsApp campaigns . To save time when generating Engage campaigns, check out the Engage guides on creating SMS templates , email templates , and WhatsApp templates . If you’re planning to import contacts to Engage, learn how to update your audiences with a CSV file . This page was last modified: 15 Jul 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Before you begin: overview and task checklist Stage 1: Configure Engage Identifiers in Unify Stage 2: Create and configure a SendGrid account Stage 3: Create and configure Twilio SMS services Stage 4: Create and configure Twilio WhatsApp services Regional Segment Next steps Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Twilio Engage Premier Onboarding Guide"
      },
      {
        "level": 2,
        "text": "Before you begin: overview and task checklist"
      },
      {
        "level": 2,
        "text": "Stage 1: Configure Engage Identifiers in Unify"
      },
      {
        "level": 2,
        "text": "Stage 2: Create and configure a SendGrid account"
      },
      {
        "level": 3,
        "text": "Create your SendGrid Pro account"
      },
      {
        "level": 3,
        "text": "Create a subuser and check the dedicated IP address"
      },
      {
        "level": 3,
        "text": "Authenticate your domain"
      },
      {
        "level": 3,
        "text": "Enable subscription tracking"
      },
      {
        "level": 3,
        "text": "Enable event webhook"
      },
      {
        "level": 3,
        "text": "Generate an API key"
      },
      {
        "level": 3,
        "text": "Warm up your IP"
      },
      {
        "level": 3,
        "text": "IP warmup best practices"
      },
      {
        "level": 2,
        "text": "Stage 3: Create and configure Twilio SMS services"
      },
      {
        "level": 3,
        "text": "Set up a Twilio Messaging Service"
      },
      {
        "level": 3,
        "text": "Generate an API key, and select your messaging service(s)"
      },
      {
        "level": 2,
        "text": "Stage 4: Create and configure Twilio WhatsApp services"
      },
      {
        "level": 3,
        "text": "Register a Twilio number with WhatsApp"
      },
      {
        "level": 3,
        "text": "Connect your Facebook account"
      },
      {
        "level": 3,
        "text": "Create the WhatsApp messaging service"
      },
      {
        "level": 2,
        "text": "Regional Segment"
      },
      {
        "level": 2,
        "text": "Next steps"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/insights/",
    "title": " Profiles Insights | Segment Documentation",
    "content": "Home / Unify / Profiles Insights Profiles Insights Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Getting started Errors and violations Success logs Audit trail FAQ With Profiles Insights, you can troubleshoot event data with transparent insight into your Unify profiles . View errors and violations, success logs, and an audit trail for events that flow into your profiles. You can also learn why certain issues occur, and take preventative action against future errors. Getting started To get started with Profiles Insights, navigate to Unify > Profiles insights . From the Profiles Insights page, you can navigate to these tabs: Errors and violations Success logs Audit trail Errors and violations Use the errors and violations tab to view and help you troubleshoot any errors or violations that have occurred in your space. You can filter results by ID type, time range, specific violations, and more. To filter by external_id , you must enter an external_id value in the search bar. Errors Errors occur when a message didn’t resolve to a profile because Segment didn’t find a matching identifier or the system behaved unexpectedly. Click on an error log to view the error and next steps that Segment recommends. Profiles Insights flags the following error: Error Description No matching identifiers on event The event didn’t have any identifier types that matched your ID Resolution Settings . As a result, the event didn’t resolve to a profile. Profile Insights won’t surface errors if the event was dropped before entering Unify’s Identity Resolution . Learn more about Unify ingestion limits . Violations Violations occur when incoming events don’t comply with your Identity Resolution Settings . For example, when Segment drops an anonymous ID (lower priority) to resolve an event based on a matching user ID (higher priority), it results in a violation. Learn about identifier priorities in your Identity Resolution. For any violations, Segment may drop lower priority identifiers or the identifiers that violate your Identity Resolution Settings. From the grid, you can click a log name to view the violation details and recommended next steps. You can use the Message Payload tab to view raw messages for Track events and see exactly where the violation occurred. Profiles Insights flags the following violations: Violation Description Identifier value limit exceeded A lower priority identifier wasn’t added to the associated profile(s) because the maximum number of values for the identifier type exceeds the limit. Identifier value time limit exceeded A lower priority identifier wasn’t added to the associated profile(s) because there’s a limit to how many identifier type values can be added in a period of time. ID value blocked The identifier wasn’t added to a profile because it’s a blocked value. Profile merge limit exceeded The profile exceeds the system imposed merge limit. Segment’s default limit is 100. Identifier mapping limit exceeded The profile exceeds the system imposed mapping limit. Segment’s default limit is 1,000. Identifier value set to unique (legacy) The profile exceeds the cardinality limit of an identifier type set to be unique. This violation only appears for existing spaces that have the enforce_unique field configured. Identifier value limit exceeded (legacy) The profile exceeds the cardinality limit of an identifier type. The cardinality limit used for this violation is the limit field in the identifier space. Success logs Success logs provide visibility into a profile’s journey from creation to the point of merging into other profiles. Use the success logs to view: Profiles that Segment has merged Identifiers that Segment has mapped to a profile You can filter results by ID type, time range, incoming event type, and more. When you click a specific log, Segment displays merge or mapping details along with the message payload for Track events. Audit trail The Audit trail displays all audit actions that occur in your Unify space. This can include, for example, a user creating an access token or modifying Unify settings. Click an audit log link to view the user who initiated the action, timestamp, and log details. FAQ What are the record display and search time limits for Profiles Insights? Profiles Insights can display up to 500 records and supports searches within a 30-day time frame. This page was last modified: 23 Apr 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Getting started Errors and violations Success logs Audit trail FAQ Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Profiles Insights"
      },
      {
        "level": 2,
        "text": "Getting started"
      },
      {
        "level": 2,
        "text": "Errors and violations"
      },
      {
        "level": 3,
        "text": "Errors"
      },
      {
        "level": 3,
        "text": "Violations"
      },
      {
        "level": 2,
        "text": "Success logs"
      },
      {
        "level": 2,
        "text": "Audit trail"
      },
      {
        "level": 2,
        "text": "FAQ"
      },
      {
        "level": 3,
        "text": "What are the record display and search time limits for Profiles Insights?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/reverse-etl/setup/",
    "title": " Set up Reverse ETL | Segment Documentation",
    "content": "Home / Connections / Reverse etl / Set up Reverse ETL Set up Reverse ETL On this page Step 1: Add a source Step 2: Add a model Step 3: Add a destination Step 4: Create mappings Initial sync for a given mapping Edit Reverse ETL syncs There are four components to Reverse ETL: Sources, Models, Destinations, and Mappings. Follow these 4 steps to set up Reverse ETL: Add a source Add a model Add a destination Create mappings Step 1: Add a source In Reverse ETL, a source is your data warehouse. You need to be a user that has both read and write access to the warehouse. To add your warehouse as a source: Navigate to Connections > Sources and select the Reverse ETL tab in the Segment app. Click + Add Reverse ETL source . Select the source you want to add. Follow the corresponding guide to set up the required permissions for your Reverse ETL source: Azure Reverse ETL setup guide BigQuery Reverse ETL setup guide Databricks Reverse ETL setup guide Postgres Reverse ETL setup guide Redshift Reverse ETL setup guide Snowflake Reverse ETL setup guide Step 2: Add a model Models define sets of data you want to sync to your Reverse ETL destinations. A source can have multiple models. Segment supports SQL models and dbt models . SQL editor Navigate to Connections > Sources and select the Reverse ETL tab. Select your source and click Add Model . Click SQL Editor as your modeling method. (Segment will add more modeling methods in the future.) Enter the SQL query that’ll define your model. Your model is used to map data to your Reverse ETL destination(s). Choose a column to use as the unique identifier for each record in the Unique Identifier column field. The Unique Identifier should be a column with unique values per record to ensure checkpointing works as expected. It can potentially be a primary key. This column is used to detect new, updated, and deleted records. Click Preview to see a preview of the results of your SQL query. The data from the preview is extracted from the first 10 records of your warehouse. Segment caches preview queries and result sets in the UI, and stores the preview cache at the source level. Click Next . Enter your Model Name . Click Create Model . dbt model Use Segment’s dbt extension to centralize model management and versioning. Users who set up a BigQuery, Databricks, Postgres, Redshift, or Snowflake source can use Segment’s dbt extension to centralize model management and versioning, reduce redundancies, and run CI checks to prevent breaking changes. If you use dbt Cloud with Reverse ETL, you can create up to 5 mappings that use the sync strategy dbt Cloud , which extracts data from your warehouse and syncs it with your destination after a job in dbt Cloud is complete. Step 3: Add a destination In Reverse ETL, destinations are the business tools or apps you use that Segment syncs the data from your warehouse to. A model can have multiple destinations. Reverse ETL supports the destinations in the Reverse ETL catalog . If the destination you want to send data to is not listed in the Reverse ETL catalog, use the Segment Connections Destination to send data from your Reverse ETL warehouse to your destination. Engage users can use the Segment Profiles Destination to create and update Profiles that can then be accessed through Profile API and activated within Twilio Engage . Separate endpoints and credentials required to set up third party destinations Before you begin setting up your destinations, note that each destination has different authentication requirements. See the documentation for your intended destination for more details. To add your first destination: Navigate to Connections > Destinations and select the Reverse ETL tab. Click Add Reverse ETL destination . Select the destination you want to connect to and click Configure . Select the Reverse ETL source you want to connect the destination to. Enter the Destination name and click Create Destination . Enter the required information on the Settings tab of the destination. Navigate to the destination settings tab and enable the destination. If the destination is disabled, then Segment won’t be able to start a sync. Step 4: Create mappings Mappings enable you to map the data you extract from your warehouse to the fields in your destination. A destination can have multiple mappings. To create a mapping: Navigate to Connections > Destinations and select the Reverse ETL tab. Select the destination that you want to create a mapping for. Click Add Mapping . Select the model to sync from. In the Define sync behavior section, select the Action you want to sync. Actions determine the information sent to the destination. The list of Actions are unique to each destination. Select which records to send to your destination after Segment completes extracting data based on your model. Some destinations have sync modes , which let you specify how Segment should send data to the destination. Sync modes are unique to each destination. Destinations without sync modes let you select from the following options: Added records Updated records Added or updated records Deleted records In the Map fields section, define how to map the record columns from your model to your destination. Map the fields that come from your source to fields that the destination expects to find. Fields on the destination side depend on the type of Action selected. If you’re setting up a Destination Action, some mapping fields might require data to be in the form of an object or array. See the supported objects and arrays for mapping for more information. (Optional) Use the Suggested Mappings feature to identify and match near-matching field names to streamline the field mapping process. In the Send test record section , select a test record to preview the fields that you mapped to your destination. When you’ve verified that the records appear as expected, click Next . Enter a name for your mapping. The name initially defaults to the Action’s name, for example, Track Event , but you can make changes to this default name. Select how often you want Segment to sync your data under Schedule configuration . Interval : Extractions perform based on a selected time cycle. Select one of the following options: 15 minutes, 30 minutes, 1 hour, 2 hours, 4 hours, 6 hours, 8 hours, 12 hours, 1 day. Day and time : Extractions perform at specific times on selected days of the week. Select the destination you’d like to enable on the My Destinations page under Reverse ETL > Destinations . Turn the toggle on for the Mapping Status . Events that match the trigger condition in the mapping will be sent to the destination. If you disable the mapping state to the destination, events that match the trigger condition in the mapping won’t be sent to the destination. Use Segment’s Duplicate mappings feature to create an exact copy of an existing mapping. The copied mapping has the same configurations and enrichments as your original mapping. Supported object and arrays When you set up destination actions in Reverse ETL, depending on the destination, some mapping fields may require data as an object or array . Object mapping You can send data to a mapping field that requires object data. An example of object mapping is an Order completed model with a Products column that’s in object format. Example: { \"product\" : { \"id\" : 0001 , \"color\" : \"pink\" , \"name\" : \"tshirt\" , \"revenue\" : 20 , \"inventory\" : 500 } } To send data to a mapping field that requires object data, you can choose between these two options: Option Details Customize object This enables you to manually set up the mapping fields with any data from the model. If the model contains some object data, you can select properties within the object to set up the mappings as well. Select object This enables you to send all nested properties within an object. The model needs to provide data in the format of the object. Certain object mapping fields have a fixed list of properties they can accept. If the names of the nested properties in your object don’t match with the destination properties, the data won’t send. Segment recommends you to use Customize Object to ensure your mapping is successful. Array mapping To send data to a mapping field that requires array data, the model must provide data in the format of an array of objects. An example is an Order completed model with a Product purchased column that’s in an array format. Example: [ { \"currency\" : \"USD\" , \"price\" : 40 , \"productName\" : \"jacket\" , \"purchaseTime\" : \"2021-12-17 23:43:47.102\" , \"quantity\" : 1 }, { \"currency\" : \"USD\" , \"price\" : 5 , \"productName\" : \"socks\" , \"quantity\" : 2 } ] To send data to a mapping field that requires array data, you can choose between these two options: Option Details Customize array This enables you to select the specific nested properties to send to the destination. Select array This enables you to send all nested properties within the array. Certain array mapping fields have a fixed list of properties they can accept. If the names of the nested properties in your array don’t match the destination properties, the data won’t send. Segment recommends you to use the Customize array option to ensure your mapping is successful. Objects in an array don’t need to have the same properties. If a user selects a missing property in the input object for a mapping field, the output object will miss the property. Null value management You can choose to exclude null values from optional mapping fields in your syncs to some destinations. Excluding null values helps you maintain data integrity in your downstream destinations, as syncing a null value for an optional field may overwrite an existing value in your downstream tool. For example, if you opt to sync null values with your destination and an end user fills out a form but chooses to leave an optional telephone number field blank, the existing telephone number you have on file in your destination could be overwritten with the null value. By opting out of null values for your downstream destination, you would preserve the existing telephone number in your destination. By default, Segment syncs null values from mapped fields to your downstream destinations. Some destinations do not allow the syncing of null values, and will reject requests that contain them. Segment disables the option to opt out of syncing null values for these destinations. To opt out of including null values in your downstream syncs: Navigate to Connections > Destinations and select the Reverse ETL tab. Select the destination and the mapping you want to edit. Click Edit mapping. Under Optional fields , select the field you want to edit. In the field dropdown selection, disable the Sync null values toggle. Initial sync for a given mapping After you’ve set up your source, model, destination, and mappings for Reverse ETL, your data will extract and sync to your destination(s) right away if you chose an interval schedule. If you set your data to extract at a specific day and time, the extraction will take place then. Edit Reverse ETL syncs Edit your model To edit your model: Navigate to Connections > Destinations and select the Reverse ETL tab. Select the source and the model you want to edit. On the overview tab, click Edit to edit your query. Click the Settings tab to edit the model name or change the schedule settings. Suggested mappings Suggested mappings is fully available for RETL mappings. Segment offers suggested mappings that automatically propose relevant destination fields for model columns and payload elements. For example, if your model includes a column or payload field named transaction_amount , the feature might suggest mapping it to a destination field like Amount or TransactionValue . This automation, powered by intelligent autocompletion, matches and identifies near-matching field names to streamline the mappings setup process. For more information, see Segment’s suggested mappings blog post and the Suggested Mappings Nutrition Facts Label . Review the suggested mappings for accuracy before finalizing them, as Segment can’t guarantee all of the suggested mappings are accurate. Edit your mapping To edit your mapping: Navigate to Connections > Destinations and select the Reverse ETL tab. Select the destination and the mapping you want to edit. Select the … three dots and click Edit mapping . If you want to delete your mapping, select Delete . This page was last modified: 18 Dec 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Step 1: Add a source Step 2: Add a model Step 3: Add a destination Step 4: Create mappings Initial sync for a given mapping Edit Reverse ETL syncs Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Set up Reverse ETL"
      },
      {
        "level": 2,
        "text": "Step 1: Add a source"
      },
      {
        "level": 2,
        "text": "Step 2: Add a model"
      },
      {
        "level": 3,
        "text": "SQL editor"
      },
      {
        "level": 3,
        "text": "dbt model"
      },
      {
        "level": 2,
        "text": "Step 3: Add a destination"
      },
      {
        "level": 2,
        "text": "Step 4: Create mappings"
      },
      {
        "level": 3,
        "text": "Supported object and arrays"
      },
      {
        "level": 3,
        "text": "Null value management"
      },
      {
        "level": 2,
        "text": "Initial sync for a given mapping"
      },
      {
        "level": 2,
        "text": "Edit Reverse ETL syncs"
      },
      {
        "level": 3,
        "text": "Edit your model"
      },
      {
        "level": 3,
        "text": "Suggested mappings"
      },
      {
        "level": 3,
        "text": "Edit your mapping"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/how-to-guides/measure-marketing-roi/",
    "title": " Measuring the ROI of Your Marketing Campaigns | Segment Documentation",
    "content": "Home / Guides / How to guides / Measuring the ROI of Your Marketing Campaigns Measuring the ROI of Your Marketing Campaigns On this page Analyze campaign performance Build the funnel Analyze channel performance Build repeatable hit marketing campaigns The purpose of marketing campaigns is to drive traffic (and sales). But how do you know which campaigns yield the most conversions or what channel across the campaigns was most effective? This guide provides you with the tools to answer these questions with SQL so that your marketing team can reproduce the hit campaigns and consistently generate loyal customers. Talk to a product specialist to learn how companies like Warby Parker and Crate & Barrel use a data warehouse to increase engagement and sales. Analyze campaign performance The goal of marketing campaigns is to drive engagement and conversions. Most commonly performed by attracting traffic to the site, these campaigns use UTM parameters for attribution. In our analysis, we’ll be heavily relying on UTM parameters to analyze not only campaign, but also channel performance. Learn how to effectively use UTM parameters in your marketing campaign strategies. For our analysis walkthrough, we’ll use fictitious e-commerce and marketing data from on-demand artisanal toast company, Toastmates. Toastmates is currently running these two campaigns: “National Toast Day”, where $5 off was applied if you made a purchase on that day “A Toast To Your Friend”, where you can buy toast for a friend at $5 off Each of these campaigns used a combination of channels. Here is a table with the channels and corresponding UTM parameters so when we build the SQL query, we can make sure all of the traffic sources are accounted for. We’ll use SQL below to measure the performance of each campaign and what that means for future marketing activities. Build the funnel The following query creates a table where each row is a customer and the columns are the date time when a key funnel event happens that have the context_campaign_name to match that of the UTM_campaign . The key funnel events in this analysis are Store Visited (based on a page view to the store URL), Product Viewed , and Order Completed . Given that each channel may have some key top of the funnel action that is unique to itself, let’s save that analysis for when we’re analyzing across channels. Feel free to copy and paste the below query for your analysis so long as you replace national-toast-day with your own UTM campaign parameter. with users as ( select * from toastmates . users ), page_viewed as ( select p . received_at as page_viewed_at , p . context_campaign_name , p . user_id from toastmates . pages p left join users u on u . id = p . user_id where p . context_campaign_name is not null and p . url ilike '%toastmates.com/store%' ), product_viewed as ( select v . received_at as product_viewed_at , v . context_campaign_name , v . user_id from toastmates . product_viewed v left join users u on u . id = v . user_id ), order_completed as ( select c . received_at as order_completed_at , c . context_campaign_name , c . user_id from toastmates . order_completed c left join users u on u . id = c . user_id ) select p . user_id as user_id , page_viewed_at , product_viewed_at , order_completed_at , p . context_campaign_name from page_viewed p left join product_viewed v on p . user_id = v . user_id left join order_completed c on p . user_id = l . user_id order by 5 desc Here are the first four rows of the resulting table: Then, we can use tweak the query above into the one below to perform some simple COUNT and SUM on the previous table to get conversion metrics as well as total revenue derived from the campaign. with users as ( select * from toastmates . users ), page_viewed as ( select p . received_at as page_viewed_at , p . context_campaign_name , p . user_id from toastmates . pages p left join users u on u . id = p . user_id where p . context_campaign_name is not null and p . url ilike '%toastmates.com/store%' ), product_viewed as ( select v . received_at as product_viewed_at , v . context_campaign_name , v . user_id from toastmates . product_viewed v left join users u on u . id = v . user_id ), order_completed as ( select c . received_at as order_completed_at , c . context_campaign_name , c . total , c . user_id from toastmates . order_completed c left join users u on u . id = c . user_id ) select p . context_campaign_name , count ( page_viewed_at ) as store_visits , count ( product_viewed_at ) as product_views , count ( order_completed_at ) as orders_completed , sum ( total ) as total_revenue from page_viewed p left join product_viewed v on p . user_id = v . user_id left join order_completed c on p . user_id = l . user_id group by 5 order by 5 desc Here is the resulting table: This analysis not only gives us a great snapshot of the conversion points along each campaign’s funnel, but also shows that we’ve generated $3,100.37 from the National Toast Day campaign and $3,824.68 from the Toast Your Friend campaign. Also we can see that the quality of the traffic from the National Toast Day is higher, but we’ve had more total traffic from Toast Your Friend, which makes sense since it’s an ongoing campaign. But this is not yet ROI, since we haven’t incorporated the spend—the labor of your marketing team and the paid acquisition channels to source part of this traffic—that went into these channels. Add campaign costs The main costs that are incorporated in an ROI calculation are salaries (pro-rated by person-hour) and media spend. While we could conceivably create a custom, static table in SQL that contains the spend information over time, the faster and more practical way would be a back of the envelope calculation. The costs associated with a given campaign consist of two major pieces: the person-hour cost and any associated media spend. Calculating the pro-rated person-hour is an estimate of the number of hours and people used to set up and manage the campaign, then multiplied by the hourly rates based off their annual salaries. The media spend is the advertising cost for distributing creatives to generate traffic to your store Want to easily export advertising data from Google Adwords or Facebook Ads ? Check out Segment Sources . When we have the aggregate cost numbers, the formula for ROI is: Campaign ROI = (Profit Attributed to Campaign – Campaign Cost) / Campaign Cost Here is a spreadsheet to illustrate the ROI calculation for both campaigns: Though ROI numbers are one success metric, it’s an important benchmark for comparing performance when launching new campaigns or comparing against past campaigns. But how can we go one step further and see what worked and what didn’t? One approach is to see which channels convert better, so you know how to adjust your marketing spend or media buys in your current campaigns or future ones. Analyze channel performance A single campaign can include a wide variety of channels: email, display ads, push notifications, forums, etc. all of which yields different engagement and conversion rates. Effective marketers will keep a pulse on each channel throughout the duration of the campaign to understand whether a target audience is being saturated, a creative refresh is needed (for advertising), or how to efficiently allocate future spend towards a source that converts. The analysis is similar to measuring the performance across a single campaign, with the only change being finding events where we focus on context_campaign_medium or context_campaign_source instead of context_campaign_name . The SQL below measures the conversion rates at key funnel events for national-toast-day , but broken down by utm_medium . You can copy the below into your favorite editor, as long as you change out the context_campaign_name and context_campaign_medium parameters to ones that applies to your business. with users as ( select * from toastmates . users ), page_viewed as ( select p . received_at as page_viewed_at , p . context_campaign_name , p . user_id from site . pages p left join users u on u . id = p . user_id where p . context_campaign_name = 'national-toast-day' and p . context_campaign_medium is not null and p . url ilike '%toastmates.com/store%' ), product_viewed as ( select v . received_at as product_viewed_at , v . context_campaign_medium , v . user_id from toastmates . product_viewed v left join users u on u . id = v . user_id ), order_completed as ( select c . received_at as order_completed_at , c . context_campaign_medium , c . user_id , c . total from toastmates . order_completed c left join users u on u . id = c . user_id ) select p . context_campaign_medium as utm_medium , count ( page_viewed_at ) as store_visits , count ( product_viewed_at ) as product_views , count ( order_completed_at ) as orders_completed , sum ( c . total ) as total_revenue from page_viewed p left join product_viewed_at v on p . user_id = c . user_id left join order_completed c on p . user_id = c . user_id group by 1 order by 1 desc The resulting table: Since the National Toast Day campaign is relatively new, the majority of the traffic is from the email and an article (“news”). But we can see that the social channels have a lower conversion from store visits to product views. Email has the best overall conversion to revenue, which may be attributed to the recipients already familiar with the Toastmates brand or having previously had a stellar end-to-end shopping experience. We can further breakdown this analysis by seeing which email, display ads, and social channels performed the best, by adding utm_source and utm_content ,assuming that you’ve properly added them in your earned and paid media links. Also note that this preliminary analysis in SQL doesn’t account for double-counted users, who had impressions with our brand on multiple channels (e.g. someone seeing a display ad, yet converted on the email outreach). Fortunately, there are multi-touch attribution models that can be applied to better understand the weights of each activity towards conversion. Learn more about multi-touch attribution models. Build repeatable hit marketing campaigns Measuring the ROI and performance of marketing campaigns and marketing channels tells a compelling story about what types of campaigns resonate with your audience. How does your audience like to be engaged? Text, push notifications, email? What campaign messaging hooks work the best in getting them back at your store? You can apply this analytical approach and performance measurement techniques to a wide variety of marketing activities, such as offline marketing, billboards, or sponsoring events. These insights can empower your team to focus on what works and eliminate what doesn’t. Talk to a product specialist to learn how companies like Warby Parker and Crate & Barrel use a data warehouse to increase engagement and sales. This page was last modified: 21 Apr 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Analyze campaign performance Build the funnel Analyze channel performance Build repeatable hit marketing campaigns Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Measuring the ROI of Your Marketing Campaigns"
      },
      {
        "level": 2,
        "text": "Analyze campaign performance"
      },
      {
        "level": 2,
        "text": "Build the funnel"
      },
      {
        "level": 2,
        "text": "Analyze channel performance"
      },
      {
        "level": 2,
        "text": "Build repeatable hit marketing campaigns"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/functions/copilot/",
    "title": " Functions Copilot | Segment Documentation",
    "content": "Home / Connections / Functions / Functions Copilot Functions Copilot On this page Functions Copilot benefits Example prompts Best practices and limitations Functions Copilot helps you generate JavaScript code for functions using natural language prompts. For more information about the language model used to generate JavaScript code, see the Functions Copilot Nutrition Facts Label . Functions Copilot benefits Functions Copilot improves efficiency and productivity by streamlining the process of creating and managing custom functions. Functions Copilot can help you: Generate JavaScript code for custom integrations and data transformations. Analyze existing code and provide optimization suggestions. Secure sensitive data with minimal effort. Simplify code testing and maintenance. Example prompts This table lists example prompts you can use with Functions Copilot: Function Type Example Prompts Source Functions “Transform incoming data into a track event.” “Enrich user data with additional demographic details using an external API.” Destination Functions “Create a function that enriches an Identify event using the Profile API.” “Remove PII data and hash email addresses in an Identify event.” Destination Insert Functions “Enrich an Identify event using an external API.” “Tokenize PII data before sending it downstream.” Best practices and limitations Follow this guidance when you use Functions Copilot: Avoid using personally identifiable information (PII) or sensitive data. Write specific prompts. Specificity leads to more accurate CustomerAI function generation. Use the names of existing events, related attributes, and properties. Iterate on your prompts. If you don’t get the result you’re looking for, try rewriting the prompt. Limitations Keep the following limitations in mind as you work with Functions Copilot: Context limitations : Functions Copilot generates code based on Segment-specific terminology and the prompts you write. As a result, the generated output may not always be accurate. If the function doesn’t initially meet your needs, try to refine or rewrite your prompt. Language support : Functions Copilot only supports English prompts. Using other languages may impact the accuracy of the generated output. This page was last modified: 27 Sep 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Functions Copilot benefits Example prompts Best practices and limitations Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Functions Copilot"
      },
      {
        "level": 2,
        "text": "Functions Copilot benefits"
      },
      {
        "level": 2,
        "text": "Example prompts"
      },
      {
        "level": 2,
        "text": "Best practices and limitations"
      },
      {
        "level": 3,
        "text": "Limitations"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/identity-resolution/identity-resolution-onboarding/",
    "title": " Identity Resolution Onboarding | Segment Documentation",
    "content": "Home / Unify / Identity resolution / Identity Resolution Onboarding Identity Resolution Onboarding Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Identity Resolution settings Connect a source Create an audience The steps in this guide pertain to spaces created after October 5th, 2020 . For spaces created before October 5th, 2020 , please refer to Identity Resolution Settings . Workspace owners, administrators, and users with the Identity Admin role can edit Identity Resolution Settings. Segment creates and merges user profiles based on a space’s Identity Resolution configuration. Segment searches for identifiers such as userId , anonymousId , and email on incoming events and matches them to existing profiles or creates new profiles. These identifiers display in the Identities tab of a User Profile in the Profile explorer. Navigate to Unify > Profile explorer to view identities attached to a profile, along with custom traits, event history, and more. Flat matching logic After receiving a new event, Segment looks for profiles that match any of the identifiers on the event. Based on the existence of a match, one of three actions can occur: 1: Create a new profile When there are no pre-existing profiles that have matching identifiers to the event, Segment creates a new user profile. 2: Add to existing profile When there is one profile that matches all identifiers in an event, Segment attempts to map the traits, identifiers, and events on the call to that existing profile. If there is an excess of any identifier on the final profile, Segment defers to the Identity Resolution rules outlined below. 3: Merge existing profiles When there are multiple profiles that match the identifiers in an event, Segment checks the Identity Resolution rules outlined below, and attempts to merge profiles. Identity Resolution settings Identity Admins should first configure Identity Resolution Settings to protect the identity graph from inaccurate merges and user profiles. During the space creation process, the first step is to choose an Identity Resolution configuration. If this is your first space, you have the option to choose a Segment-suggested Out-of-the-Box configuration or a custom Identity Resolution setup. All other spaces have a third option of importing settings from a different space. Out-of-the-box For most first-time users, Segment recommends that you use the out-of-the-box configuration and answer a short series of questions for a best-fit setup for your use-case. If you have custom unique identifiers or don’t have a canonical user_id , you’re automatically redirected to the Identity Resolution Settings page to complete your setup. Custom rules If you’re familiar with identity or have custom identifiers, Segment recommends that you select Custom Rules. Segment redirects you to the Identity Resolution Settings page where you can add Default Identifiers or Custom Identifiers. Segment’s 11 default are: External ID Type Message Location in Track or Identify Call user_id userId email traits.email or context.traits.email android.id context.device.id when context.device.type = ‘android’ android.idfa context.device.advertisingId when context.device.type = ‘android’ AND context.device.adTrackingEnabled = true android.push_token context.device.token when context.device.type = ‘android’ anonymous_id anonymousId ga_client_id context.integrations[‘Google Analytics’].clientId when explicitly captured by users group_id groupId ios.id context.device.id when context.device.type = ‘ios’ ios.idfa context.device.advertisingId when context.device.type = ‘ios’ AND context.device.adTrackingEnabled = true ios.push_token context.device.token when context.device.type = ‘ios’ You can also provide a trait or property key to match on to add custom identifiers. You can preview the locations where Segment looks for the identifier. Segment accepts both camelCase and snake_case for context.traits, traits, and properties, but accepts lowercase types for identifiers only in the context.externalIds object. Blocked values Segment recommends that you proactively prevent using certain values as identifiers. While these values remain in the payload on the event itself, it is not promoted to an identifier Segment uses to determine user profiles. This is important when developers have a hard-coded value for fields like user_id during QA or development that then erroneously make it to production. This may cause hundreds of profiles to merge incorrectly and can have costly consequences if these spaces already feed data into a production email marketing tool or push notification tool downstream. In the past, Segment has seen certain default values that cause large amounts of profiles to merge incorrectly. Segment suggests that for every identifier, customers opt into automatically blocking the following suggested values: Value Type Zeroes and Dashes (^[0-]*$) Pattern (REGEX) -1 Exact Match null Exact Match anonymous Exact Match Before sending data through, Segment also recommends that you add any default hard-coded values that your team uses during the development process, such as void or abc123 . Limit Identity Admins can specify the total number of values allowed per identifier type on a profile during a certain period. For example, in the image below, the anonymous_id field has a limit of 5 Weekly . This will vary depending on how companies define a user today. In most cases, companies rely on user_id to distinguish user profiles and Segment defaults to the following configurations: Identifier Limit user_id 1 all other identifiers 5 Specific cases may deviate from this default. For example, a case where a user can have more than one user_id but one email, like when shopify_id and an internal UUID define a user. In this case, an example configuration may be: Identifier Limit email 1 user_id 2 all other identifiers 5 When you choose the limit on an identifier, ask the following questions about each of the identifiers you send to Segment: Is it an immutable ID? An immutable ID, such as user_id , should have 1 ever per user profile. Is it a constantly changing ID? A constantly changing ID, such as anonymous_id or ga_client_id , should have a short sliding window, such as 5 weekly or 5 monthly , depending on how often your application automatically logs out the user. Is it an ID that updates on a yearly basis? Most customers will have around five emails or devices at any one time, but can update these over time. For identifiers like email , android.id , or ios.id , Segment recommends a longer limit like 5 annually . Priority Segment considers the priority of an identifier once that identifier exceeds the limit on the final profile. For example, consider a Segment space with the following Identity Resolution configurations: Identifier Limit Priority user_id 1 1 email 5 2 anonymous_id 5 3 A profile already exists with user_id abc123 and email jane@example1.com . A new event comes in with new user_id abc456 but the same email jane@example1.com . If this event maps to this profile, the resulting profile would then contain two user_id values and one email . Given that user_id has a limit of 1, this exceeds the limit of that identifier. As a result, Segment checks the priority of the user_id identifier. Because email and user_id are the two identifiers on the event and email ranks lower than user_id , Segment demotes email as an identifier on the incoming event and tries again. At this point, the event searches for any profiles that match just the identifier user_id abc456 . Now there are no existing profiles with this identifier, so Segment creates a new profile with user_id abc456 . By default, Segment explicitly orders user_id and email as rank 1 and 2 , respectively. All other identifiers are in alphabetical order beginning from rank 3 . This means that if the identifiers sent with events flowing into Segment are user_id, email, anonymous_id, and ga_client_id, the rank would be as follows: Identifier Priority user_id 1 email 2 anonymous_id 3 ga_client_id 4 If a new android.id identifier appeared without first giving it explicit order, the order would automatically reshuffle to: Identifier Priority user_id 1 email 2 android.id 3 anonymous_id 4 ga_client_id 5 If you require an explicit order for all identifiers, configure this in the Identity Resolution Settings page before sending in events. When choosing the priority of your identifier, ask the following questions about each of the identifiers you send to Segment: Is it an immutable ID? Give immutable IDs, such as user_id, highest priority. Are they unique IDs? Give Unique IDs such as email higher priority than possibly shared identifiers like android.id or ios.id. Does it temporarily identify a user? Identifiers such as anonymous_id, ios.idfa, and ga_client_id are constantly updated or expired for a user. Generally speaking, rank these lower than identifiers that permanently identify a user. Importing from an existing space This option is available to new spaces after you create an initial Dev space. Segment recommends this option when identity settings are validated as correct in the initial Dev space and should be copied into the Production space. You can review the identifiers, priorities, limits, and blocked values before you complete the import. Connect a source After you configure Identity Resolution settings, the next step is to connect a source to the Segment space. Create an audience After you connect a source, Segment creates user profiles based off of replayed and newly incoming data. The next step, which is important in the Dev space, is to create an audience to ensure that user profiles have populated correctly and that the Identity Resolution settings follow expected business logic. For example, if there should be 100,000 distinct users who have a user_id , this would be a great way to validate that the Identity Resolution settings have calculated profiles correctly. For more information about how to create audiences and traits, see Segment’s Audiences docs . This page was last modified: 15 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Identity Resolution settings Connect a source Create an audience Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Identity Resolution Onboarding"
      },
      {
        "level": 3,
        "text": "Flat matching logic"
      },
      {
        "level": 2,
        "text": "Identity Resolution settings"
      },
      {
        "level": 3,
        "text": "Out-of-the-box"
      },
      {
        "level": 3,
        "text": "Custom rules"
      },
      {
        "level": 3,
        "text": "Importing from an existing space"
      },
      {
        "level": 2,
        "text": "Connect a source"
      },
      {
        "level": 2,
        "text": "Create an audience"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/segment-app/iam/",
    "title": " Identity & Access Management Overview | Segment Documentation",
    "content": "Home / Segment app / Identity & Access Management Overview Identity & Access Management Overview Free x Team x Business ✓ Add-on x ? Advanced Access Management is available for all Business plans. See the available plans , or contact Support . On this page Exporting a workspace’s user list Twilio Unified Login Quick links Segment’s access management tools let Workspace Owners manage which users can access different parts of their Segment workspaces. The Access Management page has three tabs: Users (team members) , User Groups , and Tokens . Access settings are applied at the workspace level. A Segment user can have access to one or more workspaces and can have different roles in each workspace.\nUsers access their Segment account with either email/password credentials, their Twilio credentials , or by using Single Sign On . Exporting a workspace’s user list Workspace Owners can download a CSV list of users who have access to a specific workspace (including their roles) from the Access Management page in the Segment app. You can select a user in the table to see their roles . Check out the Roles documentation for more details. Twilio Unified Login With Twilio Unified Login, Twilio users can use their Twilio email, password, and authentication settings to access several Twilio products, including Twilio Messaging, SendGrid, and Segment. You can also use Sign up With Google to create your Twilio account. Once you link your Segment account to your Twilio credentials, you can access Segment directly from the Twilio console using the Twilio Product Switcher . Twilio Sign Up Segment invitations and sign ups that are redirected to Twilio’s sign up page must adhere to Twilio’s minimum password and 2FA requirements . To learn more, view Twilio’s Account Management documentation. Any existing Segment user must adhere to existing password requirements and 2FA settings set at the Workspace level. Twilio Product Switcher You can access Segment from the Twilio Console using the Product Switcher. For more information, view the Twilio support article Getting Started with the Unified Login and Product Switcher . User settings Twilio Unified Login users can manage their Segment user settings, including name, email, password, and 2FA settings, directly in their Twilio account. To learn more about Twilio’s user and password policies, review Twilio’s Account Management documentation. Segment Users and SSO/SCIM Existing Segment users can still use their credentials to access Segment. Segment continues to support SSO and SCIM, as users who need to access an SSO enabled workspace will be directed to authenticate through the configured Identity Provider. Quick links Invite a team member to your workspace Create a User Group Update a team member’s access Remove a team member from a workspace Add a new user with Single Sign On Invite and manage workspace members Learn how to add members to your workspace, and manage their permissions. Organize Users with User Groups Learn manage workspace members in bulk. This page was last modified: 22 Feb 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Exporting a workspace’s user list Twilio Unified Login Quick links Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Identity & Access Management Overview"
      },
      {
        "level": 2,
        "text": "Exporting a workspace’s user list"
      },
      {
        "level": 2,
        "text": "Twilio Unified Login"
      },
      {
        "level": 3,
        "text": "Twilio Sign Up"
      },
      {
        "level": 3,
        "text": "Twilio Product Switcher"
      },
      {
        "level": 3,
        "text": "User settings"
      },
      {
        "level": 3,
        "text": "Segment Users and SSO/SCIM"
      },
      {
        "level": 2,
        "text": "Quick links"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/segment-app/iam/roles/",
    "title": " Roles | Segment Documentation",
    "content": "Home / Segment app / Iam / Roles Roles On this page Global Roles Business Tier Roles PII Access Roles for managing Engage destinations Roles for connecting resources Roles for Protocols Transformations Roles for Privacy Portal A role gives a user access to resources within a workspace. Roles are additive, and can combine to configure a custom policy for a Team Member or a Group. A policy is at least one role plus one resource applied to an individual user or group. When a user has both User Permissions and Group Permissions, they will have the highest access given to either of those roles. Global Roles All Segment workspaces have the following roles, regardless of account type. Role Details Workspace Owner Owners have full read and edit access to everything in the workspace, including sources, destinations, add-on products, and settings. Owners have full edit access to all team permissions. Workspace Member Members inherit custom permissions based on individual roles assigned. Source Admin Source admins have edit access to: - assigned source(s) - the settings for that source - any connected streaming destinations - Schema - live data from the source in the debugger - the source’s write key A user with the Source Admin role can get access to either all current and future sources, or a specific list of sources, or (if you’re on a Business plan) to sources with a specific Label. Source Admins can create new sources when the “All sources in Workspace including future sources” option is selected. Function Admin Function admins can create, edit and delete access to assigned function(s). When you assign a user the Functions Admin role, you can grant them access to either all current and future functions, or to a specific list of functions. Function Read-only The Function read-only role grants users the ability to read an assigned function(s). When you assign a user the Functions Read-only role, you can grant them access to either all current and future functions, or to a specific list of functions. Business Tier Roles The following roles are only available to Segment Business Tier accounts. End User Privacy Admin Edit access to End User Privacy Settings . Includes access to Data Privacy Agreement, and user suppression and deletion workflows. Scope: Grants access to only End User Privacy Settings in the App. Identity Admin Edit access to Identity settings in Unify. Scope: Grants access to all Identity settings. Source Read-only Read access to assigned source(s), source settings, connected streaming destinations, schema, transformations, and live data in the debugger. Reverse ETL sources are also included. Scope: Grants access to either: all current and future Sources, or only specific Sources, or Sources with a specific Label (BT only). Source Admin Edit access to assigned source(s), source settings, connected streaming destinations, schema, transformations, the source’s write key and live data in the debugger. Reverse ETL sources are also included. Scope: Grants access to either: all current and future Sources, or only specific Sources, or Sources with a specific Label (BT only). Unify and Engage Admin Edit access to Unify settings and if purchased, Engage Audiences, Traits, Journeys, Content, and settings. Scope: Grants access to either: all current and future Spaces, or a specific list of Spaces, or Spaces with a specific Label (BT only). Unify and Engage Read-only Read-only access to Unify settings and if purchased, Engage audiences, traits, journeys, and content. Cannot download PII or edit settings in Unify or Engage. Scope: Grants access to either: all current and future Spaces, or a specific list of Spaces, or Spaces with a specific Label (BT only). Unify Read-only, Engage User Read-only access to Unify settings and if purchased, edit access to Engage audiences, traits, journeys, and content. Cannot download PII or edit settings in Unify or Engage. Scope: Grants access to either: all current and future Spaces, or a specific list of Spaces, or Spaces with a specific Label (BT only). Tracking Plan Admin Edit access to all Tracking Plans in Protocols. Scope: Grants access to all Tracking Plans. Tracking Plan Read-only Read access to all Tracking Plans in Protocols. Scope: Grants access to all Tracking Plans. Warehouse Destination Admin Edit access to warehouse destinations and warehouse destination settings. (For example, Redshift, Postgres, BigQuery) Scope: Grants access to all warehouses. Warehouse Destination Read-only Read-only access warehouse destination and warehouse destination settings. (For example, Redshift, Postgres, BigQuery) Scope: Grants access to all warehouses. Entities Admin Full edit and view access to all entity models and connection details. Entities Read-only Read-only access, with the ability to view entity models. PII Access The Segment App doesn’t show detected Personally Identifiable Information (PII) to workspace members if the information matches specific expected formats for PII. When PII Access turns off , detected PII is masked based on red or yellow default matchers and any custom matchers defined in the Privacy Portal. Workspace Owners can grant specific individuals or groups access to PII from their Access Management settings. PII Access only applies to the resources a user or user group has access to; it doesn’t expand a user’s access beyond the original scope. All Workspace Owners have PII access by default. For example, users with PII Access and Source Admin/Read-Only permissions can view any PII present in the Source Debugger. However, users with the PII Access role don’t have Privacy Portal access. Only users with the Workspace Owner role can access the Privacy Portal. Roles for managing Engage destinations When managing destination connections in an Engage space, you may require additional permissions. Connecting or disconnecting destinations to Engage spaces: To allow a user to connect or disconnect destination instances to your Engage space, grant Unify and Engage Admin access for the specific Engage space, and Source Admin access for the source(s) linked to that Engage space, named Engage (space name) . Managing connections to Engage features (Computed Traits/Audiences/Journeys) : To allow a user to attach or detach a destination in your Engage space to specific Engage features like Audiences or Journeys, grant these users Unify and Engage Admin access on the selected Engage space. The Source Admin role is not necessary for this action. Roles for connecting resources To connect two resource instances, you must have access to both. You can either grant this access to all resources, or to the specific resources you want to connect. To connect a source to warehouse you must have Source Admin and Warehouse Admin access for the source and the warehouse. To connect source to tracking plan requires Source Admin and Tracking Plan Admin access for the source and the tracking plan. Roles for Protocols Transformations To view transformations, you need Source Read-only , either for all Sources or the specific Sources using Protocols. To create or edit transformations you must have either Source Admin for all Sources, or for the specific Sources used with Protocols. Roles for Privacy Portal The Privacy Portal is only accessible by Workspace owners . To view, create or edit any section of the Privacy Portal, you need to have the Workspace Owner role. This page was last modified: 13 Nov 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Global Roles Business Tier Roles PII Access Roles for managing Engage destinations Roles for connecting resources Roles for Protocols Transformations Roles for Privacy Portal Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Roles"
      },
      {
        "level": 2,
        "text": "Global Roles"
      },
      {
        "level": 2,
        "text": "Business Tier Roles"
      },
      {
        "level": 2,
        "text": "PII Access"
      },
      {
        "level": 2,
        "text": "Roles for managing Engage destinations"
      },
      {
        "level": 2,
        "text": "Roles for connecting resources"
      },
      {
        "level": 2,
        "text": "Roles for Protocols Transformations"
      },
      {
        "level": 2,
        "text": "Roles for Privacy Portal"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/segment-app/extensions/dbt/",
    "title": " dbt Extension | Segment Documentation",
    "content": "Home / Segment app / Extensions / dbt Extension dbt Extension On this page Before you begin Set up Git dbt Models and dbt Cloud Git Connections Setting Up CI checks Troubleshooting dbt Extensions Segment’s dbt extension lets you use Reverse ETL with your existing dbt labs models and syncs to help centralize model management and versioning, reduce redundancies, and run CI checks to prevent breaking changes. With Segment’s dbt extension, you can: Securely connect Segment to a Git repository that stores your dbt models. Use centralized dbt models to set up Reverse ETL. Trigger Reverse ETL syncs from dbt jobs. This page explains how to set up a dbt Model and then use the model with Reverse ETL. Before you begin Keep the following in mind as you set up the dbt extension: The extension supports dbt Core v1.7 . You can use Snowflake , Databricks , Redshift , Postgres , and BigQuery as Reverse ETL sources. dbt models aren’t synchronized from the dbt cloud. The model sync connects to a Git repository that loads models into Segment for use with Reverse ETL. You can connect to GitHub using a GitHub App, token, or SSH. For GitLab and Bitbucket , use SSH to connect. Set up Git dbt Models and dbt Cloud To set up the dbt extension, you’ll need: an existing dbt account with a Git repository for job syncs, dbt cloud with jobs already created Git repository and dbt Models setup Follow these steps to connect the Git repository that stores your dbt Models: In your Segment workspace, navigate to Settings > Extensions . Click Set up Git sync . On the Configure service credentials page, select a service and protocol, add your GitHub App, SSH private key or GitHub token, then click Next . In the Connect source window, select an existing Reverse ETL warehouse source from the dropdown, then click Save . After you’ve saved your setup, you can configure your Git repository’s settings to your needs by changing the repository, branch, dbt version, default schema, and project path. dbt Cloud setup You can also use dbt Cloud to schedule Reverse ETL syncs after a dbt Cloud job successfully runs. To set up dbt Cloud: In your Segment workspace, navigate to Settings > Extensions . Click Manage dbt Cloud . Add your dbt Cloud API key or dbt Personal Access Token and an optional custom subdomain, then click Save . Adding a custom subdomain By default, dbt sets the subdomain to cloud. To identify your custom subdomain, open your URL and copy the portion before .getdbt.com . For example, if your domain was https://subdomain.getdbt.com/ , your subdomain would be subdomain . dbt Cloud Webhooks The dbt Cloud integration allows you to schedule Reverse ETL syncs based on a dbt Cloud job.  When a dbt Cloud job is selected under the Reverse ETL scheduling section, Segment creates a webhook in the dbt Cloud account that will initiate to run the Reverse ETL sync when the job is scheduled. In order to create the webhook, ensure that you have webhook permissions associated with the dbt Cloud token in the previous step. Model syncs After you set up dbt, Segment runs an initial sync to load models from your connected Git repository. This initial sync lets you use the most recent models when you set up Reverse ETL. In addition to Segment’s initial dbt sync, you can also trigger manual dbt model syncs. Use a model with Reverse ETL After you’ve successfully set up dbt with a warehouse and connected to your Git repository, you can select dbt models for use with Reverse ETL by following these steps: In your Segment workspace, navigate to Connections > Sources and select the Reverse ETL tab. Click +Add Reverse ETL source , select your source, then click Add Model . Click dbt Models as your modeling method, then select and preview a model from the dbt model dropdown. Add a primary key, then click Preview your model . Click Next . Enter your Model Name , then click Create Model . To change a connected model, ensure that you’ve removed it from all active Reverse ETL syncs. Git Connections Git Connections enable Segment to sync data with your preferred Git repository through supported like SSH and token-based authentication. Git Sync and the dbt integration operate independently. You don’t need to set up Git Sync to use dbt, and dbt Cloud can trigger its own syncs without relying on Git Sync. Supported connection types Segment supports the following credential types for setting up a Git Connection: SSH : Compatible with GitHub, GitLab, and Bitbucket, SSH provides a secure method for connecting to your repository. Git token : Git tokens are supported across GitHub, GitLab, and Bitbucket, enabling token-based authentication for added flexibility. GitHub App : For GitHub users, GitHub App integrations offer enhanced security and functionality. This method is exclusive to GitHub and supports additional features, like CI checks . Reusing Git Connections Segment lets you set up multiple Git Connections, allowing you to reuse credentials across both dbt and Git Sync. You can either use the same credential for multiple configurations or create separate Git Connections for each product and environment as needed. If you plan to reuse a Git token across both dbt and Git Sync, ensure it has the necessary read and write permissions for both integrations. Setting Up CI checks CI check availability CI checks are available only with the GitHub App connection. CI checks in Segment help prevent breaking changes to active dbt models. Avoid changing dbt models currently in use with an active Reverse ETL sync, since changes could disrupt existing mappings and active syncs. When CI checks are enabled, Segment monitors model changes in your Git repository. If a model already linked to an active Reverse ETL sync gets modified, Segment automatically rejects the change to maintain data integrity. To enable CI Checks, authorize a GitHub App credential for your Git connection. Once connected, you can enable CI Checks in the dbt model sync configuration section. Troubleshooting dbt Extensions The following table lists common dbt Extension errors, as well as their solutions: Error Error message Solution Failed sync Sync Failed: Incorrect dbt Project File Path: dbt project file not found Verify that the path to your dbt_project.yml file is relative to the repository root, excluding the root branch. For example, use project/dbt_project.yml instead of main/project/dbt_project.yml . Failed sync Sync Failed: remote: Write access to repository not granted Verify that the account associated with the token has a write role in the repository settings. Fine-grained tokens may require specific roles, depending on your Git provider. This page was last modified: 11 Dec 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Before you begin Set up Git dbt Models and dbt Cloud Git Connections Setting Up CI checks Troubleshooting dbt Extensions Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "dbt Extension"
      },
      {
        "level": 2,
        "text": "Before you begin"
      },
      {
        "level": 2,
        "text": "Set up Git dbt Models and dbt Cloud"
      },
      {
        "level": 3,
        "text": "Git repository and dbt Models setup"
      },
      {
        "level": 3,
        "text": "dbt Cloud setup"
      },
      {
        "level": 3,
        "text": "dbt Cloud Webhooks"
      },
      {
        "level": 3,
        "text": "Model syncs"
      },
      {
        "level": 3,
        "text": "Use a model with Reverse ETL"
      },
      {
        "level": 2,
        "text": "Git Connections"
      },
      {
        "level": 3,
        "text": "Supported connection types"
      },
      {
        "level": 3,
        "text": "Reusing Git Connections"
      },
      {
        "level": 2,
        "text": "Setting Up CI checks"
      },
      {
        "level": 2,
        "text": "Troubleshooting dbt Extensions"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/data-graph/setup-guides/redshift-setup//",
    "title": " Redshift Data Graph Setup | Segment Documentation",
    "content": "Home / Unify / Data graph / Setup guides / Redshift Data Graph Setup Redshift Data Graph Setup Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Prerequisite Getting started Step 1: Roles and permissions Step 2: Create a database for Segment to store checkpoint tables Step 3: Grant read-only access for the Data Graph Step 4: Validate permissions Step 5: Connect your warehouse to Segment Update user access for Segment Reverse ETL dataset Redshift for Data Graph is in beta and Segment is actively working on this feature. Some functionality may change before it becomes generally available. This feature is governed by Twilio Segment’s First Access and Beta Preview Terms . Set up your Redshift data warehouse to Segment for the Data Graph . Prerequisite To use Linked Audiences with Redshift, the Data Graph only supports materialized views . If you’re setting up Profiles Sync for the first time in the Unify space, go through the setup flow for Selective sync. If Profiles Sync is already set up for your Unify space, follow these steps to configure Profiles Sync for your Unify space: Navigate to Unify > Profile Sync . Select the Settings tab and select Selective sync . Select all the tables under Profile raw tables . These include, external_id_mapping_updates , id_graph_updates , profile_traits_updates . Linked Audiences require Profile Sync to be configured such that both the Profile raw tables and the Profile materialized tables are synchronized with your Redshift instance. Select all of the tables under Profile materialized tables . These include profile_merges , user_traits , user_identifiers . This allows faster and more cost-efficient Linked Audiences computations in your data warehouse. Select Sync all Track Call Tables under Track event tables to enable filtering on event history for Linked Audiences conditions. Getting started You need to be an AWS Redshift account admin to set up the Segment Redshift connector as well as write permissions for the __segment_reverse_etl dataset. To get started with Redshift: Log in to Redshift and select the Redshift cluster you want to connect. Follow the networking instructions to configure network and security settings. Step 1: Roles and permissions Segment recommends you to create a new Redshift user and role with only the required permissions. Create a new role and user for the Segment Data Graph. This new role will only have access to the datasets you provide access to for the Data Graph. Run the SQL commands in your Redshift cluster: -- Create a user with role for the Data Graph CREATE ROLE SEGMENT_LINKED_ROLE ; CREATE USER SEGMENT_LINKED_USER PASSWORD \"your_password\" ; GRANT ROLE SEGMENT_LINKED_ROLE TO SEGMENT_LINKED_USER ; Step 2: Create a database for Segment to store checkpoint tables Segment recommends you to create a new database for the Data Graph. If you choose to use an existing database that has also been used for Segment Reverse ETL , you must follow the additional instructions to update user access for the Segment Reverse ETL schema. Provide write access to the database as Segment requires this in order to create a schema for internal bookkeeping and to store checkpoint tables for the queries that are executed. Segment recommends you to create a new database for this purpose. This is also the database you’ll be required to specify for the Database Name when connecting Redshift with the Segment app. Run the following SQL commands in your Redshift cluster: -- Create and Grant access to a Segment internal DB used for bookkeeping CREATE DATABASE SEGMENT_LINKED_PROFILES_DB ; GRANT CREATE ON DATABASE SEGMENT_LINKED_PROFILES_DB TO ROLE SEGMENT_LINKED_ROLE ; Step 3: Grant read-only access for the Data Graph Grant the Segment role read-only access to additional schemas you want to use for the Data Graph including the Profiles Sync database. To locate the Profile Sync database, navigate to Unify > Profiles Sync > Settings > Connection Settings . You will see the database and schema name. Schemas Grant schema permissions based on customer need. See Amazon’s docs to view schema permissions and example commands that you can use to grant permissions. Repeat the following SQL query for each schema you want to use for the Data Graph. -- ********** REPEAT THE SQL QUERY BELOW FOR EACH SCHEMA YOU WANT TO USE FOR THE DATA GRAPH ********** GRANT USAGE ON SCHEMA \"the_schema_name\" TO ROLE SEGMENT_LINKED_ROLE ; Table Grant table permissions based on your needs. Learn more about Amazon’s table permissions . Table permissions can either be handled in bulk: -- query data from all tables in a schema GRANT SELECT ON ALL TABLES IN SCHEMA \"the_schema_name\" TO ROLE SEGMENT_LINKED_ROLE ; Or in a more granular fashion if needed: -- query data from a specific table in a schema GRANT SELECT ON TABLE < schema - name > . < table - name > TO ROLE segment_linked_role ; Step 4: Validate permissions To verify you have set up the right permissions for a specific table, log in with the username and password you created for SEGMENT_LINKED_USER and run the following command to verify the role you created has the correct permissions. If this command succeeds, you should be able to view the respective table. SHOW SCHEMAS FROM DATABASE \"THE_READ_ONLY_DB\" ; SELECT * FROM \"THE_READ_ONLY_DB.A_SCHEMA.SOME_TABLE\" LIMIT 10 ; Step 5: Connect your warehouse to Segment To connect your warehouse to Segment: Navigate to Unify > Data Graph . This should be a Unify space with Profiles Sync already set up. Click Connect warehouse . Select Redshift as your warehouse type. Enter your warehouse credentials. Segment requires the following settings to connect to your Redshift warehouse: Host Name: The Redshift URL Port: The Redshift connection port Database: The only database that Segment requires write access to in order to create tables for internal bookkeeping. This database is referred to as segment_linked_profiles_db in the SQL above. Username: The Redshift user that Segment uses to run SQL in your warehouse. This user is referred to as segment_linked_user in the SQL above. Password: The password of the user above Test your connection, then click Save . Update user access for Segment Reverse ETL dataset If Segment Reverse ETL ran in the project you are configuring as the Segment connection project, a Segment-managed dataset is already created, and you need to provide the new Segment user access to the existing dataset. Run the following SQL if you run into an error on the Segment app indicating that the user doesn’t have sufficient privileges on an existing __segment_reverse_etl : -- If you want to use an existing database that already has Segment Reverse ETL schemas, you’ll need to run some additional steps below to grant the role access to the existing schemas. GRANT USAGE , CREATE , DROP ON SCHEMA segment_connection_db . __segment_reverse_etl TO ROLE SEGMENT_LINKED_ROLE ; GRANT SELECT , INSERT , UPDATE , DELETE , DROP ON ALL TABLES IN SCHEMA segment_connection_db . __segment_reverse_etl TO ROLE SEGMENT_LINKED_ROLE ; This page was last modified: 10 Dec 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Prerequisite Getting started Step 1: Roles and permissions Step 2: Create a database for Segment to store checkpoint tables Step 3: Grant read-only access for the Data Graph Step 4: Validate permissions Step 5: Connect your warehouse to Segment Update user access for Segment Reverse ETL dataset Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Redshift Data Graph Setup"
      },
      {
        "level": 2,
        "text": "Prerequisite"
      },
      {
        "level": 2,
        "text": "Getting started"
      },
      {
        "level": 2,
        "text": "Step 1: Roles and permissions"
      },
      {
        "level": 2,
        "text": "Step 2: Create a database for Segment to store checkpoint tables"
      },
      {
        "level": 2,
        "text": "Step 3: Grant read-only access for the Data Graph"
      },
      {
        "level": 3,
        "text": "Schemas"
      },
      {
        "level": 3,
        "text": "Table"
      },
      {
        "level": 2,
        "text": "Step 4: Validate permissions"
      },
      {
        "level": 2,
        "text": "Step 5: Connect your warehouse to Segment"
      },
      {
        "level": 2,
        "text": "Update user access for Segment Reverse ETL dataset"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/getting-started/01-what-is-segment/",
    "title": " How Segment Works | Segment Documentation",
    "content": "Home / Getting started / How Segment Works How Segment Works On this page Overview Sources for collecting data How you can track data The Segment Methods Where you can send data In a nutshell, the Segment libraries ( Sources ) generate messages about what’s happening in your site or app, and send them to the Segment servers. Segment then translates the content of those messages into different formats for use by other tools (which Segment calls Destinations ), and sends the translated messages to those tools. The Segment servers also archive a copy of the data, and can send data to your storage systems (such as databases, warehouses, or bulk-storage buckets). Overview Segment Spec methods are how you collect interaction data from your interfaces, and the Sources are what you package with your interfaces to collect and route the data. Once you’ve collected your interaction data, there are several different actions you can take: Send it to Destinations , which receive the data from any number of sources in real time Send it to Warehouses and other bulk storage tools, which hold your raw event schemas and update on regular intervals Enrich the customer data you collect by connecting data from your other tools , and then collect it in a warehouse to monitor performance, inform decision-making processes, and create uniquely customized user experiences. Use Engage , Twilio’s marketing automation tool, to build marketing campaigns personalized to your audience. Sources for collecting data You can collect data by implementing Segment’s tracking libraries as your Sources: Analytics.js , the Segment JavaScript source, is the most powerful way to track customer data from a website. Segment recommends it as the default installation for any website. The Segment Mobile SDKs are the best way to simplify tracking in your iOS, Android, and Xamarin apps. Segment recommends them over server-side sources as the default installation for any mobile app. Server-side sources let you send analytics data directly from your servers when client-side tracking doesn’t work, or when you’re sending mission-critical data like revenues. Sources for unique cases Segment also offers these other source libraries to cover less straightforward cases: Use the HTTP Tracking API if Segment doesn’t offer a library for your specific environment yet. The Pixel Tracking API lets you track events from environments where you can’t execute code - for example, tracking when an email was opened. The Querystring API lets you use querystrings to load API methods when a user first visits a Segment-enabled site. Use this API for tracking events like email clicks and identifying users associated with those clicks on the destination page. Cloud App Sources Segment also offers Cloud App Sources to integrate data from your third-party tools: Object Cloud Sources can import third party tool data directly into your Segment warehouse, but can’t stream that data into your other Segment destinations. Make sure you enable a Segment warehouse before you enable an object cloud source. Event Cloud Sources don’t just import third party tool data into your Segment warehouse, they also send event data in real-time to your other Segment destinations. You don’t need to set up a data warehouse to send Event Cloud Source data to your destinations. How you can track data Segment supports several ways to implement tracking. The two most common are to use device-based or server-based libraries. You can use Segment’s device-based libraries, such as JavaScript, iOS, and Android, to make calls on users’ browsers or mobile devices. You can also track data with Segment’s server-based libraries, such as Node, Python, or PHP, where the calls are triggered on your own servers and then sent to the Segment servers. When you collect data using device-based libraries, you can choose between these two different connection modes: Cloud-mode is where the library sends the data directly to the Segment servers which then translate and forward it. Device-mode is where the library sends the data both directly to the Segment servers, and also to the servers for the destination tool. Device-mode sometimes requires some additional set-up steps , but can unlock rich device data. Although there are some tradeoffs between the two approaches, neither is better than the other, and Segment recommends that you implement a mix of both. In general, more direct interaction data is available using a device-based library, but server-based collection is more secure, reliable, and can’t be blocked by ad blockers. The Segment Methods The Segment libraries generate messages about what happens on your interface, translate those messages into different formats for use by destinations, and transmit the messages to those tools. There are several tracking API methods , that you can call to generate messages. The four most important methods are: Identify : Who is the user? Page and Screen : What web page or app screen are they on? Track : What are they doing? Every call shares the same common fields . When you use these methods as intended , it allows Segment to detect a specific type of data and correctly translate it to send it on to downstream destinations. Where you can send data Segment maintains a catalog of destinations where you can send your data. back Getting Started Overview next A simple Segment installation Walk through a disposable, demo implementation. This page was last modified: 21 Apr 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Overview Sources for collecting data How you can track data The Segment Methods Where you can send data Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "How Segment Works"
      },
      {
        "level": 2,
        "text": "Overview"
      },
      {
        "level": 2,
        "text": "Sources for collecting data"
      },
      {
        "level": 3,
        "text": "Sources for unique cases"
      },
      {
        "level": 3,
        "text": "Cloud App Sources"
      },
      {
        "level": 2,
        "text": "How you can track data"
      },
      {
        "level": 2,
        "text": "The Segment Methods"
      },
      {
        "level": 2,
        "text": "Where you can send data"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/storage/warehouses/redshift-faq/",
    "title": " Redshift cluster and Redshift connector limitations | Segment Documentation",
    "content": "Home / Connections / Storage / Warehouses / Redshift cluster and Redshift connector limitations Redshift cluster and Redshift connector limitations On this page Reserved words Table count limitations Cluster node limitations Column type changes VARCHAR size limits Blocklisted track call properties “Are there limitations of Redshift clusters and our Redshift connector?” While Redshift clusters are incredibly scalable and efficient, limitations are imposed to ensure that clusters maintain performance. Reserved words Redshift does not allow you to create tables or columns using reserved words. To avoid naming convention issues, we prepend a _ to any reserved word names. If you’re having trouble finding a column or table, you can check the list of Redshift reserved words or search for the table with a prepended underscore like _open . Table count limitations Redshift sets the maximum number of tables you can create in a cluster to 9,900 including temporary tables. While it’s rare to reach that limit, we recommend keeping an eye on the number of tables our warehouse connector is creating in your cluster. Keep in mind that a new table is created for each unique event you send to Segment, which becomes an issue if events are being dynamically generated. Cluster node limitations When setting up your Redshift cluster, you can select between dense storage (ds2) and dense compute (dc1) cluster types. Dense compute nodes are SSD based which allocates only 200GB per node, but results in faster queries. Dense storage nodes are hard disk based which allocates 2TB of space per node, but result in slower queries. When scaling up your cluster by adding nodes, it’s important to remember that adding more nodes will not add space linearly. As you add more dc1 nodes, the amount of preallocated space for each table increases. For example, if you have a table with 10 columns, Redshift will preallocate 20mb of space (10 columns X 2 slices) per node. That means that the same table will preallocate 20mb of space in a single ds2 cluster, and 200mb in a 10 node dc1 cluster. Column type changes Like with most data warehouses, column data types (string, integer, float, etc.) must be defined at the time the column is created. Unlike most data warehouses, Redshift does not allow for easy column type changes after the column has been created. Additionally, we store a record of what the tables and column types should be set to in a local database, and validate the structure on each connector run. Currently, column type changes (i.e. change an integer column to float) are only available to our business tier customers on an ad-hoc basis. VARCHAR size limits All Segment-managed schemas have a default VARCHAR size of 512 in order to keep performance high. If you wish to increase the VARCHAR size, you can run the following query. ALTER TABLE table_name ALTER COLUMN column_name column_type ; Example: ALTER TABLE segment_prod . identifies ALTER COLUMN account_id TYPE VARCHAR ( 1024 ); Increasing the default size can impact query performance as it needs to process more data to accomodate the increased column size. See Amazon’s Redshift Documentation for more details. Blocklisted track call properties While almost all event properties are valid, we are unable to pass through properties that have naming conflicts with the default key/value pairs included in a standard raw JSON call. For example, if you send through a property in a track call named “timestamp” or “event”, it will cause a conflict and you likely wont see it appear in your warehouse. To be more specific, if you send the following track call, {‘event’:’birthday’} will likely be dropped when syncing the data to your data warehouse. analytics.track('selected gift', {'event':'birthday', 'type':'cake'}) This page was last modified: 11 Mar 2021 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Reserved words Table count limitations Cluster node limitations Column type changes VARCHAR size limits Blocklisted track call properties Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Redshift cluster and Redshift connector limitations"
      },
      {
        "level": 2,
        "text": "Reserved words"
      },
      {
        "level": 2,
        "text": "Table count limitations"
      },
      {
        "level": 2,
        "text": "Cluster node limitations"
      },
      {
        "level": 2,
        "text": "Column type changes"
      },
      {
        "level": 2,
        "text": "VARCHAR size limits"
      },
      {
        "level": 2,
        "text": "Blocklisted track call properties"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/how-to-guides/measure-advertising-funnel/",
    "title": " Measuring Your Advertising Funnel | Segment Documentation",
    "content": "Home / Guides / How to guides / Measuring Your Advertising Funnel Measuring Your Advertising Funnel On this page Measuring Campaign Performance How does this impact my ad reporting? What if I need more precise tracking? Estimating the Impact of Moving Server-side It’s surprisingly hard to answer questions about the ROI of your ad campaigns. What does a click actually result in? How much should I pay for it? We built our Sources for Facebook Ads and Google Adwords to help you understand the true performance and cost of your campaigns. In this article, we dig into the nuances of data collection and potential gotchas around measuring clicks, pageviews, and ultimately, conversions. Measuring Campaign Performance Today, most marketing teams think about their paid acquisition funnel as three major steps… This makes sense when looking at overall campaign performance, but hides several crucial funnel steps that can make the difference between increasing a campaign’s spend and shutting it off due to poor results. Because page optimization and ad blockers can impact measurement of your funnel, it’s important to look at the four additional steps happening between the ad click and conversions. Let’s go through each true funnel step in a little more detail. Impressions & Clicks: When a user views an ad, the ad platform increments the count of impressions for that ad. When an ad is clicked, the ad platform logs a click. This is all handled by the ad platform’s servers. Facebook and Google work hard to filter invalid and fraudulent traffic, whether that’s a mistaken click, a bot, or a competitor looking to drain your advertising budget. Any bad traffic is removed from both your reporting and your monthly bill. Page Request Initiated: After an ad is clicked, a user’s browser attempts to load your landing page. This request is the first contact your application has with the user, and the server responds with the content to render the landing page. First JavaScript Loaded: The user’s browser starts to download the landing page content, which includes the HTML, JavaScript, and CSS. The browser parses and renders this content, loading the JavaScript sequentially as it parses the page. By default, analytics.js uses the async tag , which means that the browser won’t block the page and will load analytics.js once everything else is ready. Analytics.js wants to get out of the way where possible so you can create the best experience for your customers. Page Fully Rendered: The page is fully rendered once all the html, css and scripts have been loaded on the page. This time can vary a lot based on the speed of the internet connection (how fast all the assets download) and the device itself (how fast the local computer can run all of the scripts). Third-Party Scripts Loaded: Finally, third-party scripts are asynchronously loaded onto the page. The speed at which these scripts are loaded depends on a variety of factors, like the page size, network speed, and the size and number of the third-party scripts. Once these scripts are loaded, analytics.js triggers a page call to our API. Conversion Event: From there, a user might fill out a form, signup, or buy your product! How does this impact my ad reporting? There are three less-obvious contributors to fall-off across the paid acquisition funnel: slow loads, ad blockers, and bounces. For the sake of illustration, this means that if you have 100 ad clicks, you will be able to count most but not all corresponding page views because some visitors may bounce (exit or hit the back button) before analytics.js is executed. Similarly, you may miss some attributable conversions due to slow load times (your page calls can’t fire in time) and ad blockers (which often block analytics not just ads). Here’s how it works. Slow Loads Slow loads can impact your attribution modeling, making campaigns appear to have worse performance than reality. In the general case, when a user hits your landing page, your tracking code loads and triggers a pageview event that you can use to attribute that user to a campaign. But if third-party scripts take on the order of seconds to load (for example, on 1x or 3G networks), users may click off the page before your tracking code executes. In this case, the pageview never gets recorded and your ability to attribute that click to a conversion is lost. This is generally not an issue for most companies because they are focused more on people who spend a good deal of time on their pages. However, it is a potential source of opaqueness, particularly for users with slow or bad network connection. Bounces Bounces can occur at any stage of the funnel between an ad being clicked and third-party scripts loading on the page. Some bounces are not tracked because the user doesn’t even last the few seconds to request your HTML, render it, and execute tracking. If they quickly hit back or close the browser window, your ad platform will report clicks that don’t show up in your analytics tracking. Ad blockers It is likely the case that some percentage of your users are using ad blockers. It’s estimated that 22% of mobile smartphones worldwide and 16% of US web traffic use ad blockers. Segment customers have reported ad blockers for as little as a few percentage points of their visitors, to upwards of 70% of traffic for companies with very tech-forward audiences. But just because a user is using ad blockers doesn’t mean that they aren’t seeing and clicking on ads. Facebook recently announced that they would be suppressing ad blockers , and Adblock Plus, the most popular ad blocking and anti-tracking software, categorizes Google Search ads as acceptable ads . That said, many ad blockers do block analytics tools like Google Analytics, Mixpanel and Segment. This means that there exists some percentage of your conversions that actually came through your paid acquisition channels, but are unattributable due to ad blockers. What if I need more precise tracking? Segment offers two ways of joining your user clickstream data to your paid acquisition channels: standard client-side tracking or advanced server-side page calls. Both options come with their own tradeoffs that are important to consider for your use case. Client-side Tracking (Standard) Analytics.js is loaded with the async tag by default, which means that the library and all it’s destinations are loaded near the end of the page rendering. The benefit is that analytics.js doesn’t slow down page loads, but it does mean that tracking is not executed immediately on page load. When you use standard client-side tracking, you’ll lose pageview data for visitors who bounce or click off the page before analytics.js executes, and for visitors with ad blockers enabled. Server-side Page Calls (Advanced) If you want to capture adblock, bounce, and slow load traffic, we recommend adding an additional page() call to the server-side. This allows you avoid the browser altogether and see the total number of requests emanating from your paid acquisition channels. You’ll get visibility on an extra step in that funnel. The general approach is to use an arbitrary anonymousId (e.g. a UUID) in the server-side page() call and then also set the anonymousId as the ajs_anonymous_id cookie in the browser. You can read more about how to implement that here. This approach is tricky to implement, so we recommend that this is undertaken only for use cases in which bounce and/or adblock data is critical. Estimating the Impact of Moving Server-side If you want to get a quick estimate for the number of additional clicks you’d track using server-side tracking, you can use “redirect tracking” with a URL shortener to estimate the number of clicks coming from Google Adwords or Facebook Ads. This will give you an estimate for the number of times an ad is clicked (minus some bounce in the few hundred milliseconds of the redirect), which will closely match server-side page() tracking should you choose to implement it. Here’s how it works… Use a URL shortener like bit.ly to link to a landing page, with a custom parameter like ?ttg=2 . Add the shortened link to your ad. Measure total clicks from the bit.ly stats page. In your warehouse, count the number of pages with that unique url parameter from step 1 (make sure you’re looking at the same timeframe). select received_at , url from < site > . pages where url like '%/warehouses%' and search like '%ttg=2' order by received_at We hope this overview helps explain the technical nuances of measuring what happens when a customer finds you using an ad! If you have any other questions, feel free to share them in the Segment Community for discussion. This page was last modified: 21 Apr 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Measuring Campaign Performance How does this impact my ad reporting? What if I need more precise tracking? Estimating the Impact of Moving Server-side Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Measuring Your Advertising Funnel"
      },
      {
        "level": 2,
        "text": "Measuring Campaign Performance"
      },
      {
        "level": 2,
        "text": "How does this impact my ad reporting?"
      },
      {
        "level": 2,
        "text": "What if I need more precise tracking?"
      },
      {
        "level": 2,
        "text": "Estimating the Impact of Moving Server-side"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/profiles-sync/profiles-sync-setup/databricks-profiles-sync/",
    "title": " Databricks for Profiles Sync | Segment Documentation",
    "content": "Home / Unify / Profiles sync / Profiles sync setup / Databricks for Profiles Sync Databricks for Profiles Sync Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Getting started Set up Databricks for Profiles Sync Connect your Databricks warehouse Set up selective sync With Databricks for Profiles Sync, you can use Profiles Sync to sync Segment profiles into your Databricks Lakehouse. Getting started Before getting started with Databricks Profiles Sync, note the following prerequisites for setup. The target Databricks workspace must be Unity Catalog enabled. Segment doesn’t support the Hive metastore. Visit the Databricks guide enabling the Unity Catalog for more information. Segment creates managed tables in the Unity catalog. Segment supports only OAuth (M2M) for authentication. Warehouse size and performance A SQL warehouse is required for compute. Segment recommends a warehouse with the the following characteristics: Size : small Type Serverless otherwise Pro Clusters : Minimum of 2 - Maximum of 6 To improve the query performance of the Delta Lake, Segment recommends creating compact jobs per table using OPTIMIZE following Databricks recommendations . Segment recommends manually starting your SQL warehouse before setting up your Databricks destination. If the SQL warehouse isn’t running, Segment attempts to start the SQL warehouse to validate the connection and may experience a timeout when you hit the Test Connection button during setup. Set up Databricks for Profiles Sync From your Segment app, navigate to Unify > Profiles Sync . Click Add Warehouse . Select Databricks as your warehouse type. Use the following steps to connect your warehouse . Connect your Databricks warehouse Use the five steps below to connect to your Databricks warehouse. To configure your warehouse, you’ll need read and write permissions. Step 1: Name your schema Pick a name to help you identify this space in the warehouse, or use the default name provided. You can’t change this name once the warehouse is connected. Step 2: Enter the Databricks compute resources URL You’ll use the Databricks workspace URL, along with Segment, to access your workspace API. Check your browser’s address bar when inside the workspace. The workspace URL should resemble: https://<workspace-deployment-name>.cloud.databricks.com . Remove any characters after this portion and note the URL for later use. Step 3: Enter a Unity catalog name This catalog is the target catalog where Segment lands your schemas and tables. Follow the Databricks guide for creating a catalog . Be sure to select the storage location created earlier. You can use any valid catalog name (for example, “Segment”). Note this name for later use. Select the catalog you’ve just created. Select the Permissions tab, then click Grant . Select the Segment service principal from the dropdown, and check ALL PRIVILEGES . Click Grant . Step 4: Add the SQL warehouse details from your Databricks warehouse Next, add SQL warehouse details about your compute resource. HTTP Path : The connection details for your SQL warehouse. Port : The port number of your SQL warehouse. Step 5: Add the service principal client ID and client secret Segment uses the service principal to access your Databricks workspace and associated APIs. Service principal client ID : Follow the Databricks guide for adding a service principal to your account . This name can be anything, but Segment recommends something that identifies the purpose (for example, “Segment Profiles Sync”).  Segment doesn’t require Account admin or Marketplace admin roles. The service principal needs the following setup: Catalog-level privileges which include: USE CATALOG USE SCHEMA MODIFY SELECT CREATE SCHEMA CREATE TABLE Databricks SQL access entitlement at the workspace level. CAN USE permissions on the SQL warehouse that will be used for the sync. Client secret : Follow the Databricks instructions to generate an OAuth secret . Once you’ve configured your warehouse, test the connection and click Next . Set up selective sync With selective sync, you can choose exactly which tables you want synced to the Databricks warehouse. Segment syncs materialized view tables as well by default. Select tables to sync, then click Next . Segment creates the warehouse and connects databricks to your Profiles Sync space. You can view sync status, and the tables you’re syncing from the Profiles Sync overview page. Learn more about using selective sync with Profiles Sync. This page was last modified: 03 Jun 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Getting started Set up Databricks for Profiles Sync Connect your Databricks warehouse Set up selective sync Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Databricks for Profiles Sync"
      },
      {
        "level": 2,
        "text": "Getting started"
      },
      {
        "level": 3,
        "text": "Warehouse size and performance"
      },
      {
        "level": 2,
        "text": "Set up Databricks for Profiles Sync"
      },
      {
        "level": 2,
        "text": "Connect your Databricks warehouse"
      },
      {
        "level": 3,
        "text": "Step 1: Name your schema"
      },
      {
        "level": 3,
        "text": "Step 2: Enter the Databricks compute resources URL"
      },
      {
        "level": 3,
        "text": "Step 3: Enter a Unity catalog name"
      },
      {
        "level": 3,
        "text": "Step 4: Add the SQL warehouse details from your Databricks warehouse"
      },
      {
        "level": 3,
        "text": "Step 5: Add the service principal client ID and client secret"
      },
      {
        "level": 2,
        "text": "Set up selective sync"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/getting-started/implementation-guide/",
    "title": " Getting Started Guide | Segment Documentation",
    "content": "Home / Getting started / Getting Started Guide Getting Started Guide On this page Basics Instrumentation Optimization Welcome to Segment! This doc mirrors Segment’s in-product guide, and walks you through each of the tasks to level up your workspace strength and become familiar with Segment. The guide is broken into three categories of tasks: Basics : These tasks allow you to send and debug your first data through Segment. Instrumentation : These tasks allow you to send additional types of data (track & identify) and give you an introduction to creating a data strategy. Optimization : These tasks guide you to expand your data coverage and optimize your workspace. Basics The tasks included in Basics help you send and debug your very first data from a Source (a library that sends data to Segment), and into a Destination (tools you use to analyze or act on your data). The Basic tasks include: Invite teammates Add a Source Add page or screen tracking Add a Destination Testing and Debugging Invite Teammates Segment allows you to invite team members to your workspace. To decide who on your team should be added to Segment, think about who might be responsible for implementing, owning, or using your data in downstream tools. For example, as a developer, you might invite: Marketing colleagues to inform what data might be needed to power campaigns or better understand conversion metrics, A data scientist or analyst to help inform data strategy and property structuring, Product managers to help debug data flow, and to connect product analytics tools To invite team members to your workspace: Go to Settings > Workspace Settings and click the Access Management tab. Click + Invite Team Member . Enter the email addresses of the team members you want to invite separated by a comma. (Optional) You can choose to Add Members to User Groups so that members inherit roles from user groups, or Add Individual Roles to bulk assign individuals roles to all invites. Click Invite . Add a Source A Source is a website, server library, mobile SDK, or cloud application which can send data into Segment. It’s where your data originates. Add a Source to collect data to understand who your customers are and how they’re using your product. Create a source for each website or app you want to track. To add a Source: Go to Connections . Click Add Source . Click the Source you’d like to add. Note: More than 80% of workspaces start by adding their JavaScript website. Click Add Source . Enter a name for your source as well as any information on the setup page. Click Add Source . Learn More What is a Source? Create a Source Sources Catalog Add page or screen tracking Once you’ve added your Segment Source, you’re ready to send data into Segment. The simplest data to send into Segment is a Page call (for website Sources) or Screen call (for mobile Sources). Page and screen calls send automatically once you install the Segment snippet or SDK on your website or mobile app. Page and screen calls allow you to record whenever a user sees a page of your website or screen of your app, along with any optional properties about the page or screen. Learn how to install the Segment snippet or SDK on your website or mobile app to start sending data. Learn More Install Segment Spec: Page Spec: Screen Add a Destination Destinations are the business tools or apps that Segment forwards your data to. Adding Destinations allow you to act on your data and learn more about your customers in real time. To add a Destination: Navigate to Connections . Click Add Destination . Choose the Destination you want to add and click Configure . Most users eventually add destinations for: Analytics, Advertising, Email Marketing, and/or Live Chat. Select the Source you want to connect to your Destination. Click Next . Give your Destination a name. Click Save . Configure the settings and enable your destination on the destination settings page. Learn More Sending data to destinations Destination compatibility Destination connection modes Testing and Debugging The Source Debugger is a real-time tool that helps you validate that API calls made from your website, mobile app, or servers arrive at your source. You can use the Source Debugger to make sure that your source functions properly and your events actively send. The Debugger shows a live stream of events that flow through your Segment Source, so that you can check that your events send in the correct format. When you click on a specific event, you’ll be able to see these two views of an event: The Pretty view is a recreation of the API call you made that was sent to Segment. The Raw view is the complete JSON object Segment receives from the calls you send. These calls include all the details about what is tracked: timestamps, properties, traits, ids, and contextual information Segment automatically collects the moment the data is sent. To access your Source Debugger: Navigate to Connections > Sources and choose your source. Click on the Debugger tab. Learn More Testing and Debugging Using the Source Debugger Segment University: Testing and Debugging Instrumentation The tasks in this phase help you create a data strategy and send additional types of data (identify and track calls) to get a clearer picture of who your users are and what actions they’re taking. The Instrumentation tasks include: Basics Invite Teammates Add a Source Add page or screen tracking Add a Destination Testing and Debugging Instrumentation Send an Identify call Send a Track call Choose what to track Event anatomy and naming standards Add a data warehouse Add more destinations Optimization Add more sources Add a cloud source Explore Protocols Explore Engage Send an Identify call The Identify call allows you to tie a user to their actions and record traits about them. It includes a unique User ID and any optional traits you know about the user, like their email, name, and address. Sending an Identify call is your first step towards understanding who your users are. An example of the types of details you might want to learn and track about your users in an Identify call are: Name Email Address Company Lifetime Value Learn More Spec: Identify Plan your identify and group calls Segment University: Identify Send a Track call The Segment Track call allows you to record any actions your users perform, along with any properties that describe the action. Sending a track call is your first step towards understanding what your users are doing. Each action that a user takes is known as an event. Each event has a name and properties. For example, the User Registered event might have properties like plan or accountType . To save time on instrumentation, be sure to check if one of Segment’s Business Specs meets your needs. Learn More Spec: Track Best practices for event calls Analytics Academy: The anatomy of a track call Segment University: The Track Method Choose what to track Segment recommends you to create and maintain a Tracking Plan to have data clarity and team alignment about what customer data you need to collect and why. It’s best to think about the measurable business outcomes you’re trying to track or improve, and then drill down to track the events needed for each business outcome. For example, if you’re looking to reduce cart abandonment, you may want to engage cart abandoners by sending emails and in-app messaging to them using Customer.io and Intercom. You also might want to track events like Product Added or Cart Viewed along this customer journey. Segment maintains a number of industry or product-specific specs to help you get started: B2B Ecommerce Video Mobile Learn More Data Collection Best Practices Analytics Academy: How to create a successful data tracking plan Segment University: Planning your implementation Event anatomy and naming standards When it comes to data collection, the best way to set your company up for success is to establish consistent naming conventions. This makes your code easier to read, and it helps everyone at your company understand what your events mean. Segment recommends the best practice of using an “Object Action” (Noun Verb) naming convention for all Track events (for example, Menu Clicked) and using noun_noun snake case for property names (for example, property_name). You can view all the event names you’re currently tracking in the Schema view to ensure you’re using consistent conventions and casing. To view your event names in the Source Schema: Navigate to Connections > Sources . Click on the Source you want to view. Click on the Schema tab.\nYour event names are listed in the table. Learn More Event naming best practices Analytics Academy: Naming conventions for clean data Add a data warehouse A data warehouse is a central location where you can store your raw customer data from multiple sources. A data warehouse gives you flexibility to query your data, which allows you to answer analytical questions that may not be possible with a standard analytics tool. A data warehouse also allows you to collect and compile data from third party tools as Cloud Sources in Segment, to help you gain a 360 view of your customer touchpoints. Learn More What’s a warehouse? Warehouse FAQs Analytics Academy: Why you should own your data Add more destinations Adding more destinations allows you to connect all your business tools to run through Segment. This gives you the confidence that they are all acting on the same data. Most users connect a variety of marketing, advertising, product, and analytics tools. With all your tools acting on the same set of customer data, you can personalize your customer engagement and deliver a consistent message across multiple channels To add more destinations: Navigate to Connections . Click Add Destination . Choose the Destination you want to add and click Configure . Most users eventually add destinations for: Analytics, Advertising, Email Marketing, and/or Live Chat. Select the Source you want to connect to your Destination. Click Next . Give you Destination a name. Click Save . Configure the settings and enable your destination on the destination settings page. Repeat steps 1-7 for each destination you want to add. Learn More Segment Blog: Recipes Automating Multi-Channel Re-Engagement Campaigns Optimization The tasks in this phase help you to optimize your Segment implementation and take it to the next level. The optimization tasks include: Add more sources Add a cloud source Explore Protocols Explore Engage Add more sources Adding any additional data sources that you might have, like a mobile app, marketing website, server, or cloud tool will give you a more complete view of your customer.\nEach touchpoint you have with your customers is a potential area to gain a better understanding of them. To add more sources: Go to Connections . Click Add Source . Click the Source you’d like to add. Click Add Source . Enter a name for your source as well as any information on the setup page. Click Add Source . Repeat steps 1-6 for all the other sources you want to add. Learn More Tracking users across channels and devices Sources catalog Add a cloud source Cloud sources allow you to pull in customer data from third-party tools (like Twilio or Stripe) into a data warehouse for complex querying. Consolidating your customer data enables you to eliminate data silos to get a single view of your customer. Before adding a cloud source, you need to make sure you: Get cloud source credentials. Get warehouse credentials. Choose your preferred sync time. Once you have the necessary credentials, to add a cloud source: Navigate to Connections and click Add Source . Click on the cloud source you want to add and click Add Source . Give your cloud source a name and click Authenticate . Enter your credentials or log in using OAuth. Enable the source. Navigate to Connections > Destinations and select your warehouse. On the Settings tab of your warehouse, enter the credentials for your warehouse if you don’t already have one connected to Segment. Learn More Cloud sources Comparing Cloud Sources Explore Protocols Protocols automate and scale the data quality best practices developed over years of helping users implement Segment. Investing in data quality improves trust in your data, reduces time spent by your engineering and business teams navigating and validating data, and allows your business to grow faster. There are steps to take when you use Protocols: Align teams with a Tracking Plan Validate data quality with violations Enforce data standards with controls Resolve data issues with transformations Learn More Protocols Overview Protocols FAQs Intro to Protocols Explore Engage Engage is a powerful personalization platform that enables you to create unified customer profiles in Segment, to build and enrich audiences, and to activate audiences across marketing tools. Engage allows you to enrich user profiles with custom traits, allowing you to create granular audiences for campaigns, advertising, and analysis. This page was last modified: 24 Jan 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Basics Instrumentation Optimization Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Getting Started Guide"
      },
      {
        "level": 2,
        "text": "Basics"
      },
      {
        "level": 3,
        "text": "Invite Teammates"
      },
      {
        "level": 3,
        "text": "Add a Source"
      },
      {
        "level": 3,
        "text": "Add page or screen tracking"
      },
      {
        "level": 3,
        "text": "Add a Destination"
      },
      {
        "level": 3,
        "text": "Testing and Debugging"
      },
      {
        "level": 2,
        "text": "Instrumentation"
      },
      {
        "level": 3,
        "text": "Send an Identify call"
      },
      {
        "level": 3,
        "text": "Send a Track call"
      },
      {
        "level": 3,
        "text": "Choose what to track"
      },
      {
        "level": 3,
        "text": "Event anatomy and naming standards"
      },
      {
        "level": 3,
        "text": "Add a data warehouse"
      },
      {
        "level": 3,
        "text": "Add more destinations"
      },
      {
        "level": 2,
        "text": "Optimization"
      },
      {
        "level": 3,
        "text": "Add more sources"
      },
      {
        "level": 3,
        "text": "Add a cloud source"
      },
      {
        "level": 3,
        "text": "Explore Protocols"
      },
      {
        "level": 3,
        "text": "Explore Engage"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/identity-resolution/",
    "title": " Identity Resolution Overview | Segment Documentation",
    "content": "Home / Unify / Identity Resolution Overview Identity Resolution Overview Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Identity Graph Highlights Technical highlights FAQs Identity Graph Identity Resolution sits at the core of Segment. The Identity Graph merges the complete history of each customer into a single profile, no matter where they interact with your business. Identity Resolution allows you to understand a user’s interaction across web, mobile, server, and third-party partner touch-points in real time, using an online and offline ID graph with support for cookie IDs, device IDs, emails, and custom external IDs. If you are sending the Group call , you can also understand user behavior at the account-level. Highlights Supports existing data — no additional code or set up required Supports all channels — stitches web + mobile + server + third party interactions into the same user Supports anonymous identity stitching — by merging child sessions into parent sessions Supports user:account relationships - for B2B companies, generates a graph of relationships between users and accounts Real-time performance - reliable real-time data stream merges with minimal latency Technical highlights Supports custom external IDs - bring your own external IDs Customizable ID Rules — allows you to enforce uniqueness on select external IDs and customize which external IDs and sources cause associations Merge Protection - automatically detects and solves identity issues, like non-unique anonymous IDs and the library problem using the priority trust algorithm Maintains persistent ID - multiple external IDs get matched to one persistent ID FAQs Can I use the Profile API on the client-side? For security reasons, Segment requires that the Profile API only be used server-side. The Profile API allows you to look up data about any user given an identifier (for example, email, anonymousId , or userId ) and an authorized access secret. While this enables powerful personalization workflows, it could also let your customers’ data fall into the wrong hands if the access secret were exposed on the client. Instead, by creating an authenticated personalization endpoint server-side backed by the Profile API, you can serve up personalized data to your users without the risk of their information falling into the wrong hands. This page was last modified: 22 Nov 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Identity Graph Highlights Technical highlights FAQs Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Identity Resolution Overview"
      },
      {
        "level": 2,
        "text": "Identity Graph"
      },
      {
        "level": 2,
        "text": "Highlights"
      },
      {
        "level": 2,
        "text": "Technical highlights"
      },
      {
        "level": 2,
        "text": "FAQs"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/segment-vs-tag-managers/",
    "title": " Segment vs. Tag Managers | Segment Documentation",
    "content": "Home / Guides / Segment vs. Tag Managers Segment vs. Tag Managers Tag managers, also known as Tag Management Systems (TMS), were a popular solution before the mainstream adoption of mobile apps. They primarily helped Digital Analytics and Online Marketers manage web tags or “beacons” on a website. Built on an older technology, tag managers inject either a piece of JavaScript or an ad pixel into a website. They carry out rules that marketers create for each tag, like firing an ad channel pixel when that network refers a website visitor. Every tag requires users to create rules. No data is stored, and no code is eliminated. In addition to ad networks, today’s data-driven businesses use a variety of tools to optimize their product and marketing spends. In order to a/b test copy, nurture sales leads, email customers, and provide fast support, businesses integrate variety of analytics and marketing tools. Segment makes it easy to install, try, and use them all. Tag managers primarily focus on ad networks, and can’t support modern tools without extensive customization. Rather than “firing and forgetting,” Segment takes a data-centric, deliberate approach to destinations. You don’t need to set up special parameters for each tool – Segment does that for you. Segment structures your data so we can understand what it is, and can translate it correctly for each destination we send it to.  Segment works because all of these tools operate on the same customer data: who is on your app and what are they doing. Segment collects this data once, then translates and sends it to every tool you use. Because Segment also archives the data, Segment can replay your historical data into new tools, and send your raw data to a data storage solution for later analysis. Segment Tag Managers Core Competency Integrates complex tools with minimal effort, stores a complete copy of clickstream data, exports data to SQL databases Loads JavaScript into webpages, inserts advertising pixels based on rule settings Data Storage Stores clickstream data in one comprehensive set; replays historical data into new tools; exports data into SQL databases and internal systems Does not store data; cannot load historical data into new tools; cannot translate and load historical data into SQL databases Device Compatibility Tracks user events in mobile, web, and server environments. Server libraries include Python, Node, Ruby, PHP, .NET, Java, Clojure, Go, Rust and Xamarin Operates on web; limited functionality on mobile; does not support server destinations User Interface Delivers sleek user experience; automatically translate data for new tools when you enable a destination Requires that you configure settings and rules for each pixel to fire Tool Integrations Fully integrates analytics, advertising, email, customer support, marketing automation, usability tracking, error testing, and CRM tools with the flick of a switch Manages ad pixels; requires custom engineering work to integrate any other complex tool Every organization’s data stack and business requirements are unique. Segment also works well in tandem with a tag manager. For example, Segment sends data directly to the Google Tag Manager (GTM) destination . While you can use Segment’s Analytics.js library through a tag manager, Segment doesn’t recommended this for a few reasons: A hybrid approach makes it difficult to determine the root cause of technical problems, and complicates troubleshooting. Segment cannot guarantee destination compatibility in a “hybrid” Segment-tag-manager installation, and cannot guarantee support on these installations. All QA and regression testing assumes a native installation of Analytics.js on the page. One of Segment’s main charters is to not lose data. Our system and cloud infrastructure is designed to ensure that data loss does not happen. If you implement the entry point of data capture (Segment’s libraries) using a Tag Manager, you introduce risk of data loss and make it difficult or impossible to troubleshoot. This implementation behind a tag manager can introduce major delays and performance issues, which can cause delays with events that need to occur early in your funnel. The biggest challenge is around triggering cascading events. Browsers are notorious for dropping calls. When you use a TMS to initiate Segment events you are introducing a second point of failure for those events. This page was last modified: 16 Feb 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Segment vs. Tag Managers"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/how-to-guides/",
    "title": " How to Guides Index | Segment Documentation",
    "content": "Home / Guides / How to Guides Index How to Guides Index On this page Implementation Engagement and Automation Analytics Quickstart Guides Segment’s How-to Guides provide an in-depth walk through and examples of the many things you can do to implement, automate, engage with, and begin analyzing your data. We’ve also got a series of Quickstart Guides for each of our Source libraries. Implementation What are best practices for identifying users? Should I collect data on the client or server? How do I collect page views on the server side? How do I import historical data? How do I join user profiles? How do I migrate code from other analytics tools? Engagement and Automation What role does Segment play in Attribution? How do I automate multi-channel re-engagement campaigns? How do I create a push notification? How do we track customers across channels and devices? How do I set up a dynamic coupon program to reward loyal customers? How do we set up event-triggered notifications or alerts? Analytics How do I forecast Long Term Value with SQL and Excel for e-commerce? How do I measure my advertising funnel? How do I measure the ROI of my Marketing Campaigns? Quickstart Guides Analytics.js (Javascript) Quickstart Guide .NET Quickstart Guide Go Library Quickstart Guide Python Library Quickstart Guide Java Library Quickstart Guide PHP Library Quickstart Guide Node.js Library Quickstart Guide Ruby Library Quickstart Guide iOS Quickstart Guide Android Quickstart Guide This page was last modified: 25 Apr 2022 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Implementation Engagement and Automation Analytics Quickstart Guides Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "How to Guides Index"
      },
      {
        "level": 2,
        "text": "Implementation"
      },
      {
        "level": 2,
        "text": "Engagement and Automation"
      },
      {
        "level": 2,
        "text": "Analytics"
      },
      {
        "level": 2,
        "text": "Quickstart Guides"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/spec/semantic/",
    "title": " Spec: Semantic Events | Segment Documentation",
    "content": "Home / Connections / Spec / Spec: Semantic Events Spec: Semantic Events One of the core components of the Segment Spec is the Track call. It describes any arbitrary event that the user has triggered. For some industry verticals and applications, Segment has standardized event names. For Ecommerce tracking, for example, there are specific event names and properties that we recognize semantically. This semantic meaning allows Segment to specially recognize and transform key events before sending them off to each different tool. There are a few places where Segment has standardized event names and properties already: Mobile A/B Testing Ecommerce Email Live Chat Video In the future Segment plans to standardize event names from other data sources as well. This page was last modified: 21 Nov 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Spec: Semantic Events"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/spec/mobile-packaging-sdks/",
    "title": " Packaging SDKs for Mobile Destinations | Segment Documentation",
    "content": "Home / Connections / Spec / Packaging SDKs for Mobile Destinations Packaging SDKs for Mobile Destinations When it comes to Mobile SDKs, we know that minimizing size and complexity is a priority for our customers. That’s why our core Mobile SDKs are small and offload as much work as possible in handling destinations to our servers. When you install our light-weight SDK, you have access to our entire suite of server-side destinations. Why do some destinations require bundling their SDKs? We bundle certain SDKs, instead of just proxying your data to them through our servers, so that you have access to their deeper features that requires direct client manipulation (A/B testing, user surveys, touch heatmapping, etc) or access to rich data such as CPU usage, network data, or raised exceptions. For those types of features, we still need to bundle their native SDK for you so you can make the most of them. We’ve worked hard to make our mobile SDKs as modular as possible so that you only need to include the SDKs for tools you plan to use. Custom builds allow us to offer the native functionality of all of our destinations without having to include hefty third-party SDKs by default. This gives you control over size and method bloat. Check out how to use custom builds for both Android and iOS . Which SDKs are bundled? To check if a destination is bundled or not, take a look at our documentation for that specific destination. This page was last modified: 14 Jul 2021 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Packaging SDKs for Mobile Destinations"
      },
      {
        "level": 3,
        "text": "Why do some destinations require bundling their SDKs?"
      },
      {
        "level": 3,
        "text": "Which SDKs are bundled?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/destinations/",
    "title": " Destinations Overview | Segment Documentation",
    "content": "Home / Connections / Destinations Overview Destinations Overview On this page Sources vs Destinations Destination connection types Method compatibility Source compatibility Destination Actions Connection modes Sync modes Add a destination Data deliverability IP Allowlisting Destinations are the business tools or apps that Segment forwards your data to. Adding Destinations allow you to act on your data and learn more about your customers in real time. Destinations Catalog If you want to explore the destinations compatible with Segment, check out the Destinations catalog . Select an item from the catalog to learn more about it. The documentation for each destination explains how the Segment Tracking API methods are implemented for that destination. Sources vs Destinations Segment has Sources and Destinations . Sources send data into Segment, while Destinations receive data from Segment. Destination connection types Segment has three destination connection types: Event streams Storage Reverse ETL Event streams destinations Event streams destinations are all destinations that aren’t storage or Reverse ETL destinations. Adding these destinations allow you to act on your data and learn more about your customers in real time. These include Destination Actions . Storage destinations Storage destinations enable you to store your raw Segment data. This enables data analysts and data scientists to work with the raw data to derive deeper and more customized insights to support your organization. Learn more from the storage overview page . Reverse ETL destinations Reverse ETL destinations are the business tools or apps you use that Segment syncs the data from your warehouse to. If your destination is not listed in the Reverse ETL catalog , use the Segment Connections destination to send data from your Reverse ETL warehouse to other destinations listed in the catalog . The Segment Connections destination enables you to mold data extracted from your warehouse in Segment Spec API calls that are then processed by Segment’s HTTP Tracking API . The Segment HTTP Tracking API lets you record analytics data. The requests hit Segment’s servers, and then Segment routes your data to any destination you want. Get started with the Segment Connections destination . Method compatibility Not all destinations can accept data from specific method types. To know if a destination can accept data from specific method types, look for the Quick Info box at the top of the destination’s documentation page, or check out the Destinations Methods comparison chart . Source compatibility Many destinations can accept data from all types of sources, but some are only compatible with specific source types (for example, web only, or server only). To find out which source types a specific destination can accept data from, check the documentation for that destination in the Quick info box, or in the Supported Sources and Connection Modes section. Destinations Compatibility Matrix Wondering which destinations take which data? Check out the Destination connection modes list by category. Destination Actions In June 2021, Segment released a new form of destinations called Destinations Actions . These destinations allow users to create subscriptions : sets of conditions in which data is sent to the destinations and data mappings, to format that data for the destination tool. Segment watches for data that matches the conditions you create ( triggers ) for the subscription, and when the conditions are met, uses an explicit mapping to transform the incoming data to an output format that your destination can use. Connection modes Segment’s web source (Analytics.js), and native client-side libraries (iOS, Android, React-native) allow you to choose how you send data to Segment from your website or app. There are two ways to send data: Cloud-mode : The sources send data directly to the Segment servers, which then translate it for each connected downstream destination, and send it on. Translation is done on the Segment servers, keeping your page size, method count, and load time small. Healthcare and Life Sciences (HLS) customers can encrypt data flowing into their destinations HLS customers with a HIPAA eligible workspace can encrypt data in fields marked as Yellow in the Privacy Portal before they flow into an event stream, cloud-mode destination. To learn more about data encryption, see the HIPAA Eligible Segment documentation Device-mode : You include additional code on your website or mobile app which allows Segment to use the data you collect on the device to make calls directly to the destination tool’s API, without sending it to the Segment servers first . (You still send your data to the Segment servers, but this occurs asynchronously.) This is also called wrapping or bundling , and it might be required when the source has to be loaded on the page to work, or loaded directly on the device to function correctly. When you use Analytics.js, you can change the device-mode destinations that a specific source sends from within the Segment web app, without touching any code. If you use Server source libraries, they only send data directly to Segment in Cloud-mode. Server library implementations operate in the server backend, and can't load additional destination SDKs. Choosing a connection mode Cloud-mode destinations send data through Segment. Device-mode destinations send data in parallel to Segment. There are tradeoffs between using cloud-mode and device-mode destinations. In general, Cloud-mode is preferred because you then benefit from Segment’s system features, like retries, Replay, Warehouses, Privacy blocking, filtering, and more. You should consider using device-mode if you use destinations which record information directly on the user’s device. These types of tools might lose functionality if they aren’t loaded directly on the device. Take a look at the pros and cons chart of device-mode and cloud-mode destinations to determine which connection mode is best for you: Connection Mode Pros Cons Cloud-mode * Increased site or app performance * Unaffected by ad blockers * May limit Destination features Device-mode * Access to all features of the Destination * Decreased site or app performance Website source connection modes Segment’s website sources use device-mode by default, because so many website-based destinations require that they be loaded on the page, and because size and page performance are less of a concern than on mobile. If your website source only collects information that you can instrument yourself, then you can use cloud-mode. For example, a web-chat destination must be loaded to connect to the service and collect metrics efficiently - you don’t expect it to route chat messages through Segment! This does mean that Segment might not receive a small amount of the destination-specific information from your users. In the chat example, if the destination is calculating idle time between messages, that data would appear in the destination’s tooling, but not necessarily in the Segment data. Mobile source connection modes By default, destinations configured on a mobile source send their data directly to the Segment servers, then translate it and use Cloud-mode to forward it to destinations. Cloud-mode means that Segment sends the data directly from the Segment servers, to their servers. This means you don’t need to package third-party SDKs for destinations that can accept cloud-mode data. Some primarily web-based destinations also allow cloud-mode, which can help reduce app size, and improve load time and performance. You can read more about the effects of mobile app size on downloads in Segment’s blog . Before you turn on or opt-in for cloud-mode for a mobile source, consider if your destinations have features that require interactions on the device or require device-specific data (see the examples above). For example, if you use cloud-mode for Mixpanel, you’ll get your data on reporting and people, but won’t be able to use their features for in-app surveys or auto-tracking. These can be really valuable, but might not be a priority for your team. How Segment determines Device-mode and Cloud-mode destinations There are two main things Segment considers when deciding to use Device-mode or Cloud-mode, or both, for a destination partner: Anonymous Attribution Methodology Client-native Destination Features Anonymous attribution methodology Mobile attribution The anonymous identifiers used on mobile devices are usually static, which means Segment doesn’t need to do additional resolution, and can build Cloud-mode destinations by default. Because Segment uses native advertising identifiers on mobile devices, you don’t need a full SDK on the device to reconcile or identify a user. For example, you might track users who viewed an advertisement in one app and installed another app as a result. However, some mobile attribution tools do more advanced reconciliation based on more than the native identifier, which requires the SDK on the device to work properly. For those destinations, Segment offers device-mode, which packages the tool’s SDK with the client-side library so that you can get the entire range of tool functionality. Web Attribution Cross-domain identity resolution for websites requires that the attribution tool use a third-party cookie so it can track a user anonymously across domains. This is a critical component of attribution modeling. As a matter of principle, Segment only uses first-party cookies and doesn’t share cookies with partners, so Analytics.js and the data it collects aren’t enough to generate view-through attribution in ad networks. Customers can load their libraries and pixels in the context of the browser and trigger requests to attribution providers from their device in response to Segment API calls to take advantage of advertising and attribution tools. Client-native destination features Many of Segment’s destinations offer client-side features beyond data collection in their SDKs and libraries, for both mobile and web. In these cases, Segment offers Device-mode SDKs so that you can collect information on the device using Segment, but still get the destination’s complete native functionality. Some features that usually require Device-mode include: automatic A/B testing, displaying user surveys, live chat or in-app notifications, touch and hover heatmapping, and accessing rich device data such as CPU usage, network data, or raised exceptions. How can I tell which connection modes and platforms are supported for a destination? The first place to look is the individual destination documentation. Each one includes a matrix of supported Sources and Connection Modes. Segment provides a list of all destinations and their connection modes . In order to override the default, check the destination settings pane in the Segment web App either for a Connection Mode toggle or instructions on bundling any additional mobile components required. Sync modes Sync modes allow users to define how changes in the source should send downstream to your destination. Depending on which destinations you set up in Segment, you may need to choose a sync mode for your data. This configuration determines how Segment updates your destination based on the source data. The available sync modes can vary based on the destination, integration type, and actions within the destination. For example, if you sync customer data, you might have the option to Insert, Update, or Upsert records. Available sync modes include: Update : Modify existing records in the destination without adding new ones. Upsert : Update existing records and add new ones, if necessary. Add : Add records to a list, segment, or journey. Remove : Remove records from a list, audience, or journey. Add a destination To add a Destination: Navigate to Connections . Click Add Destination . Choose the Destination you want to add and click Configure . Most users eventually add destinations for: Analytics, Advertising, Email Marketing and/or Live Chat. Select the Source you want to connect to your Destination. Click Next . Give you Destination a name. Click Save . Configure the settings and enable your destination on the destination settings page. Learn more about what adding a destination entails. Disabled destinations do not receive data If you haven’t enabled your destination for the first time after you created it or if you actively disable a destination, Segment prevents any data from reaching the destination. Business Tier customers can request a Replay , which resends data from the time the destination was disabled to the time it was re-enabled. Replays can also send data to currently disabled destinations. Some destinations are not compatible with Replays after a certain period of time, for example, 14 days. Check with Segment’s support team friends@segment.com to confirm that your intended destination allows historical timestamps. Data deliverability Segment increases deliverability to destinations using retries and replays . Retries happen automatically for all customers, while replays are available on request for Business Tier customers. Segment’s data flow is primarily unidirectional, from Segment to integrated destinations. Segment does not inherently support a bidirectional flow where events, once delivered and processed by a destination, are sent back to Segment. Segment also uses batching to increase deliverability to your destinations. Some destinations have batching enabled by default, and some, like Segment’s Webhook (Actions) Destination , let you opt in to batching. Some cases of event batching might lead to observability loss While batching does increase event deliverability, you might experience error amplification, as if the entire batch fails, all events will be marked with the same status. For example, if a batch fails due to one 429 (Rate Limit) error, it might appear in the UI that there was one 429s request failure for each item in the batch. Retries Retries in Segment’s client libraries Segment’s client libraries ensure delivery of your data to the API reliably in the face of spotty connections, device failure, or network partitions in your data centers. When you use Segment’s mobile SDK, Segment dispatches each event to a background thread where the event is then written to a queue. Later, Segment’s SDK batches together many requests in to one compressed request and sends it to Segment’s servers. Segment’s SDKs minimize battery use and bandwidth use by powering up the radio less frequently and for shorter time periods. If the delivery of the payload is not successfully sent due to connection issues, all of your SDKs will automatically retry the request until successful receipt of the payload according to the following policies. Note that retry policies are subject to change / tuning in the future. Platform Initial Wait - Sleep duration before the first retry Wait Growth - Rate of growth of the sleep duration between each retry Max Wait - Maximum sleep duration between retries Max Attempts - Maximum number of individual retries C++ 1s None 1s 5 Clojure 15s Exponential 1h 50 Go 100ms Exponential 10s 10 Java 15s Exponential 1h 50 JavaScript 1s Exponential 1h 10 .Net 100ms Exponential 6.4s 7 Node.js 100ms Exponential 400ms 3 PHP 100ms Exponential 6.4s 7 Python 1s Exponential 34m 10 Ruby 100ms Exponential 10s 10 Mobile library retries All mobile libraries handle retries by periodically attempting to flush their internal queue of events to Segment. If the flush is unsuccessful, the library waits until the next regularly-scheduled flush time to try again. The background queue of requests to Segment is bounded in size so if events are being queued faster than we can successfully flush them to Segment, some events may be dropped. Retries between Segment and destinations The destination endpoint APIs have fluctuations in availability due to a number of issues ranging from network failures to bugs to overload. Segment’s internal systems retry failed destination API calls for four hours with a randomized exponential backoff after each attempt. This substantially improves delivery rates. Here’s an example destination that was only successfully accepting 93.36% of all API requests but was achieving a 99.28% final deliverability rate due to Segment’s retry functionality. You can see the current destination endpoint API success rates and final delivery rates for Segment’s server-side destinations on Segment’s status page . Replays Replay is available to Business tier customers. Contact Segment to learn more. Replays allow customers to load historical data from Segment’s S3 logs into downstream destinations which accept cloud-mode data. So, for example, if you wanted to try out a new email or analytics tool, Segment can replay your historical data into that tool. This gives you a great testing environment and prevents data lock-in when vendors try to hold data hostage. If you submitted suppress_only requests , Segment still retains historical events for those users, which can be replayed. If you do not want historical events replayed for suppressed users, submit suppress_and_delete requests instead. Batching Segment uses stream batching for all destinations that require near-realtime data and bulk batching for some data flows in our pipeline. Stream batching For all destinations, except for non-realtime Engage syncs and Reverse ETL syncs, Segment processes events from your source as they arrive and then flows the data downstream to your destinations in small batches, in a process called stream batching . These batches might contain different events between retry attempts, as events in previous batches may have succeeded, failed with a permanent error, or expired. This variability reduces the workload the system processes during partial successes, allows for better per-event handling, and reduces the chance of load-related failures by using variable batch formations. Bulk batching Some data flows may be able to use a process called bulk batching , which supports batching for destinations that produce between several thousand and a million events at a time. Real-time workloads or using a Destination Insert Function may prevent bulk batches from being formed. Batches contain the same events between retries. The following destinations support bulk batching: DV360 Google Adwords Remarketing Lists Klaviyo (Actions) Pinterest Audiences Snapchat Audiences LiveRamp The Trade Desk CRM You must manually configure bulk batches for Actions destinations To support bulk batching for the Actions Webhook destination, you must set enable-batching: true and batch_size: >= 1000 . IP Allowlisting IP Allowlisting uses a NAT gateway to route traffic from Segment’s servers to your destination through a limited range of IP addresses, which can prevent malicious actors from establishing TCP and UDP connections with your integrations. IP Allowlisting is available for customers on Business Tier plans. Supported destinations Segment supports IP Allowlisting in all destinations except for the following: LiveRamp TradeDesk Amazon Kinesis Destinations that are not supported receive traffic from randomly assigned IP addresses. Configure IP Allowlisting To enable IP Allowlisting for your workspace: From your Segment workspace, navigate to Settings > Workspace settings > Destination IP settings . On the Destination IP settings page, click Enable IP allowlisting . The page displays the IP address ranges that Segment uses to route data from Segment’s internal systems to your destination. Note these ranges, as you’ll need this information to enforce IP restriction in your downstream destinations. Open each of your downstream tools and configure IP restriction for each destination. For more information, refer to the documentation for your downstream tool. IP restriction might not be supported in all destinations. This page was last modified: 04 Dec 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Sources vs Destinations Destination connection types Method compatibility Source compatibility Destination Actions Connection modes Sync modes Add a destination Data deliverability IP Allowlisting Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Destinations Overview"
      },
      {
        "level": 2,
        "text": "Sources vs Destinations"
      },
      {
        "level": 2,
        "text": "Destination connection types"
      },
      {
        "level": 3,
        "text": "Event streams destinations"
      },
      {
        "level": 3,
        "text": "Storage destinations"
      },
      {
        "level": 3,
        "text": "Reverse ETL destinations"
      },
      {
        "level": 2,
        "text": "Method compatibility"
      },
      {
        "level": 2,
        "text": "Source compatibility"
      },
      {
        "level": 2,
        "text": "Destination Actions"
      },
      {
        "level": 2,
        "text": "Connection modes"
      },
      {
        "level": 3,
        "text": "Choosing a connection mode"
      },
      {
        "level": 3,
        "text": "How Segment determines Device-mode and Cloud-mode destinations"
      },
      {
        "level": 3,
        "text": "How can I tell which connection modes and platforms are supported for a destination?"
      },
      {
        "level": 2,
        "text": "Sync modes"
      },
      {
        "level": 2,
        "text": "Add a destination"
      },
      {
        "level": 2,
        "text": "Data deliverability"
      },
      {
        "level": 3,
        "text": "Retries"
      },
      {
        "level": 3,
        "text": "Replays"
      },
      {
        "level": 3,
        "text": "Batching"
      },
      {
        "level": 2,
        "text": "IP Allowlisting"
      },
      {
        "level": 3,
        "text": "Supported destinations"
      },
      {
        "level": 3,
        "text": "Configure IP Allowlisting"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/storage/warehouses/warehouse-syncs/",
    "title": " Warehouse Syncs | Segment Documentation",
    "content": "Home / Connections / Storage / Warehouses / Warehouse Syncs Warehouse Syncs On this page Sync Frequency Sync History Warehouse Selective Sync Instead of constantly streaming data to the warehouse destination, Segment loads data to the warehouse in bulk at regular intervals. Before the data loads, Segment inserts and updates events and objects, and automatically adjusts the schema to make sure the data in the warehouse is inline with the data in Segment. When Segment loads data into your warehouse, each sync goes through two steps: Ping: Segment servers connect to your warehouse. For Redshift warehouses, Segment also runs a query to determine how many slices a cluster has. Common reasons a sync might fail at this step include a blocked VPN or IP, a warehouse that isn’t set to be publicly accessible, or an issue with user permissions or credentials. Load: Segment de-duplicates the transformed data and loads it into your warehouse. If you have queries set up in your warehouse, they run after the data is loaded into your warehouse. Warehouses sync with all data coming from your source. However, Business plan members can manage the data that is sent to their warehouses using Selective Sync . Sync Frequency Your plan determines how frequently data is synced to your warehouse. Plan Frequency Free Once a day (every 86,400 seconds) Team Twice a day (every 43,200 seconds) Business* Up to 24 times a day. Generally, these syncs are fixed to the top of the hour (:00), but these times can vary. *If you’re a Business plan member and would like to adjust your sync frequency, you can do so using the Selective Sync feature. To enable Selective Sync, please go to Warehouse > Settings > Sync Schedule . Why can't I sync more than 24 times per day? We do not set syncs to happen more than once per hour (24 times per day). The warehouse product is not designed for real-time data, so more frequent syncs would not necessarily be helpful. Sync History You can use the Sync History page to see the status and history of data updates in your warehouse. The Sync History page is available for every source connected to each warehouse. This page helps you answer questions like, “Has the data from a specific source been updated recently?” “Did a sync completely fail, or only partially fail?” and “Why wasn’t this sync successful?” The Sync History includes the following information: Sync Status : The possible statuses are: Success : The sync run completed without any notices and all rows synced, OR no rows synced because no data was found. Partial : The sync run completed with some notices and some rows synced. Failure : The sync run completed with some notices and no rows synced. Start Time : The time at which the sync began. This is shown in your local timezone. Duration : The length of time the sync took. Synced Rows : Number of rows successfully synced from the sync run. Notices : A list of errors or warnings found, which could indicate problems with the sync run. Click a notice message to show details about the result, and any errors or warnings for each collection included in the sync run. If a sync run shows a partial success or failure, the next sync attempts to sync any data that was not successfully synced in the prior run. View the Sync History To view the Sync History: Go to Connections > Destinations and choose the warehouse destination you want to view the sync history for. Click the source you want to view the sync history for. (Optional) Click on any of the rows in the Sync History table to see additional details related to that sync. You can view: The Results of your sync which shows the number of rows synced for each collection. The Sync Duration which shows the Preparation and Loading times of your sync. Warehouse Selective Sync Warehouse Selective Sync allows you to manage the data that you send to your warehouses. You can use this feature to stop syncing specific events (also known as collections) or properties that aren’t relevant, and may slow down your warehouse syncs. This feature is only available to Business Tier customers. You must be a Workspace Owner to change Selective Sync settings. With Selective Sync, you can customize which collections and properties from a source are sent to each warehouse. This helps you control the data that is sent to each warehouse, allowing you to sync different sets of data from the same source to different warehouses. NOTE: This feature only affects warehouses , and doesn’t prevent data from going to any other destinations . When you disable a source, collection or property, Segment no longer syncs data from that source. Segment won’t delete any historical data from your warehouse. When you re-enable a source, Segment syncs all events since the last sync. This doesn’t apply when a collection or property is re-enabled. Only new data generated after re-enabling a collection or property will sync to your warehouse. For each warehouse only the first 5,000 collections per source and 5,000 properties per collection are visible in the Selective Sync user interface. Learn more about the limits . Disabling the received_at column will cause your syncs to fail, as all tables use received_at as the sort key. When to use Selective Sync By default, all sources and their collections and properties are sent, and no data is prevented from reaching warehouses. When you disable sources, collections, or properties using Selective Sync, Segment stops sending new data for these sources, collections, or properties to your warehouse. It doesn’t delete any existing data in the warehouse. If you choose to re-enable a source to begin syncing again, Segment loads all data that arrived since the last sync into the warehouse, but doesn’t backfill data that was omitted while these were disabled. When a collection or property is re-enabled, data only syncs going forward. It will not be loaded from the last sync. Enable Selective Sync To use Selective Sync: Go to Connections > Destinations and select the warehouse you want to enable Selective Sync for. Click the Settings tab and click Selective Sync in the left menu. Select which sources, collections, and properties to sync. All that is not selected won’t be synced to your warehouse. Click Save Changes . Change sync settings to a single warehouse from multiple sources To change the sync settings to a single warehouse from multiple sources, follow the same steps as above . This may be valuable if you’re looking to make changes in bulk, such as when setting up a new warehouse. Change sync settings on a specific Warehouse to Source connection To manage data from one specific source to an individual warehouse: Go to Connections > Destinations and select the warehouse you want to change the sync settings for. On the Warehouse Overview page, click the Schema you want to change the sync settings for. On the Settings tab of the Sync History page for that source, select the data you want synced to your warehouse, or deselect the data you don’t want synced. This may be valuable when you’re making smaller changes, for example, disabling all properties from one unnecessary collection. All changes made through Selective Sync only impact an individual warehouse. They don’t impact multiple warehouses at once. To make changes to multiple warehouses, you need to enable/disable data for each individual warehouse. Selective Sync User Interface Limits Regardless of schema size, for each warehouse only the first 5,000 collections per source and 5,000 properties per collection can be managed using the Selective Sync user interface. After you hit any of these limits, all future data is still tracked and sent to your warehouse. New collections created after hitting this limit is not displayed in the Selective Sync table. You will see a warning in the Selective Sync user interface when the warehouse schema has reached 80% of the limit for collections and/or properties. An error message will appear when you’ve reached the limit. Contact Support to edit Selective Sync settings for any collections and/or properties which exceed the limit. Only Workspace Owners can change Selective Sync settings. This page was last modified: 20 Mar 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Sync Frequency Sync History Warehouse Selective Sync Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Warehouse Syncs"
      },
      {
        "level": 2,
        "text": "Sync Frequency"
      },
      {
        "level": 2,
        "text": "Sync History"
      },
      {
        "level": 3,
        "text": "View the Sync History"
      },
      {
        "level": 2,
        "text": "Warehouse Selective Sync"
      },
      {
        "level": 3,
        "text": "When to use Selective Sync"
      },
      {
        "level": 3,
        "text": "Enable Selective Sync"
      },
      {
        "level": 3,
        "text": "Change sync settings to a single warehouse from multiple sources"
      },
      {
        "level": 3,
        "text": "Change sync settings on a specific Warehouse to Source connection"
      },
      {
        "level": 3,
        "text": "Selective Sync User Interface Limits"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/filtering-data/",
    "title": " Filtering your Segment Data | Segment Documentation",
    "content": "Home / Guides / Filtering your Segment Data Filtering your Segment Data On this page Filtering with the Integrations Object Destination filters Per-Source schema integrations filters Schema event filters Protocols Tracking Plan blocking and property omission Destination Insert Function Warehouse Selective Sync Privacy Portal filtering There are many ways you can use Segment to filter event and object based data to control which destinations it reaches. This document lists the most commonly used ways you can filter data in Segment, and explains when you’d use each. Filtering with the Integrations Object The Integrations object is the only filtering method that cannot be edited using the Segment web app. As such, it is both the most reliable, and the most complicated filtering option to change. The integrations object is available to all customers regardless of Segment plan. Use this option when you absolutely, for sure, 100% know that you always , or never want this data in a specific destination or set of destinations. You can also build logic in your app or site to conditionally enable or disable destinations by rewriting this object, however this is not recommended as it is time consuming to change, especially for mobile apps. The Integrations object filters track , page , group , identify , and screen events from both client and cloud based sources, and routes or prevents them from getting to the listed destinations. You can use the integrations JSON object as part of your Segment payloads to control how Segment routes your data to specific destinations. An example payload is below: { \"anonymousId\" : \"507f191e810c19729de860ea\" , \"context\" : { \"locale\" : \"en-US\" , \"page\" : { \"title\" : \"Analytics Academy\" , \"url\" : \"https://segment.com/academy/\" } }, \"integrations\" : { \"All\" : true , \"Mixpanel\" : false , \"Salesforce\" : false , \"My Destination Function (My Workspace)\" : true } } By default , the integrations object is set to 'All': true . You do not need to include this flag in the object to use this behavior, but if you’ll be using the integrations object frequently to control destination filtering, you might want to do this to make it explicit for later readers. Change this to 'All': false to prevent any downstream destinations from receiving data, not including data warehouses. If you set 'Segment.io': false in the integrations object, Analytics.js 2.0 drops the event before it reaches your Source Debugger. You can also add destinations to the object by key, and provide a true or false value to allow or disallow data to flow to them on an individual basis. The Destination Info box at the top of each destination page lets you know how to refer to each destination in the Integrations object. If you are using multiple instances of a destination , any settings you set in the integrations object are applied to all instances of the destination. You cannot specify an instance of a destination to apply Integrations object settings to. Note that destination flags are case sensitive and match the destination’s name in the docs (for example, “AdLearn Open Platform”, “awe.sm”, or “MailChimp”). The syntax to filter data to a data warehouse is different. Refer to the Warehouse FAQs for more details. Destination filters Destination filters allow you to control the data flowing into each specific destination, by examining event payloads, and conditionally preventing data from being sent to destinations. You can filter out entire events, or just specific fields in the properties, in the traits, or in the context of your events. Destination filters support cloud-based (server-side), actions-based, and mobile and web device-mode destinations.  Destination filters aren’t available for, and don’t prevent data from reaching your warehouse(s) or S3 destinations. Destination filters are only available in workspaces that are on a Business Tier plan. Keep these limitations in mind when using destination filters. To set up destination filters from the Segment web app for the destination from which you want to exclude data: (For web device-mode destinations only) Enable device mode destination filters for your Analytics.js source. To do this, go to your Javascript source and navigate to Settings > Analytics.js and turn the toggle on for Destination Filters . NOTE: Destination filters for web device-mode only supports the Analytics.js 2.0 source. Navigate to Connections > Destinations and select the destination you want to set up filters for. Go to the Filters tab and click + New Filter to create a destination filter.\nSee the Destination Filters documentation for more details. You can set up destination filters using the options presented in the Segment web app, or using Segment’s Filter Query Logic (FQL). If you use FQL, your query syntax is limited to 5KB per query. Per-Source schema integrations filters Integration filters allow you to quickly change which destinations receive specific Track, Identify, or Group events. Access this tool in any Source that is receiving data by navigating to the Schema tab. Schema integration filters are available to workspaces that are on a Business Tier plan only. You can apply Integrations filters to specific events regardless of whether the source is connected to a Tracking Plan. To update which destination an event can be sent to, click the Integrations dropdown menu to see a list of the destinations each call is sent to. You can turn those destinations on or off from within the dropdown menu. The events filtered out of individual destinations using this method still arrive in your data warehouse(s). Warehouses do not appear in the integration filters dropdown, and you cannot prevent data from flowing to Warehouses using this feature - to do that use Warehouse Selective Sync . Integration filters are all-or-nothing for each event. If you require more detailed control over which events are sent to specific destinations, you can use Destination Filters to inspect the event payload, and conditionally drop the data or forward it to the destination. Integration filters won’t override an existing value in the integrations object. If the integration object already has a value for the integration, the per source schema integration filters will not override this. For example, if you’re sending events to Appsflyer with the appsflyerId passed into the integration object: integrations : { Appsflyer : { appsflyerId : ' xxxxxx ' } } For the same event you have Appsflyer turned off using the per source schema integrations filter, this filter won’t override the above object with a false value, and events still send downstream. In this scenario, you can use destination filters to drop the event before it sends downstream. Schema event filters You can use Schema Event Filters to discard and permanently remove Page, Screen and Track events from event-based sources, preventing them from reaching any destinations or warehouses, as well as omit identify traits and group properties. Use this if you know that you’ll never want to access this data again. This functionality is similar to filtering with the Integrations object, however it can be changed from within the Segment app without touching any code. When you enable these filters, Segment stops forwarding the data to all of your Cloud- and device-mode destinations, including warehouses, and your data is no longer stored in Segment’s warehouses for later replay. Use this when you need to disable an event immediately, but may need more time to remove it from your code, or when you want to temporarily disable an event for testing. In addition to blocking track calls, you can block all page and screen calls, as well as omit identify traits and group properties. If the Source is not connected to a tracking plan, you’ll find event filter toggles next to the Integration filters in the source’s schema tab. When an event is set to block, the entire event is blocked. This means no destinations receive it, including data warehouses. When you block an event using Schema filters, it won’t be considered in the MTU count unless blocked event forwarding is enabled. When an event is blocked, the name of the event or property appears on your Schema page with a counter which shows how many times it has been blocked. By default, data from blocked events and properties is not recoverable. You can always re-enable the event to continue sending it to downstream destinations. In most cases, blocking an event immediately stops that event from sending to destinations. In rare cases, it can take up to 6 hours for an event to completely stop arriving in all Destinations. This feature is only available if the Source is not connected to a Tracking Plan, and is only available in workspaces that are on a Business Tier plan. Protocols Tracking Plan blocking and property omission If you’re using Protocols, and you’re confident that your tracking plan includes exactly the events and properties you want to record, you can tell Segment to block unplanned events or malformed JSON . When you do this, Segment discards any data coming from the Source that doesn’t conform to the tracking plan. By default, the blocked events are permanently discarded: they do not flow to Destinations, and cannot be Replayed (similar to Schema Controls). However, you can opt to send data in violation of the tracking plan to a new Segment Source so you can monitor it. (This source can affect your MTU count.) If you have Protocols in your workspace, and have a tracking plan associated with the Source, you’ll see additional options in the Schema Configuration section of the Source’s Settings page. From this page you can choose how to handle data violations across different types of calls and properties, whether that be blocking events entirely or omitting violating properties. Destination Insert Function A customizable way to filter or alter data going from a source to a cloud-mode destination is to use Insert Functions ). This feature gives you the ability to receive data from your Segment source, write custom code to alter or block it, and then pass that altered payload to a downstream cloud-mode destination. Warehouse Selective Sync Warehouse Selective Sync allows you to stop sending specific data to specific warehouses. You can use this to stop syncing specific events or properties that aren’t relevant, and could be slowing down your warehouse syncs. See the Warehouse Selective Sync documentation to learn more. This feature is only available to Business Tier customers, and you must be a Workspace Owner to change Selective Sync settings. Privacy Portal filtering The Privacy Portal is available to all Segment customers, because Segment believes that data privacy is a right, and that anyone collecting data should have tools to help ensure their users’ privacy. More enhancements are available to BT customers who may need tools for managing complex implementations. The Privacy Portal tools allow you to inspect your incoming calls and their payloads, detect potential Personally Identifiable Information (PII) in properties using matchers, classify the information by different categories of risk, and use those categories to determine which Destinations may or may not receive the data. Learn more about these features in the Privacy Portal documentation . This page was last modified: 02 Feb 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Filtering with the Integrations Object Destination filters Per-Source schema integrations filters Schema event filters Protocols Tracking Plan blocking and property omission Destination Insert Function Warehouse Selective Sync Privacy Portal filtering Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Filtering your Segment Data"
      },
      {
        "level": 2,
        "text": "Filtering with the Integrations Object"
      },
      {
        "level": 2,
        "text": "Destination filters"
      },
      {
        "level": 2,
        "text": "Per-Source schema integrations filters"
      },
      {
        "level": 2,
        "text": "Schema event filters"
      },
      {
        "level": 2,
        "text": "Protocols Tracking Plan blocking and property omission"
      },
      {
        "level": 2,
        "text": "Destination Insert Function"
      },
      {
        "level": 2,
        "text": "Warehouse Selective Sync"
      },
      {
        "level": 2,
        "text": "Privacy Portal filtering"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/reverse-etl/reverse-etl-source-setup-guides/azure-setup/",
    "title": " Azure Reverse ETL Setup | Segment Documentation",
    "content": "Home / Connections / Reverse etl / Reverse etl source setup guides / Azure Reverse ETL Setup Azure Reverse ETL Setup On this page Required permissions Set up guide Set up Azure as your Reverse ETL source. At a high level, when you set up Azure dedicated SQL pools for Reverse ETL, the configured user needs read permissions for any resources (databases, schemas, tables) the query needs to access. Segment keeps track of changes to your query results with a managed schema ( __SEGMENT_REVERSE_ETL ), which requires the configured user to allow write permissions for that schema. Required permissions Make sure the user you use to connect to Segment has permissions to use that warehouse. You can follow the process below to set up a new user with sufficient permissions for Segment’s use. To create a login in your master database, run: CREATE LOGIN <login name of your choice> WITH PASSWORD = 'Str0ng_password'; -- password of your choice Execute the commands below in the database where your data resides. To create a user for Segment, run: CREATE USER <user name of your choice> FOR LOGIN <login name of your choice>; To grant access to the user to read data from all schemas in the database, run: EXEC sp_addrolemember 'db_datareader', '<user name of your choice>'; To grant Segment access to read from certain schemas, run: CREATE ROLE <role name of your choice>;\n  GRANT SELECT ON SCHEMA::[schema_name] TO <role name of your choice>;\n  EXEC sp_addrolemember '<role name of your choice>', '<user name of your choice>'; To grant Segment access to create a schema to keep track of the running syncs, run: GRANT CREATE SCHEMA TO <user name of your choice>; If you want to create the schema yourself and then give Segment access to it, run: CREATE SCHEMA  __segment_reverse_etl;\n  GRANT CONTROL ON SCHEMA::__segment_reverse_etl TO <user name of your choice>;\n  GRANT CREATE TABLE ON DATABASE::[database_name] TO <user name of your choice>; Set up guide To set up Azure as your Reverse ETL source: Log in to your Azure account. Navigate to your dedicated SQL pool . Segment supports both dedicated SQL pool (formerly SQL DW) and dedicated SQL pool in Synapse workspace. Navigate to Settings > Connection strings and select the JDBC tab to find the server, port, and database name. Open your Segment workspace . Navigate to Connections > Sources and select the Reverse ETL tab. Click + Add Reverse ETL source . Select Azure and click Add Source . Enter the configuration settings for your Azure source based on the information from Step 3. Hostname: Use xxxxxxx.sql.azuresynapse.net if you’re connecting to a dedicated SQL pool in Synapse workspace. Use xxxxxxx.database.windows.net if you’re connecting to a dedicated SQL pool (formerly SQL DW) Port: 1433 (default) Database name: The name of your dedicated SQL pool. Username: The login name you created with CREATE LOGIN in the required permissions section. Password: The password that’s associated with the login name. Click Test Connection to see if the connection works. If the connection fails, make sure you have the right permissions and credentials, then try again. Click Add source if the test connection is successful. After you’ve successfully added your Azure source, add a model and follow the rest of the steps in the Reverse ETL setup guide. This page was last modified: 10 Jun 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Required permissions Set up guide Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Azure Reverse ETL Setup"
      },
      {
        "level": 2,
        "text": "Required permissions"
      },
      {
        "level": 2,
        "text": "Set up guide"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/aws-privatelink/",
    "title": " Amazon Web Services PrivateLink | Segment Documentation",
    "content": "Home / Connections / Amazon Web Services PrivateLink Amazon Web Services PrivateLink On this page Databricks RDS Postgres Redshift Snowflake Amazon Web Services’ PrivateLink is an AWS service that provides private connectivity between VPCs without exposing traffic to the public Internet. Keeping traffic in the Amazon network reduces the data security risk associated with exposing your Warehouse traffic to the Internet. Segment’s PrivateLink integration is currently in private beta and is governed by Segment’s First Access and Beta Preview Terms . You might incur additional networking costs while using AWS PrivateLink. You can configure AWS PrivateLink for Databricks , RDS Postgres , Redshift , and Snowflake . Only warehouses located in regions us-east-1 , us-west-2 , or eu-west-1 are eligible. Usage limits for each customer during the AWS PrivateLink Private Beta include the following: Up to 2 AWS PrivateLink VPC endpoints. A monthly data transfer limit of 300GB total for all PrivateLink VPC endpoints connected to Segment. Databricks The following Databricks integrations support PrivateLink: Databricks storage destination Databricks Reverse ETL source Databricks Profiles Sync Databricks Data Graph Segment recommends reviewing the Databricks documentation before attempting AWS PrivateLink setup The setup required to configure the Databricks PrivateLink integration requires front-end and back-end PrivateLink configuration. Review the Databricks documentation on AWS PrivateLink to ensure you have everything required to set up this configuration before continuing. Prerequisites Before you can implement AWS PrivateLink for Databricks, complete the following prerequisites in your Databricks workspace: Databricks account must be on the Enterprise pricing tier and use the E2 version of the platform. Databricks workspace must use a Customer-managed VPC and Secure cluster connectivity . Configure your VPC with DNS hostnames and DNS resolution Configure a security group with bidirectional access to 0.0.0.0/0 and ports 443, 3306, 6666, 2443, and 8443-8451. Implement PrivateLink for Databricks To implement Segment’s PrivateLink integration for Databricks: Follow the instructions in Databricks’ Enable private connectivity using AWS PrivateLink documentation. You must create a back-end connection to integrate with Segment’s front-end connection. After you’ve configured a back-end connection for Databricks, let your Customer Success Manager (CSM) know that you’re interested in PrivateLink. Segment’s engineering team creates a custom VPC endpoint on your behalf. Segment then provides you with the VPC endpoint’s ID. Register the VPC endpoint in your Databricks account and create or update your Private Access Setting to include the VPC endpoint. For more information, see Databricks’ Register PrivateLink objects documentation. Configure your Databricks workspace to use the Private Access Setting object from the previous step. Reach back out to your CSM and provide them with your Databricks Workspace URL. Segment configures their internal DNS to reroute Segment traffic for your Databricks workspace to your VPC endpoint. Your CSM notifies you that Segment’s PrivateLink integration is complete. If you have any existing Segment Databricks integrations that use your Databricks workspace URL, they now automatically use PrivateLink. Any new Databricks integrations created in the Segment app using your Databricks workspace URL will also automatically use PrivateLink. RDS Postgres The following RDS Postgres integrations support PrivateLink: RDS Postgres storage destination RDS Postgres Reverse ETL source RDS Postgres Profiles Sync Prerequisites Before you can implement AWS PrivateLink for RDS Postgres, complete the following prerequisites: Set up a Network Load Balancer (NLB) to route traffic to your Postgres database : Segment recommends creating a NLB that has target group IP address synchronization, using a solution like AWS Lambda. \nIf any updates are made to the Availability Zones (AZs) enabled for your NLB, please let your CSM know so that Segment can update the AZs of your VPC endpoint. Configure your NLB with one of the following settings : Disable the Enforce inbound rules on PrivateLink traffic setting If you must enforce inbound rules on PrivateLink traffic, add an inbound rule that allows traffic belonging to Segment’s PrivateLink/Edge CIDR: 10.0.0.0/8 Implement PrivateLink for RDS Postgres To implement Segment’s PrivateLink integration for RDS Postgres: Create a Network Load Balancer VPC endpoint service using the instructions in the Create a service powered by AWS PrivateLink documentation. Let your Customer Success Manager (CSM) know that you’re interested in PrivateLink. They will share information with you about Segment’s AWS principal. Add the Segment AWS principal as an “Allowed Principal” to consume the Network Load Balancer VPC endpoint service you created in step 1. Reach out to your CSM and provide them with the Service Name for the service that you created above. Segment’s engineering team provisions a VPC endpoint for the service in the Segment Edge VPC. Segment provides you with the VPC endpoint’s private DNS name. Use the DNS name as the Host setting to update or create new Postgres integrations in the Segment app. Redshift The following Redshift integrations support PrivateLink: Redshift storage destination Redshift Reverse ETL source Redshift Profiles Sync Redshift Data Graph Prerequisites Before you can implement AWS PrivateLink for Redshift, complete the following prerequisites: You’re using the RA3 node type : To access Segment’s PrivateLink integration, use an RA3 instance. You’ve enabled cluster relocation : Cluster relocation migrates your cluster behind a proxy and keeps the cluster endpoint unchanged, even if your cluster needs to be migrated to a new Availability Zone. A consistent cluster endpoint makes it possible for Segment’s Edge account and VPC to remain connected to your cluster. To enable cluster relocation, follow the instructions in the AWS Relocating your cluster documentation. Your cluster is using a port within the ranges 5431-5455 or 8191-8215 : Clusters with cluster relocation enabled might encounter an error if updated to include a port outside of this range . Implement PrivateLink for Redshift To implement Segment’s PrivateLink integration for Redshift: Let your Customer Success Manager (CSM) know that you’re interested in PrivateLink. They will share information with you about Segment’s Edge account and VPC. After you receive the Edge account ID and VPC ID, grant cluster access to Segment’s Edge account and VPC . Reach back out to your CSM and provide them with the Cluster Identifier for your cluster and your AWS account ID. Segment’s engineering team creates a Redshift managed VPC endpoint within the Segment Redshift subnet on your behalf, which creates a PrivateLink Endpoint URL. Segment then provides you with the internal PrivateLink Endpoint URL. Use the provided PrivateLink Endpoint URL as the Hostname setting to update or create new Redshift integrations in the Segment app. Snowflake The following Snowflake integrations support PrivateLink: Snowflake storage destination Snowflake Reverse ETL source Snowflake Profiles Sync Snowflake Data Graph Prerequisites Before you can implement AWS PrivateLink for Snowflake, complete the following prerequisites: Your Snowflake account is on the Business Critical Edition or higher. Your Snowflake account is hosted on the AWS cloud platform . Implement PrivateLink for Snowflake To implement Segment’s PrivateLink integration for Snowflake: Follow Snowflake’s PrivateLink documentation to enable AWS PrivateLink for your Snowflake account. Let your Customer Success Manager (CSM) know that you’re interested in PrivateLink. They will provide you with Segment’s AWS Edge account ID. Create a Snowflake Support Case to authorize PrivateLink connections from Segment’s AWS account ID as a third party vendor to your Snowflake account. After Snowflake support authorizes Segment, call the SYSTEM$GET_PRIVATELINK_CONFIG function while using the Snowflake ACCOUNTADMIN role. Reach back out to your Segment CSM and provide them with the privatelink-vpce-id and privatelink-account-url values from the function output. Note down for yourself the privatelink-account-name value. Segment’s engineering team creates a custom VPC endpoint on your behalf. Segment also creates a CNAME record to reroute Segment traffic to use your VPC endpoint. This ensures that Segment connections to your privatelink-account-name are made over PrivateLink. Your CSM notifies you that the setup on Segment’s side is complete. Use your privatelink-account-name as the Account setting to update or create new Snowflake integrations in the Segment app. This page was last modified: 30 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Databricks RDS Postgres Redshift Snowflake Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Amazon Web Services PrivateLink"
      },
      {
        "level": 2,
        "text": "Databricks"
      },
      {
        "level": 3,
        "text": "Prerequisites"
      },
      {
        "level": 3,
        "text": "Implement PrivateLink for Databricks"
      },
      {
        "level": 2,
        "text": "RDS Postgres"
      },
      {
        "level": 3,
        "text": "Prerequisites"
      },
      {
        "level": 3,
        "text": "Implement PrivateLink for RDS Postgres"
      },
      {
        "level": 2,
        "text": "Redshift"
      },
      {
        "level": 3,
        "text": "Prerequisites"
      },
      {
        "level": 3,
        "text": "Implement PrivateLink for Redshift"
      },
      {
        "level": 2,
        "text": "Snowflake"
      },
      {
        "level": 3,
        "text": "Prerequisites"
      },
      {
        "level": 3,
        "text": "Implement PrivateLink for Snowflake"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/traits/predictions/using-predictions/",
    "title": " Using Predictions | Segment Documentation",
    "content": "Home / Unify / Traits / Predictions / Using Predictions Using Predictions Free x Team x Business ✓ + Unify Plus ✓ ? Unify Plus requires a business tier account and is included with Engage See the available plans , or contact Support . On this page Working with Predictions in Segment Predictions use cases FAQs Working with Predictions in Segment Predictions are stored as computed traits in user profiles, with scores represented as percentage cohorts. For example, a score of 0.8 indicates the user is in the 80th percentile, or the top 20% of the cohort. After selecting a cohort, use Predictions with the following Segment features: Audiences , build new audiences using Predictions as a base. Segment also provides prebuilt Suggested Predictive Audiences as part of Engage.. Journeys ; use Predictions in Journeys to trigger Engage marketing campaigns when users enter a high-percentage cohort, or send promotional material if a customer shows interest and has a high propensity to buy. Destinations ; send your Predictions downstream to Warehouses , support systems, and ad platforms. Prediction tab You can access generated Predictions in the Prediction tab of your Trait. The Prediction tab gives you actionable insight into your prediction. The Explore your prediction section of the Prediction tab visualizes prediction data and lets you create Audiences to target. An interactive chart displays a percentile cohort score that indicates the likelihood of users in each group to convert on your chosen goal. You can choose the top 20%, bottom 80%, or create custom ranges for specific use cases. You can then create an Audience from the group you’ve selected, letting you send efficient, targeted marketing campaigns within Journeys. You can also send your prediction data to downstream destinations. Model monitoring Predictions rank your customers by their likelihood to perform a specific conversion event, from most to least likely. For each custom prediction, Segment monitors the percentile cohort where customers were ranked when they performed the predicted conversion event. After around 7 days, Segment creates a graph data visualization, allowing you to evaluate the prediction’s accuracy based on real workspace data. For example, suppose you’re predicting the likelihood of customers completing an order_completed event. The graph shows that: Customers in the 91–100% cohort performed the event about 6,700 times. Customers in the 81–90% cohort performed the event about 3,900 times. Customers in the 71–80% cohort performed the event about 3,000 times. This pattern shows that the prediction was extremely accurate in identifying customers most likely to convert. Ideally, most graphs will show a similar trend, where the highest-ranked cohorts have the most conversion activity. However, this pattern can change depending on how you use Predictions. For example, if you run a marketing campaign targeting the bottom 10% cohort, you might see an increase in conversions for that group instead. Like any AI or machine learning tool, Predictions may not always be perfect. Start small, test your predictions, and refine your approach as needed. Model monitoring makes it easier to measure and improve the accuracy of your predictions. Model statistics The Predictions tab’s Understand your prediction section provides insights into the performance of the underlying predictive model. This information helps you understand the data points that contribute to the prediction results. The Understand your prediction dashboard displays the following model metrics: AUC , or Area under the ROC curve ; AUC values range from 0 to 1, with 1 indicating a perfect prediction and 0 indicating the opposite. Higher AUC indicates better predictions. Lift Quality , which measures the effectiveness of a predictive model. Segment calculates lift quality as the ratio between the results obtained with and without the predictive model. Higher lift quality indicates better predictions. Log Loss ; the more a predicted probability diverges from the actual value, the higher the log-loss value will be. Lower log loss indicates better predictions. Top contributing events ; this graph visually describes the events factored into the model, as well as the associated weights used to create the prediction. Predictions use cases Predictions offer more value in some situations than others. This sections covers common scenarios where predictions have high impact, as well as others where alternative approaches may be more appropriate. Marketing opportunities Improve ad targeting ; build targeted audience segments based on predictive behavior. Optimize campaign performance ; reduce customer acquisition costs (CAC), and improve customer lifetime value (LTV) by building campaigns that target customers most likely to purchase or perform another desired action. Power more personalization ; With Predictions, you can deliver the right message at the right time. You can create targeted customer Journeys with personalized offers and recommendations that boost conversion and promote upsell and cross sell. Win back unengaged customers ; Predictions let you identify unengaged customers you can re-engage with personalized winback campaigns. Data science use cases Model improvement ; You can extract Predictions from Segment and use them to improve proprietary machine learning models. Testing experiences ; data teams can validate and strengthen existing machine learning models by testing proprietary models against Segment’s out-of-the-box models. Save time on predictive modeling ; data science teams can use Segment’s predictive models, freeing up time to building other in-house models like inventory management and fraud alerting. When to use a prediction Predictions are most effective in the following situations: When your desired outcome is difficult to measure and not clearly defined , like activation, retention, engagement, or long-term value Journeys. When your product has more than 100,000 average monthly users ; smaller sample sizes lead to less accurate statistical conclusions. When you need to save time building cohorts ; Predictions lets marketers access and take action on predictive data without the help of data science teams, while also giving data teams out-of-the-box machine learning models they can use in downstream tools. When other approaches work better Predictions may not be as beneficial in the following situations: When you sell limited but highly-priced items , like enterprise software, complex medical machines, and so on; this also applies if you’re in the B2B sector. When you don’t yet have enough data ; your model could produce errors if, for example, your target is too new and lacks sufficient data. Waiting a month could allow Segment to gather more predictive data. FAQs What type of machine learning model does Segment use? Segment uses a binary classification model that uses decision trees. What level of confidence can I have in my predictions? Once Segment creates your prediction, you can check the model statistics page, where Segments shows you how the model was created. Segment also maintains automated systems that monitor model performance and will alert you if your model is not predictive. How long do predictions take to create? Trait creation depends on the amount of data, but Segment expects predictions to be completed in around 24 hours. For larger customers, however, this could take 48 hours. Predictions shows a status of In Progress while computing; Segment updates this status when customers are scored. What are AUC, log loss, and lift quality? These data science statistics measure the effectiveness of Segment’s predictions when tested against historical data. For more information, refer to ROC Curve and AUC , The Lift Curve in Machine Learning , and Intuition behind log-loss score . What is the Prediction Quality Score? The Prediction Quality Score factors AUC, log loss, and lift quality to determine whether Segment recommends using the prediction. A model can have a score of Poor, Fair, Good, or Excellent. How does Segment store trait values? The created trait value represents the user’s percentile cohort. This value will refresh when we re score the customers based on your refresh cadence. If you see 0.85 on a user’s profile, this means the user is in the 85th percentile, or the top 15% for the prediction. How frequently do you re-train the model? Segment rebuilds the machine learning model every 30 days. How frequently do you update trait values? By default, Segment refreshes scores every 7 days. However, you can request that trait values update daily. Reach out to your CSM to determine your eligibility. Can I update Predictive Traits and Predictive Audiences? Predictive Traits can’t be updated, but Predictive Audiences can. To modify a Predictive Trait, you’ll need to recreate it. How many predictions can I have? You get five predictions as part of Engage Foundations or Unify Plus. To purchase more predictions, reach out to your CSM. Predictive Audiences contribute to the Engage limit of 100 audiences. Whether you create the audience manually or with predictive modeling, the audience counts towards the 100-audience limit. Is Predictions HIPAA eligible? Yes. Are there any known Predictions limitations? Yes. Keep the following in mind when you work with Predictions: Predictions made for more than 100 million users will fail. Segment recommends making predictions only for non-anonymous users, or, as an alternative, use the Starting Cohort to narrow down the audience for which you want to make a prediction. Predictions will not work as intended if you track more than 5,000 unique events in your workspace. Prediction is failing with error “We weren’t able to create this prediction because your requested prediction event is not being tracked anymore. Please choose a different prediction event and try again.” Predictions are computed based on the available data and the conditions specified for the trait. A gap in tracking events for seven continuous days could potentially affect the computation of the prediction.\nNevertheless, once data tracking resumes and there is enough data, the prediction should be recomputed. How is the average calculated? The probabilities for all users are added together and then divided by the total number of users. If a user’s score in “Likelier to convert than average” is below 1, it means they are less likely than the average user to convert. This page was last modified: 26 Nov 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Working with Predictions in Segment Predictions use cases FAQs Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Using Predictions"
      },
      {
        "level": 2,
        "text": "Working with Predictions in Segment"
      },
      {
        "level": 3,
        "text": "Prediction tab"
      },
      {
        "level": 3,
        "text": "Model monitoring"
      },
      {
        "level": 2,
        "text": "Predictions use cases"
      },
      {
        "level": 3,
        "text": "Marketing opportunities"
      },
      {
        "level": 3,
        "text": "Data science use cases"
      },
      {
        "level": 3,
        "text": "When to use a prediction"
      },
      {
        "level": 3,
        "text": "When other approaches work better"
      },
      {
        "level": 2,
        "text": "FAQs"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/sources/about-cloud-sources/",
    "title": " Cloud Sources | Segment Documentation",
    "content": "Home / Connections / Sources / Cloud Sources Cloud Sources On this page How do cloud sources work? Set up a cloud source Troubleshooting cloud sources Using Cloud Source data Querying source data Cloud-App Sources (often shortened to Cloud Sources) allow you to pull in data from third-party tools so you can use it in Segment. There are two types of Cloud Apps: Object and Event sources. As in the basic tracking API, objects usually contain information about a person or group which is updated over time, while event data happens once, and is appended to a list. Event Cloud-App Sources Event Cloud Sources can export their data both into Segment warehouses, and into other enabled Segment integrations that work with event data. Object Cloud-App Sources Object Cloud App Sources can export data and import it directly into a Segment warehouse. You must have a Segment warehouse enabled before you enable these. From the warehouse, you can analyze your data with SQL, use Reverse ETL to extract data, or use Engage SQL Traits to build audiences. Some examples of Object Cloud sources are Salesforce (account information), Zendesk (support cases), and Stripe (payments information). In the app, data from website, mobile, and server sources can go to a warehouse or to destinations. Object Cloud-App Source data can only go to Warehouses. How do cloud sources work? Sources are functionally comprised of either one or both of the following components: a “sync” component and a “streaming” component. They work together to populate logical collections of data based on upstream resource availability and following data normalization best practices. These collections may be either events (append only data streams, akin to “facts” in data warehousing parlance) or objects (dimensional values that may be updated based on changes in state upstream). Sync frequency You enable a cloud source from the Segment web app, and grant Segment access by pasting an API key or authenticating with OAuth. Segment then starts a scheduled job on your behalf which makes requests to the downstream tool, normalizes and transforms the data, and forwards that data to the Segment API. Cloud sources attempt to use as few API calls as possible, and (where possible) only fetch data that changed since the last sync. The syncs might take a long time (especially on the first sync), so the cloud source syncs have robust retry and rate limiting logic. Contact Segment Product Support if you’d like to change the cadence of your source’s sync frequency. API call use and collection selection We make an effort to be respectful of your API call allotments and limits. For example, in the case of Salesforce, we issue only one query per collection per run, using the absolute minimum number of API calls possible (typically about 350/day). Moreover, we’re deliberate about which collections we pull, striking a balance between allowing you to get a full picture of your users and reducing extraneous data (like administrative and metadata tables). Soon, we’ll allow you to specify which collections you care about during the source set up phase, so if you need to cut down on calls, you’ll be able to just deselect collections. Streaming Streaming components are used to listen in real time to webhooks from downstream cloud sources, normalize and transform the data, and forward it to our APIs. Both sync and streaming components can forward data to our event tracking and objects upsertion API processing layers, but generally sync components are used to fetch objects and streaming components listen for events. Set up a cloud source To use cloud sources, we suggest going through the following steps. Get cloud source credentials Get warehouse credentials Choose your preferred sync time Before you connect a source, check out the sources documentation . See what kind of credentials you will need to enable the source. Different sources require different levels of permissioning. Next, you’ll also need to get the credentials for your warehouse . Once you have the necessary credentials (or are logged in to OAuth for your cloud source), you should be ready to go! Go to the “sources catalog” in the Segment web app. Choose a cloud source, and click Configure. Enter your credentials or log in using OAuth. Go to the “warehouses” tab and enter the credentials for your warehouse if you don’t already have one connected to Segment. Based on your plan, you can schedule a certain number of syncs per day. We suggest setting these up so your dashboards and reports are fresh for reporting, but not at the same time of day that a lot of people are querying your database. Troubleshooting cloud sources The most common reason cloud sources have trouble because of authentication or permission issues. When the issue is related to authentication, you’ll see an “access denied” connection error in your source details. When this happens, Segment quits the process early and does not make any further attempts on any collections. When you successfully authenticate, but your user lacks the required permissions (for example, if you use an agent login instead of an administrator for Zendesk), Segment attempts to pull each collection and reports errors on a per-collection basis. This helps you troubleshoot why source runs fail, because sometimes permission-based denials are scoped to specific resources from the upstream tool. Segment attempts to make the errors displayed in the UI clear enough so we don’t need to document all of them. However, if it’s not clear what to do to fix an error you encounter, contact support and let them know. Sometimes, when the sync job fails due to an unhandled error or is mysteriously hanging for too long, we’ll kill the job and report a failure with instructions to contact support. When this happens, our support and engineering teams have already been notified of the failure and have the complete set of logs to set about debugging and remediating the issue, but  don’t hesitate to get in touch so they can keep you in the loop! Using Cloud Source data What kind of data does Segment pull from each source? In general, we’ve focused on pulling all of the collections directly related to the customer experience. We do not automatically pull all collections available from a partner API, since many of them aren’t relevant to the customer journey. You can see a list of the collections we pull in the docs for each cloud source . Each collection reflects a table in your database. Contact Segment Product Support if you need additional data collected, or to change the schema to do the analysis you want. We’d love to know what analysis you’re trying to run, what additional data you need, and we’ll share with the product team to evaluate. What questions can you answer with data from cloud, web, and mobile sources combined in a single warehouse? What content drives people forward in our sales funnel? What are the top pages viewed before a support ticket is sent? Do people who opt into text messages engage more than people who only get emails? Do customers that interact with our support team activate faster? - Retain more overtime? What are all of the communications across marketing, success, and sales, this account has had in the last 2 months? Querying source data Generally, you need intermediate- to advanced SQL experience to explore and analyze cloud source data in a warehouse. The following resources can help you get up and running more quickly! Joining IDs As you start to get into joining across different types of sources, you’ll need a way to join user IDs. This help article explains how to do this in detail. Partner Dashboards Our BI partners at Mode, Looker, BIME, Periscope, and Chartio have created out of the box dashboards that work on top of our source schemas. This page was last modified: 22 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page How do cloud sources work? Set up a cloud source Troubleshooting cloud sources Using Cloud Source data Querying source data Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Cloud Sources"
      },
      {
        "level": 3,
        "text": "Event Cloud-App Sources"
      },
      {
        "level": 3,
        "text": "Object Cloud-App Sources"
      },
      {
        "level": 2,
        "text": "How do cloud sources work?"
      },
      {
        "level": 3,
        "text": "Sync frequency"
      },
      {
        "level": 3,
        "text": "API call use and collection selection"
      },
      {
        "level": 3,
        "text": "Streaming"
      },
      {
        "level": 2,
        "text": "Set up a cloud source"
      },
      {
        "level": 2,
        "text": "Troubleshooting cloud sources"
      },
      {
        "level": 2,
        "text": "Using Cloud Source data"
      },
      {
        "level": 3,
        "text": "What kind of data does Segment pull from each source?"
      },
      {
        "level": 3,
        "text": "What questions can you answer with data from cloud, web, and mobile sources combined in a single warehouse?"
      },
      {
        "level": 2,
        "text": "Querying source data"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/storage/warehouses/health/",
    "title": " Warehouse Health Dashboard | Segment Documentation",
    "content": "Home / Connections / Storage / Warehouses / Warehouse Health Dashboard Warehouse Health Dashboard On this page Warehouse dashboards Warehouse-Source dashboards Warehouse Health Dashboard FAQs The Warehouse Health dashboard helps you understand trends in data volume (specifically, rows) synced to your data warehouse over time. You can use this feature to answer questions such as: Growth patterns - How has the volume of data synced to the warehouse grown over time? How does this growth align to the storage capacity available in my warehouse? Anomaly detection - How much data is being synced on a daily basis? Have there been anomalous spikes or dips that may indicate sudden changes in event volume, sync failures, or something else? Data composition - Which sources are contributing the most (or least) amount of data in my warehouse? Which collections make up the majority of data within a source? Note : Warehouse Health is available for all Warehouse customers. The Warehouse Health dashboards are available at both the warehouse level , and at the warehouse-source connection level , explained below. Data in the dashboards updates in real-time, and covers the previous 30 days. The timezones displayed in the dashboards are converted to the viewer’s local time. Warehouse dashboards Go to the Segment App, to the Destinations list, and select the warehouse. On the warehouse’s information page, click the Health tab. This dashboard displays aggregate trends from all sources that sync to the specific warehouse. A warehouse level dashboard Warehouse-Source dashboards Go to the Segment App, to the Destinations list, and select the warehouse. On the warehouse’s Overview page, select the Source (schema) you want to see data for, then click the Health tab. This dashboard displays trends for each separate source that syncs to a specific warehouse. It also displays aggregations of the collections within that source. A warehouse-source level dashboard Warehouse Health Dashboard FAQs Can I use the Health Dashboard data for QA and validation? No. These dashboards exist to help you understand high-level trends, but not to provide exact numbers about the data synced to the warehouse. The numbers provided in these dashboards are rounded, and are not exact. These dashboards will help you understand trends in the data, and use signals to do deeper investigation and QA, as needed. How is this similar (or different) than the information available in the Sync History and Overview tabs? The Warehouse Overview, Sync History and Health tabs provide different levels of granularity into warehouse syncs. Overview - Shows which sources (also referred to as schemas) are connected to a warehouse, and information about the most recent sync and upcoming sync for each source. This information includes when the last sync happened, what the status of that sync is, how many events were synced, and when the next sync is scheduled. Sync History - Shows detailed information about most recent syncs for a specific source connected to a warehouse (warehouse-source level). In this tab you can find information for each sync including sync status, start time, duration, synced rows, and notices about errors and/or warnings. Health - The Health tab provides an aggregate view of syncs to a warehouse over time. You can either look at this at a warehouse level, or warehouse-source level. This shows information about the volume of rows synced over the last 30 days. How often is the data refreshed? Data is refreshed on a real time basis. What timeframe is the data available for? The data available shows the last 30 days. What timezone are the dates in? All dates and times found within Warehouse Health, Sync History and Warehouse overview pages are in the user’s local time. This page was last modified: 21 Apr 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Warehouse dashboards Warehouse-Source dashboards Warehouse Health Dashboard FAQs Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Warehouse Health Dashboard"
      },
      {
        "level": 2,
        "text": "Warehouse dashboards"
      },
      {
        "level": 2,
        "text": "Warehouse-Source dashboards"
      },
      {
        "level": 2,
        "text": "Warehouse Health Dashboard FAQs"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/faqs/",
    "title": " Engage FAQs | Segment Documentation",
    "content": "Home / Engage / Engage FAQs Engage FAQs Free x Team x Business ✓ + Engage Foundations ✓ ? Engage Foundations requires a Business tier account and includes Unify. See the available plans , or contact Support . On this page Do you have an Audiences API? Can I programmatically determine if a user belongs to a particular audience? Can I modify audience keys? Can I reuse audience keys? How do historical lookback windows work? What are Funnel Audiences? What is Engage Merge Protection? Which destinations support syncing the identity graph? What Sources can I sync to Engage? Can I send audiences to multiple destination accounts? Why is the user count in a journey step greater than the entry/previous step of the journey? Why were multiple audience-entered events triggered for the same user? Why am I not seeing standard source events on the Engage source, even though it has been connected through “Unify -> Unify Settings -> Profile Sources” page? Why can’t I connect the audience/computed trait to an existing destination in my workspace? How are the “5 most common values” for traits calculated? Do you have an Audiences API? Yes. You can learn more about the Audience API by visiting the Segment Public API documentation . Can I programmatically determine if a user belongs to a particular audience? Yes. Because Engage creates a trait with the same name as your audience, you can query the Profile API to determine if a user belongs to a particular audience. For example, to determine if the user with an email address of bob@example.com is a member of your high_value_users audience, you could query the following Profile API URL: https://profiles.segment.com/v1/namespaces/<namespace_id>/collections/users/profiles/email:bob@segment.com/traits?include=high_value_users The following response indicates that Bob is a high-value user: { \"traits\" : { \"high_value_users\" : true , }, \"cursor\" : { \"has_more\" : false , } } For more information on profile queries, visit the Profile API documentation . Can I modify audience keys? You can’t change the audience key after it’s created. To change the key, you need to re-create the audience. Can I reuse audience keys? Avoid using the same audience key twice, even if you’ve deleted the key’s original audience. Downstream tools and destinations might have trouble distinguishing between different audiences that once shared the same key. This may create mismatch in audience size between Segment and the destination because the destination may count users of the old audience, resulting in a larger audience size. How do historical lookback windows work? Engage allows you to compute new traits and audiences of your users based on their entire customer journey, and all historical data you’ve tracked with Segment. When you create a new computed trait or audience, you include a lookback window that determines how far back into the past the trait or audiences will be computed. Some important things to keep in mind when setting a lookback window: Historical lookback windows are based on the event timestamp field. Lookback windows are precise down to the hour, so a 90-day lookback window will include any events with a timestamp timestamp within the last 2,160 hours (24 hr/day * 90 days). The trait and audience will automatically update going forward as historical events exceed the lookback window. What are Funnel Audiences? Funnel Audiences allow you to use strict, relative ordering for your audience conditions. Common use cases for these audiences are Cart Abandonment (users that triggered the Product Added event but did not trigger the Order Completed event after the Product Added event occurred) and onboarding steps (users that Added Credit Card but did not Subscribe afterward). To get started with Funnel Audiences, go to: Audiences > New > Select Funnel Condition (“and then did not”/”and then did”) The funnel condition will now be relative to the parent condition. The audience in the image below includes all users that have Product Added in the last week, but not Order Completed within a day of doing so. Funnel Audiences compute based on all instances of the parent event within the lookback period. This means that if you have a user that Product Added ⟶ Order Completed ⟶ Product Added, this user would be entered into the Abandoned Cart state despite having previously completed an order. What is Engage Merge Protection? Engage’s merge protection algorithm protects your identity graph from unnecessary merges by finding and removing untrusted external IDs. Here’s an example: In this example, anonymous_id: a1 is not reset during a User Logout . Without merge protection rules, Segment would merge user_id u1 and user_id u2 . Instead, the identity resolution algorithm detects that such a merge would break user_id uniqueness and prevents the merge. This is especially helpful for preventing “blob users” that are merged together by non-unique anonymous IDs or by common group emails like team@company.com . Which destinations support syncing the identity graph? Most destinations on the Segment Platform are built up around a user model. They assume that a user will have a single userId. Further, most Destinations are not built to handle anonymous traffic. By default, Segment doesn’t sync the output of the Identity Graph to Destinations. However, Segment computed traits and audiences are based on the entire user profile, including anonymous and merged data. Segment syncs the value of these computations (for example, blog_posts_ready_30_days: 10 ) using all userIds on the profile. For Destinations that support an alias call (for example, Mixpanel), you can emit an alias call on merge. What Sources can I sync to Engage? The following list shows just some data sources you can sync to Engage: Website ( Analytics.js ) Mobile SDKs ( iOS , Android , AMP ) Server-side libraries ( Go , Node , Java , PHP , Python , Ruby , .NET ) Facebook Lead Ads ActiveCampaign Customer.io Drip Iterable Klaviyo Mailjet Nudgespot Vero Blueshift Delighted Braze Looker Radar Autopilot Friendbuy Can I send audiences to multiple destination accounts? Yes, Engage supports the ability to send an audience or computed trait to two or more accounts of the same partner. The most common use case is multiple Facebook, or Adwords ad accounts. Why am I getting alerts about an audience/computed trait sync failure, but when I look at the specific audience/computed trait it shows a successful sync? An audience/computed trait run or sync may fail on its first attempt, but Engage will retry up to five times before considering it a hard failure that displays on the audience/compute trait’s overview page. As long as the runs/syncs within the specific audience’s overview page indicate success, you can ignore any failure alerts. How things work internally: Segment’s Engage scheduler fetches audiences/traits from the compute service and then handles the logic of generating tasks. These compute/sync tasks get scheduled and executed by another worker. These tasks are a list of steps to be executed. Each task has a series of steps that Segment marks as complete by saving a timestamp for the completion. If something disrupts the worker, it picks up at the latest step without a completed_at timestamp. In some cases, the step or entire task might fail due to timeout or worker disruption. No matter the cause, Segment will retry any failures. The audit trail’s configuration notifies about every task failure, even if the failure later succeeds. In most cases, you won’t need to track these failures, unless you notice actual computation or sync failures. If you don’t want to receive notifications for temporary failures, reach out to support . Upon request, Segment can disable temporary failure notifications, which will reduce the number of notifications your workspace receives. Why is the user count in a journey step greater than the entry/previous step of the journey? Each step of a Journey is an Engage audience under the hood. The conditions stack, so a user must be a member of the previous step (audience) and meet all conditions to be added to subsequent steps. However, if the user no longer meets entry conditions for a particular step, they’ll exit and you’ll see the user count reduced. For any subsequent steps a user is still a part of, they’ll remain until they no longer meet entry conditions. Why were multiple audience-entered events triggered for the same user? Multiple audience events can trigger for a user if any of the following conditions occur:\n1) There is a merge on the user.\n2) An external_id was added to the profile.\n3) The user has multiple identifiers of the same type . Segment sends one event per identifier for each audience or computed trait event.\n4) The include anonymous users option is selected for an audience. Segment sends an event for every anonymousId on the user profile. Why am I not seeing standard source events on the Engage source, even though it has been connected through “Unify -> Unify Settings -> Profile Sources” page? Based on Engage behavior, standard source events such as Page, Track and Identify calls aren’t visible on the Engage source. The Engage source tracks and manages events related to audiences and computed traits within the Engage space. This includes events generated by changes in audience membership or computed trait calculations or when a user profile has been created in the Engage space. These are distinct from the typical Page calls, Track calls, or Identify calls (user interaction events) that you would observe in a standard Segment source. Why can’t I connect the audience/computed trait to an existing destination in my workspace? Engage will not allow you to connect an audience/computed trait to a destination that is already linked to a Connections-based source . Instead, create a new instance of the destination with the correct Engage space selected as the data source. How are the “5 most common values” for traits calculated? The “5 most common values” are the most frequently observed values for a given trait across all users, not tied to any individual user. This page was last modified: 24 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Do you have an Audiences API? Can I programmatically determine if a user belongs to a particular audience? Can I modify audience keys? Can I reuse audience keys? How do historical lookback windows work? What are Funnel Audiences? What is Engage Merge Protection? Which destinations support syncing the identity graph? What Sources can I sync to Engage? Can I send audiences to multiple destination accounts? Why is the user count in a journey step greater than the entry/previous step of the journey? Why were multiple audience-entered events triggered for the same user? Why am I not seeing standard source events on the Engage source, even though it has been connected through “Unify -> Unify Settings -> Profile Sources” page? Why can’t I connect the audience/computed trait to an existing destination in my workspace? How are the “5 most common values” for traits calculated? Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Engage FAQs"
      },
      {
        "level": 2,
        "text": "Do you have an Audiences API?"
      },
      {
        "level": 2,
        "text": "Can I programmatically determine if a user belongs to a particular audience?"
      },
      {
        "level": 2,
        "text": "Can I modify audience keys?"
      },
      {
        "level": 2,
        "text": "Can I reuse audience keys?"
      },
      {
        "level": 2,
        "text": "How do historical lookback windows work?"
      },
      {
        "level": 2,
        "text": "What are Funnel Audiences?"
      },
      {
        "level": 2,
        "text": "What is Engage Merge Protection?"
      },
      {
        "level": 2,
        "text": "Which destinations support syncing the identity graph?"
      },
      {
        "level": 2,
        "text": "What Sources can I sync to Engage?"
      },
      {
        "level": 2,
        "text": "Can I send audiences to multiple destination accounts?"
      },
      {
        "level": 3,
        "text": "Why am I getting alerts about an audience/computed trait sync failure, but when I look at the specific audience/computed trait it shows a successful sync?"
      },
      {
        "level": 2,
        "text": "Why is the user count in a journey step greater than the entry/previous step of the journey?"
      },
      {
        "level": 2,
        "text": "Why were multiple audience-entered events triggered for the same user?"
      },
      {
        "level": 2,
        "text": "Why am I not seeing standard source events on the Engage source, even though it has been connected through “Unify -> Unify Settings -> Profile Sources” page?"
      },
      {
        "level": 2,
        "text": "Why can’t I connect the audience/computed trait to an existing destination in my workspace?"
      },
      {
        "level": 2,
        "text": "How are the “5 most common values” for traits calculated?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/data-graph/linked-events-limits//",
    "title": " Linked Events Limits | Segment Documentation",
    "content": "Home / Unify / Data graph / Linked Events Limits Linked Events Limits Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Usage limits To provide consistent performance and reliability at scale, Segment enforces default use limits for Linked Events. Usage limits Linked Events provides you with the flexibility to enrich unlimited events in downstream destinations. This means you won’t encounter any limitations or pauses in service related to the number of Linked Events enrichments. Segment measures Linked Events limits based on entities and entity rows. Entities: The warehouse tables that are declared in the Data Graph with the enrichment_enabled = true property. Entity rows : The total number of rows synced to Segment cache across all enrichment entities at any given time. To see how many entities and entity rows you’re using with Linked Events, navigate to Settings > Usage & billing and select the Linked Events tab. Plan Linked Events Limits How to increase your limit Free Not available N/A Teams Not available N/A Business If you use Unify and Engage, you’ll receive a trial version with: * 1 Entity for every Unify space * 1 million Entity rows per workspace Contact your sales rep to upgrade to the full paid version of Linked Events to unlock: * Unlimited Entities * Additional Entity Rows (10 x the number of MTUs or 0.1 x the number of monthly API calls up to a maximum of 100 million, to be used across your workspaces) Note: You must already be on a Unify or Engage plan to be eligible for upgrade. Special cases If you have a non-standard or high volume usage plan, you may have unique Linked Events limits or custom pricing. If you’re on the trial version of Linked Events, you won’t be able to add more than 1 million entity row syncs. Reach out to your Customer Success representative to upgrade to the Linked Events paid tier. If you’re using the paid version of Linked Events, and you reach your entity row limit before the end of your billing period, your syncs won’t automatically pause to avoid disruptions to your business. You may be billed for overages in cases of significant excess usage. If you consistently require a higher limit, contact your sales representative to upgrade your plan with a custom limit. There is a hard limit of 100 million entity rows that causes syncs to pause. This page was last modified: 15 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Usage limits Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Linked Events Limits"
      },
      {
        "level": 2,
        "text": "Usage limits"
      },
      {
        "level": 3,
        "text": "Special cases"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/protocols/",
    "title": " Protocols Overview | Segment Documentation",
    "content": "Home / Protocols Overview Protocols Overview Free x Team x Business ✓ + Protocols ✓ ? Protocols is available as an add-on for Business plans only. See the available plans , or contact Support . On this page There are four steps to using Protocols Learn more Protocols is only available for event stream (website, mobile, and server sources) and Engage sources. Segment helps customers collect and integrate customer data across a wide range of tools and Destinations. To do so reliably, the data Segment receives must be clean, consistent and adhere to a well thought out tracking plan. Protocols was built to automate and scale the data quality best practices developed over years of helping customers implement Segment. Investing in data quality will improve trust in your data, reduce time spent by your engineering and business teams navigating and validating data, and ultimately allow your business to grow faster. Protocols is a premium add-on feature available to Business Tier customers. If your plan includes Protocols, you can access it from the protocols path in your workspace . If your plan doesn’t include Protocols, contact your Segment account executive. There are four steps to using Protocols 1. Align teams with a Tracking Plan Good data quality starts with a well thought out Tracking Plan. With Protocols, you can define your events and corresponding properties in a Tracking Plan. This tracking plan becomes a central source of truth for product, engineering, analytics, and business teams. 2. Validate data quality with violations With your tracking plan living in Segment, you can apply it to 1 or more data sources. Any event or property that does not match the tracking plan will generate a violation. Violations are displayed in aggregated form to spot trends, and detailed form to help you quickly find and resolve discrepancies. 3. Enforce data standards with controls To maintain a high degree of quality over time, we offer strict controls to block non-conforming events. Blocked events can be forwarded to a separate quarantined Segment source for analysis and review. 4. Resolve data issues with transformations Even the most exacting data collection processes are subject to human error and organizational complexity. Transformations can be applied from within Protocols to change event and property names without touching code. Learn more Best Practices Learn more about tracking plans and why you need them. Tracking Plan Create a Tracking Plan to standardize your collected data. FAQ Get answers to Protocols questions that come up the most. Get Started: Learn more about Tracking Plans -> This page was last modified: 13 Jul 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page There are four steps to using Protocols Learn more Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Protocols Overview"
      },
      {
        "level": 2,
        "text": "There are four steps to using Protocols"
      },
      {
        "level": 2,
        "text": "Learn more"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/getting-started/",
    "title": " What is Segment? | Segment Documentation",
    "content": "Home / What is Segment? What is Segment? With Segment, you can collect, transform, send, and archive your first-party customer data . Segment simplifies the process of collecting data and connecting new tools, allowing you to spend more time using your data, and less time trying to collect it. You can use Segment to track events that happen when a user interacts with the interfaces. “Interfaces” is Segment’s generic word for any digital properties you own: your website, mobile apps, and processes that run on a server or OTT device. When you capture interaction data in Segment, you can send it (often in real-time) to your marketing, product, and analytics tools, as well as to data warehouses. In most cases, you won’t even need to touch your tracking code to connect to new tools. next Ready to get started? Let's walk through the steps to get up and running on Segment. Let's go! This page was last modified: 14 Dec 2021 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "What is Segment?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/destinations/actions/",
    "title": " Destination Actions | Segment Documentation",
    "content": "Home / Connections / Destinations / Destination Actions Destination Actions Free ✓ Team ✓ Business ✓ Add-on x ? Destination Actions are available for all Segment plans. Self-service plans are limited to two conditions per Trigger. See the available plans , or contact Support . On this page Benefits of Destination Actions Available Actions-based Destinations Destination Actions compatibility Components of a Destination Action Set up a destination action Migrate a classic destination to an actions-based destination Edit a destination action Disable a destination action Delete a destination action Test a destination action Customize mappings Suggested mappings Duplicate Mappings FAQ and troubleshooting The Destination Actions framework improves on classic destinations by enabling you to see and control how Segment sends the event data it receives from your sources, to actions-based destinations. Each Action in a destination lists the event data it requires, and the event data that is optional. You can also choose which event types, event names, or event property values trigger an Action. These Triggers and mappings make it possible to send different versions of the Action, depending on the context from which it is triggered. Each Actions-framework Destination you see in the Segment catalog represents a feature or capability of the destination which can consume data from your Segment source. The Action clearly lists which data from the events it requires, and which data is optional. For example, Amplitude requires that you always send a LogEvent , or Slack always requires a PostMessage .  Each Action also includes a default mapping which you can modify. Benefits of Destination Actions Easier setup : Users see fewer initial settings which can decrease the time spent configuring the destination. Increased transparency : Users can see the exact data that is sent to the destination, and when Segment sends it. For example, users can see exactly when Segment sends an IP address to FullStory or an AnonymousId to Amplitude. Improved customization : Users can determine how the events their sources trigger and map to actions supported by the destination. For example, define the exact events that are considered purchases by Braze. Partner ownership : Partners can own and contribute to any Actions-based destination that use cloud and device mode (web). Available Actions-based Destinations The following Actions-based Destinations are available: Destination Status 1Flow Web (Actions) Beta ABsmartly (Actions) GA Accoil Analytics GA Acoustic (Actions) GA Actable Predictive Beta Actions Pipedrive Beta Adobe Target Cloud Mode GA Adobe Target Web GA Aggregations.io (Actions) Beta Airship (Actions) GA Algolia Insights (Actions) GA Amazon Ads DSP and AMC Beta Amplitude (Actions) GA Angler AI Beta AppFit Beta Attio (Actions) Beta Avo GA Blackbaud Raiser's Edge NXT Beta Blend Ai Beta Braze Cloud Mode (Actions) GA Braze Cohorts GA Braze Web Device Mode (Actions) GA Canny (Actions) GA ChartMogul Beta CleverTap (Actions) GA Close GA CommandBar GA Contentstack Cloud Beta Contentstack Web Beta Cordial (Actions) GA Criteo Audiences GA Customer.io (Actions) GA Display and Video 360 (Actions) GA Drip (Actions) Beta Dynamic Yield by Mastercard Audiences Beta Emarsys (Actions) Beta Encharge (Actions) GA Equals Beta Facebook Conversions API (Actions) GA Facebook Custom Audiences (Actions) Beta Friendbuy (Cloud Destination) GA Friendbuy (Web Destination) GA Fullstory (Actions) GA Fullstory Cloud Mode (Actions) GA Gainsight Px Cloud (Actions) GA Gameball (Actions) Beta Gleap (Action) Beta Google Ads Conversions GA Google Analytics 4 Cloud GA Google Analytics 4 Web GA Google Sheets GA GWEN (Actions) Beta Hubble (Actions) Beta HubSpot Cloud Mode (Actions) GA HubSpot Web (Actions) GA Inleads AI GA Insider Audiences GA Insider Cloud Mode (Actions) GA Intercom Cloud Mode (Actions) GA Intercom Web (Actions) GA Iterable (Actions) GA Iterate Web (Actions) Beta Jimo (Actions) Beta June (Actions) GA Kafka Beta Kameleoon (Actions) Beta Klaviyo (Actions) GA Koala GA Koala (Cloud) GA LaunchDarkly (Actions) GA LaunchDarkly Audiences GA LinkedIn Audiences GA LinkedIn Conversions API GA Listrak (Actions) GA LiveLike Beta LiveRamp Audiences Beta LogRocket GA Loops (Actions) GA Marketo Static Lists (Actions) GA Metronome (Actions) GA Mixpanel (Actions) GA Moengage (Actions) GA Moloco MCM Beta Movable Ink (Actions) GA Optimizely Advanced Audience Targeting Beta Optimizely Data Platform Beta Optimizely Feature Experimentation (Actions) GA Pardot (Actions) GA Pendo Web (Actions) Beta Pinterest Conversions API GA PlayerZero Web GA Podscribe (Actions) GA Postscript Beta Pushwoosh Beta Qualtrics GA Reddit Conversions API GA Rehook Beta RevX Cloud (Actions) Beta Ripe Cloud Mode (Actions) GA Ripe Device Mode (Actions) GA Rokt Audiences (Actions) Beta Rupt Beta Salesforce (Actions) GA Salesforce Marketing Cloud (Actions) GA Saleswings (Actions) GA Schematic Beta Screeb Web (Actions) Beta Segment Connections GA Segment Profiles GA SendGrid GA SingleStore GA Slack (Actions) GA Snapchat Conversions API GA Sprig (Actions) GA StackAdapt Beta Survicate (Actions) Beta Taboola (Actions) Beta Talon.One (Actions) GA The Trade Desk Crm Beta TikTok Audiences GA TikTok Conversions GA Tiktok Offline Conversions Beta TikTok Pixel Beta Toplyne Cloud Mode (Actions) Beta Topsort Beta Upollo Web (Actions) Beta Usermaven (Actions) Beta UserMotion (Actions) Beta Userpilot Cloud (Actions) Beta Userpilot Web (Actions) Beta Voucherify (Actions) Beta VWO Cloud Mode (Actions) GA VWO Web Mode (Actions) Beta Webhooks (Actions) GA Wisepops GA Xtremepush (Actions) Beta Yahoo Audiences Beta Destination Actions compatibility Destination Actions are available to all customers on all Segment plans. Destination Actions do not require that you disable or change existing destinations. However, to prevent data duplication in the destination tool, you should make sure you aren’t sending the data through both a standard destination and the Actions destination at the same time. You can still use the Event Tester with Destination Actions, and event delivery metrics are still collected and available in the destination information pages. If you are using Protocols, Destination Actions actions are applied after schema filters and transformations . If you are using destination filters , Actions are applied after the filters - meaning that they are not applied to data that is filtered out. Destination Actions can not yet be accessed or modified using the Segment APIs. Components of a Destination Action A Destination Action contains a hierarchy of components, that work together to ensure the right data is sent to the destination. Component Description Global Settings Define authentication and connection-related information like API and Secret keys. Mappings Handle the individual calls to the destination. In them, you define what type of call you want to make to the destination, and what Triggers that call. Individual Destination Actions may come enabled with some predefined mappings to handle common events like Screen calls, Identify calls, and Track calls. Mappings have two components that make this possible: Triggers and an Action . Triggers Enable you to define when the corresponding Action fires. As part of a Trigger, you can use condition-based filters to narrow the scope of the Trigger. Triggers don’t support matching on event fields containing .$ or .$. , which reference an array type. Self-service users can add a maximum of two conditions per Trigger. Actions Determine the information sent to the destination. In the Configure action section, you map the fields that come from your source, to fields that the destination expects to find. Fields on the destination side depend on the type of action selected. For example, in the Amplitude (Actions) destination, you define your API and Secret keys in the destination’s global settings. Then, the provided Page Calls mapping: Triggers the action on all incoming Page events. Runs the Log Event action, to map your incoming data to Amplitudes properties. Set up a destination action To set up a new Actions-framework destination for the first time: Log in to the Workspace where you want to add the new destination, go to the Catalog page, and click the Destinations tab. (You can also get to this screen by clicking Add Destination either from an existing Source, or from your list of existing destinations.) Click the Destination Actions category in the left navigation, then click the destination you want to add. From the preview screen that appears, click Configure . If prompted, select the source you want to connect to the new destination. Enter your credentials. This could be an API Key and secret key, or similar information that allows the destination to connect to your account. Next, choose how you want to set up the destination, and click Configure Actions . You can choose Quick Setup to use the default mappings, or choose Customized Setup (if available) to create new mappings and conditions from a blank state. You can always edit these mappings later. (Optional) Click Suggest Mappings to get suggested mappings. Learn more about suggested mappings . Once you’re satisfied with your mappings, click Create Destination . You must configure and enable at least one mapping to handle a connected source’s event(s) in an Actions-framework destination in order for data to send downstream. \nEvents send downstream in the order in which they appear in the mappings UI. There is no mechanism through which you can control the order of events that send to the downstream destinations outside of that. Migrate a classic destination to an actions-based destination Moving from a classic destination to an actions-based destination is a manual process. Segment recommends that you follow the procedure below: Create the actions-based destination with your development or test source. Copy API keys, connection details, and other settings from the classic destination to the actions-based destination. Refer to the actions-based destination’s documentation for information about migrating specific settings. Disable the classic version of the destination, and enable the actions-based version. Verify that data is flowing from the development or test source to the partner tool. Repeat the steps above with your production source. Migrate your destination filters from the classic destination to the actions destination You can only migrate your destination filters using the Public API if you’re on the business tier plan. This functionality isn’t available in the Segment app. To migrate your destination filters to your actions destination from the classic destination: Send a request to the Public API endpoint. Use List Filters from Destination . The destinationId can be found in the URL while viewing the destination in your Segment workspace. Grab the response and parse through the data.filters object. Each object returned inside the data.filters object is an individual filter associated with the specified destination. Send individual POST requests to the Public API endpoint. Use Create Filter for Destination , for each of the filters from step 2. Specify the Actions destinationId , found in the URL when viewing that destination. The body of the request is the individual filters from step 2. If the bodies of those requests don’t already include the field \"enabled\": true , make sure to enable each of those filters after you create them. Migrate to an actions-based destination using Destination Filters For a more comprehensive migration from a classic destination to an actions-based destination, follow the steps outlined below. This implementation strategy is only available for customers on a Segment Business Tier plan with access to Destination Filters . By adding additional line of defense with Destination Filters, you remove the possibility of duplicate events or dropped events and ensure that events sent before/after a specified received_at timestamp are sent to each destination. This migration strategy involves configuring a destination filter on both the Classic destination and the Actions destination. Configure the classic destination filter to block events by the received_at field with a certain value, and the Actions destination to drop events until the received_at timestamp field reaches that same value. Destination Filters within the UI have a limitation where they cannot access any top-level fields, but this is not a limitation for Destination Filters created by the Public API using FQL . Because the received_at is a top-level field in the payload, you’ll need to create a destination filter with the Public API and submit the request with that FQL information described below. By combining these Filters, Segment sends events through the Classic integration up until a specified time and then blocks events after that time. Then the Actions integration blocks events until that specified time, and only allows events beginning at that specified time. The following code samples show you how you can create filters for your destinations using the Create Filter for Destination Public API operation. Classic destination Endpoint : POST https://api.segmentapis.com/destination/classic_destination_id_from_url/filters // JSON BODY : \n{\n  \"sourceId\": \"add_source_id_here\",\n  \"destinationId\": \"classic_destination_id_from_url\",\n  \"title\": \"drop event after (timestamp) received_at > value April 4, 2023 19:55pm\",\n  \"description\": \"drop event after (timestamp) received_at > value April 4, 2023 19:55pm\",\n  \"if\": \"(received_at >= '2023-04-21T19:55:00.933Z')\",\n  \"actions\": [\n    {\n      \"type\":\"DROP\"\n    }\n  ],\n  \"enabled\": true\n} Actions destination Endpoint : POST https://api.segmentapis.com/destination/actions_destination_id_from_url/filters // JSON BODY :\n{\n  \"sourceId\": \"add_source_id_here\",\n  \"destinationId\": \"actions_destination_id_from_url\",\n  \"title\": \"drop event before (timestamp) received_at < value April 4, 2023 19:55pm\",\n  \"description\": \"drop event before (timestamp) received_at < value April 4, 2023 19:55pm\",\n  \"if\": \"(received_at < '2023-04-21T19:55:00.933Z')\",\n  \"actions\": [\n    {\n      \"type\":\"DROP\"\n    }\n  ],\n  \"enabled\": true\n} After configuring the Destination Filter on both the Classic and Actions destination, see each destination’s Filters tab and enable the filters. After completing the migration, you can disable the Classic destination on the Settings page, and remove each of the filters from both destinations. Edit a destination action You can add or remove, disable and re-enable, and rename individual actions from the Actions tab on the destination’s information page in the Segment app. Click an individual action to edit it. From the edit screen you can change the action’s name and mapping, and toggle it on or off. See Customizing mappings for more information. When an Action is created, it’s disabled by default, to ensure that it’s only used after being fully configured. To begin sending data through an Action, enable it on the Actions page by selecting the toggle so that it appears blue. Disable a destination action If you find that you need to stop an action from running, but don’t want to delete it completely, you can click the action to select it, then click the toggle next to the action’s name to disable it. This takes effect within minutes, and disables the action until you reenable it. Delete a destination action To delete a destination action: click the action to select it, and click Delete (the trash can icon). This takes effect within minutes, and removes the action completely. Any data that would have gone to the destination is not delivered. Once deleted, the saved action cannot be restored. Test a destination action To test a destination action, follow the instructions in Testing Connections . You must enable a mapping in order to test the destination. Otherwise, this error occurs: You may not have any subscriptions that match this event. You can also test within the mapping itself. To test the mapping: Navigate to the Mappings tab of your destination. Select a mapping and click the … and select Edit Mapping . In step 2 of the mappings edit page, click Load Test Event from Source to add a test event from the source, or you can add your own sample event. Scroll to step 4 on the page, and click Test Mapping to test the mapping and view the response from the destination. Test Mapping might not return the events you're looking for Segment only surfaces a small subset of events for the Test Mapping feature and might not always return the event you’re looking for. If you’d like to test with a specific event, copy a specific event from your Source Debugger and paste it into the Add test event interface. Customize mappings If you use the default mappings for a destination action, you don’t need to customize the mapping template for the action. You can edit the fields later if you find that the defaults no longer meet your needs. Actions-based destinations have a limit of 50 individual mappings. To create a custom destination action, start from the Actions tab.\nIf necessary, click New Mapping to create a new, blank action. In the edit panel, define the conditions under which the action should run. Test those conditions to make sure that they correctly match an expected event.\n This step looks for events that match the criteria in the debugger queue , so you might need to Trigger some events with the expected criteria to test your conditions. You can skip the test step if needed, and re-try it at any time. Select data models to enrich your events with. Set up the data mapping from the Segment format to the destination tool format. You can click the Source field, then select the Enrichments tab to view and select Enrichments to use. Test the mapping with data from a sample event.\n The edit panel shows you the mapping output in the format for the destination tool. The Select Object option sends the entire object from the event, while the Edit Object option lets you map each individual property. You can change your mapping as needed and re-test. When you’re satisfied with the mapping, click Save . Segment returns you to the Mappings table. In the Mappings table Status column, verify that the Enabled toggle is on for the mapping you just customized. The required fields for a destination mapping appear automatically. Click the + sign to see optional fields. Suggested mappings Suggested mappings is fully available for RETL mappings, and is in public beta for event streams and connections. Segment offers suggested mappings that automatically propose relevant destination fields for both model columns and payload elements. For example, if your model includes a column or payload field named transaction_amount , the feature might suggest mapping it to a destination field like Amount or TransactionValue . This automation, powered by intelligent autocompletion, matches and identifies near-matching field names to streamline the setup. For more information, see Segment’s suggested mappings blogpost and the Suggested Mappings Nutrition Label . Review the suggested mappings for accuracy before finalizing them as the suggestions aren’t guaranteed to be 100% accurate. Coalesce function The coalesce function takes a primary value and uses it if it is available. If the value isn’t available, the function uses the fallback value instead. Replace function The replace function allows you to replace a string, integer, or boolean with a new value. You have the option to replace up to two values within a single field. Flatten function The flatten function allows you to flatten a nested object to an object with a depth of 1. Keys are delimited by the configured separator. For example, an object like {a: { b: { c: 1 }, d: 2 } } will be converted to { ‘a.b.c’: 1, ‘a.d’: 2 }. Conditions Self-service users can add a maximum of two conditions per Trigger. Mapping fields are case-sensitive. The following type filters and operators are available to help you build conditions: Event type ( is / is not ). This allows you to filter by the event types in the Segment Spec . Event name ( is , is not , contains , does not contain , starts with , ends with ). Use these filters to find events that match a specific name, regardless of the event type. Event property ( is , is not , less than , less than or equal to , greater than , greater than or equal to , contains , does not contain , starts with , ends with , exists , does not exist ).  Use these filters to trigger the action only when an event with a specific property occurs. You can specify nested properties using dot notation, for example context.app.name . If the property might appear in more than one format or location, you can use an ANY statement and add conditions for each of those formats. For example, you might filter for both context.device.type = ios as well as context.os.name = \"iPhone OS \" The does not exist operator matches both a null value or a missing property. The available operators depend on the property’s data type: Data Type Supported Operators string is , is not , contains , does not contain , starts with , ends with string or numeric is less than , is less than or equal to , is greater than , is greater than or equal to boolean is true , is false You can combine criteria in a single group using ALL or ANY .  Use an ANY to “subscribe” to multiple conditions. Use ALL when you need to filter for very specific conditions. You can only create one group condition per destination action. You cannot created nested conditions. Unsupported Special Characters Mappings do not support the use of double quotes “ or a tilde ~ in the trigger fields. In mapping fields, the . character is not supported unless it’s being used to access an object key. If a string has a . in it, that is not supported. Limitations Mapping fields don’t support dot notation. For example, properties.amount.cost or properties_amount.cost aren’t supported. Destination Filters Destination filters are compatible with Destination Actions. Consider a Destination Filter when: You need to remove properties from the data sent to the destination You need to filter data from multiple types of call (for example, Track, Page, and Identify calls) If your use case does not match these criteria, you might benefit from using Mapping-level Triggers to match only certain events. Duplicate Mappings You can use the Duplicate Mappings feature to create an exact copy of a mapping. The duplicated mapping has the same configurations and enrichments as your original mapping. Duplicate Mappings supports Actions destinations , Reverse ETL destinations , and destinations connected to Engage Audiences and Journeys . To duplicate your mappings: Navigate to Connections > Destinations and select the destination with the mappings you’d like to copy. On the destination’s Mappings tab, select the menu button ( … ) and click Duplicate Mapping . Review the popup and click Duplicate Mapping . Segment creates a disabled mapping with the name “Original Mapping Name (Copy)”. You must enable the mapping for data to flow. FAQ and troubleshooting Validation error when using the Event Tester When you send an event with an actions destination Event Tester that doesn’t match the trigger of any configured and enabled mappings, you’ll see an error message that states, You may not have any subscriptions that match this event. To resolve the error, create a mapping with a trigger to handle the event being tested, or update the test event’s payload to match the trigger of any existing mappings. Data not sending downstream If no mappings are enabled to trigger on an event that has been received from the connected source, the destination will not send any events. Ensure that at least one mapping has been configured and enabled in the destination mappings for an event that you would like to reach downstream. Events without mappings enabled to handle them display as being discarded due to “No matching mapping” in a destination’s Delivery Overview. Multiple mappings triggered by the same event When the same event triggers multiple mappings, a request will be generated for each mapping that’s configured to trigger on an event. For example, for the Subscription Updated event, if two mappings are enabled and both have conditions defined to trigger on the Subscription Updated event, the two requests will be generated and sent to the destination for each Subscription Updated event. Oauth “access token expired” message shown in Segment UI Access Tokens that were generated from initial authorization, for example, when you connect a destination via Oauth, are always short-lived. Commonly, the token remains valid for 30 minutes to 1 hour. When Segment receives 401 error responses from the destination after a token has expired, it will automatically make another request to the destination for a new token and will then retry the event. Therefore, 401 responses are sometimes expected and do not indicate an event failure. There are three event flows when events are received and sent to a destination: through source through event tester through actions tester in mapping screen The underlying systems for these flows have their own copy of the token, which can expire at different points in time.\nThrefore, if you see a 401 error in a sample response, it is likely that you’ll also see another request was made after it, to ask the downstream destination for a new token. Then one more request was made to actually send the data in your payload to the downstream destination. Is it possible to map a field from one event to another? Segment integrations process events through mappings individially. This means that no context is held that would allow you to map a value from one event to the field of a subsequent event. Each event itself must contain all of the data you’d like to send downstream in regards to it. For example, you cannot send email in on an Identify call and then access that same email field on a Track call that comes in later if that Track call doesn’t also have email set on it. I’m getting a ‘Couldn’t load page’ error when viewing or editing a mapping This issue can occur due to a browser cache conflict or if an event property name includes a / . To resolve it, try clearing your browser cache or accessing the mapping page in an incognito window. Additionally, check if the mapped property name contains a / . If it does, rename the property to remove the / and update the mapping. This page was last modified: 09 Jan 2025 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Benefits of Destination Actions Available Actions-based Destinations Destination Actions compatibility Components of a Destination Action Set up a destination action Migrate a classic destination to an actions-based destination Edit a destination action Disable a destination action Delete a destination action Test a destination action Customize mappings Suggested mappings Duplicate Mappings FAQ and troubleshooting Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Destination Actions"
      },
      {
        "level": 2,
        "text": "Benefits of Destination Actions"
      },
      {
        "level": 2,
        "text": "Available Actions-based Destinations"
      },
      {
        "level": 2,
        "text": "Destination Actions compatibility"
      },
      {
        "level": 2,
        "text": "Components of a Destination Action"
      },
      {
        "level": 2,
        "text": "Set up a destination action"
      },
      {
        "level": 2,
        "text": "Migrate a classic destination to an actions-based destination"
      },
      {
        "level": 3,
        "text": "Migrate your destination filters from the classic destination to the actions destination"
      },
      {
        "level": 3,
        "text": "Migrate to an actions-based destination using Destination Filters"
      },
      {
        "level": 2,
        "text": "Edit a destination action"
      },
      {
        "level": 2,
        "text": "Disable a destination action"
      },
      {
        "level": 2,
        "text": "Delete a destination action"
      },
      {
        "level": 2,
        "text": "Test a destination action"
      },
      {
        "level": 2,
        "text": "Customize mappings"
      },
      {
        "level": 2,
        "text": "Suggested mappings"
      },
      {
        "level": 3,
        "text": "Coalesce function"
      },
      {
        "level": 3,
        "text": "Replace function"
      },
      {
        "level": 3,
        "text": "Flatten function"
      },
      {
        "level": 3,
        "text": "Conditions"
      },
      {
        "level": 2,
        "text": "Duplicate Mappings"
      },
      {
        "level": 2,
        "text": "FAQ and troubleshooting"
      },
      {
        "level": 3,
        "text": "Validation error when using the Event Tester"
      },
      {
        "level": 3,
        "text": "Data not sending downstream"
      },
      {
        "level": 3,
        "text": "Multiple mappings triggered by the same event"
      },
      {
        "level": 3,
        "text": "Oauth “access token expired” message shown in Segment UI"
      },
      {
        "level": 3,
        "text": "Is it possible to map a field from one event to another?"
      },
      {
        "level": 3,
        "text": "I’m getting a ‘Couldn’t load page’ error when viewing or editing a mapping"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/spec/best-practices-identify/",
    "title": " Best Practices for Identifying Users | Segment Documentation",
    "content": "Home / Connections / Spec / Best Practices for Identifying Users Best Practices for Identifying Users On this page Identifying users AnonymousId generation Best options for userIds When to call Identify Soft User Registration Full User Registration Merging Identified and Anonymous user profiles User profiles in warehouses ID expiration and overwriting Linking server and client generated Ids The most important calls you make with Segment are the identify and track calls. When you use these calls together, you can attribute actions on your site or app to individuals, and gain a better understanding of their activities, identity, and use patterns over time. Tracking users with the identify and track calls reduces the number of Monthly Tracked Users you are billed for. Identifying users The Identify call specifies a customer identity that you can reference across the customer’s lifetime. There are instances where you want to record information about a user that isn’t already known to you. An example of this might be, a user that visits your site and doesn’t register, but they do give you their email address through a newsletter email sign-up form. In this instance, you would record that email address as a trait, and for the identifier (ID), you would use anonymous ID. When you make an identify call using Segment’s Analytics.js library, Segment saves the userId to the browser cookie, and writes all the user traits in localStorage . If you’re using one of the Segment mobile libraries, the userId and traits are stored in the device’s memory. This makes it possible to append the user’s data to all subsequent page calls or track calls for the user, so you can properly attribute those actions. If a user returns to your site after the cookie expires , Analytics.js looks for an old ID in the user’s localStorage , and if one is found, sets it as the user’s ID again in a new cookie. If the user clears their cookies and localStorage , all of the IDs are removed and the user gets a completely new anonymousId when they next visit the page. Whenever possible, follow the Identify call with a Track event that records what caused the user to be identified. AnonymousId generation If you’re using Segment’s browser or mobile libraries, the Segment SDK generates and sets a UUID as anonymousID at the user’s first visit to your site. That anonymousId is saved in the user’s cookie, as well as localStorage, and will stick with that user until the cache is cleared or a reset call is triggered. You can use the anonymousId to link events performed by the user as they navigate around your website. When you track the anonymousId , you can attribute activities over multiple days to the same user by collecting all of the activities with that ID. If a user chooses to register for your site, or log in to your app, you can Identify them, and still include their anonymousId in the event payload along with the new userId . If you use Segment’s server libraries, you must generate an anonymousId manually. It can be any pseudo-unique identifier, for example, you might use a sessionId from a backend server. Best options for userIds Segment recommends that you use a unique user identifier (UUID) that won’t change for your userId . A userId should be a robust, static, unique identifier that you recognize a user by in your own database systems. Because these IDs are consistent across a customer’s lifetime, you should include a userId in Identify calls as often as you can. If you don’t have a userId, you need to include an anonymousId in your Identify call in order to record identifying information about your user. Ideally, the userId could be a database ID. For example, if you’re using MongoDB it might be a row identifier and look something like 507f191e810c19729de860ea . These can also be UUID s that you generate somewhere in your application. You can also use identifiers that you get from other tools - such as Shopify or Braze - however this approach can lead to extra complexity in your systems. Segment does not recommend using simple email addresses or usernames as a User ID, as these can change over time. Segment recommends that you use static IDs instead, so the IDs never change. When you use a static ID, you can still recognize the user in your analytics tools, even if the user changes their email address. And even better, you can link your analytics data with your own internal database. Tip! Even though Segment doesn’t recommend using an email address or a username as a User ID, you can still send that identifying information in your Identify call as traits . When to call Identify You should make an Identify call in the following situations: When the user provides any identifying information (such as a newsletter sign-up with email and name) When first you create a user (and so it is assigned a userId ) When a user changes information in their profile When a user logs in (Optional) Upon loading any pages that are accessible by a logged in user Soft User Registration An anonymous user visits the site for the very first time. The home page has the analytics.js tracking snippet loaded in its header. When the page loads, this sets off the default Page call to Segment. The Segment SDK generates and sets anonymousId . analytics . page ({ path : ' / ' , title : ' Home Page ' , url : ' https://somesite.com/ ' , }) You can see in this full page event, the anonymousId is populated, and the userId is null. { \" anonymousId \" : \" bd077b70-816b-448b-ae79-2f5f7d856513 \" \" context \" : { \" ip \" : \" 0.0.0.0 \" , \" library \" : { \" name \" : \" analytics.js \" , \" version \" : \" 3.11.4 \" }, \" locale \" : \" en-US \" , \" page \" :{ \" path \" : \" / \" \" referrer \" : \"\" , \" search \" : \"\" , \" title \" : \" Home Page \" , \" url \" : \" https://somesite.com \" }, \" userAgent \" : \" Mozilla/5.0 \" }, \" integrations \" : {}, \" messageId \" : \" ajs-84d32beb4273e661a2257bfef41c4964 \" , \" originalTimestamp \" : \" 2020-04-23T22:38:48.55Z \" , \" properties \" :{ \" path \" : \" / \" , \" referrer \" : \"\" , \" search \" : \"\" , \" title \" : \" Home Page \" , \" url \" : \" https://somesite.com \" }, \" receivedAt \" : \" 2020-04-23T22:38:48.55Z \" , \" sentAt \" : \" 2020-04-23T22:38:48.55Z \" , \" timestamp \" : \" 2020-04-23T22:38:48.55Z \" , \" type \" : \" page \" , \" userId \" : null } The user signs up for an email newsletter and fills out the form giving you their first and last name, as well as their email address. At this point, you will fire off an Identify call. You won’t yet assign them a user ID in this example, but you can still grab these traits about them. analytics . identify ({ firstName : ' Joe ' , lastName : ' Visitor ' , email : ' jvisitor@thissite.com ' }); You’ll notice the Identify call contains no userId . These traits will be associated to the anonymousId that is available in the user’s cookie and localStorage . { \" anonymousId \" : \" bd077b70-816b-448b-ae79-2f5f7d856513 \" \" context \" : { \" ip \" : \" 0.0.0.0 \" , \" library \" : { \" name \" : \" analytics.js \" , \" version \" : \" 3.11.4 \" }, \" locale \" : \" en-US \" , \" page \" :{ \" path \" : \" / \" \" referrer \" : \"\" , \" search \" : \"\" , \" title \" : \" Email Signup \" , \" url \" : \" https://somesite.email \" }, \" userAgent \" : \" Mozilla/5.0 \" }, \" integrations \" : {}, \" messageId \" : \" ajs-84d32beb4273e661a2257bfef41c4964 \" , \" originalTimestamp \" : \" 2020-04-23T22:38:48.55Z \" , \" properties \" :{ \" path \" : \" / \" , \" referrer \" : \"\" , \" search \" : \"\" , \" title \" : \" Home Page \" , \" url \" : \" https://somesite.com \" }, \" receivedAt \" : \" 2020-04-23T22:38:48.55Z \" , \" sentAt \" : \" 2020-04-23T22:38:48.55Z \" , \" timestamp \" : \" 2020-04-23T22:38:48.55Z \" , \" traits \" { \" email \" : \" jvisitor@thissite.com \" , \" first_name \" : \" Joe \" \" last_name \" : \" Visitor \" }, \" type \" : \" page \" , \" userId \" : null } Full User Registration An anonymous visitor registers for an account and becomes a known user. The account creation process allows you to assign a userId from your production database and capture additional traits. For this example, the userId that is assigned is “123abc”. This is when you’ll want to fire an Identify call with this user’s newly assigned userId and additional traits. analytics . identify ( `123abc` ,{ phone : ' 555-555-5555 ' , address : { street : ' 6th Street ' , city : ' San Fransisco ' , state : ' CA ' , postalCode : ' 94103 ' , country : ' US ' , } }); After you fire the Identify call with the userId , you’ll notice that the payload now has both a userId and an anonymousId attributed to the user. { \" anonymousId \" : \" bd077b70-816b-448b-ae79-2f5f7d856513 \" \" context \" : { \" ip \" : \" 0.0.0.0 \" , \" library \" : { \" name \" : \" analytics.js \" , \" version \" : \" 3.11.4 \" }, \" locale \" : \" en-US \" , \" page \" :{ \" path \" : \" / \" \" referrer \" : \"\" , \" search \" : \"\" , \" title \" : \" Email Signup \" , \" url \" : \" https://somesite.email \" }, \" userAgent \" : \" Mozilla/5.0 \" }, \" integrations \" : {}, \" messageId \" : \" ajs-84d32beb4273e661a2257bfef41c4964 \" , \" originalTimestamp \" : \" 2020-04-23T22:38:48.55Z \" , \" properties \" :{ \" path \" : \" / \" , \" referrer \" : \"\" , \" search \" : \"\" , \" title \" : \" Home Page \" , \" url \" : \" https://somesite.com \" }, \" receivedAt \" : \" 2020-04-23T22:38:48.55Z \" , \" sentAt \" : \" 2020-04-23T22:38:48.55Z \" , \" timestamp \" : \" 2020-04-23T22:38:48.55Z \" , \" traits \" { \" phone \" : ' 555-555-5555 ' , \" address \" : { \" street \" : ' 6th Street ' , \" city \" : ' San Fransisco ' , \" state \" : ' CA ' , \" postalCode \" : ' 94103 ' , \" country \" : ' US ' , } }, \" type \" : \" page \" , \" userId \" : \" 123abc \" } Merging Identified and Anonymous user profiles The illustration below shows a timeline with a user’s interactions on a website, including sample API calls above that show Segment calls, and the user’s anonymousId and userId . When the user first visits a page, Analytics.js automatically assigns the user an anonymousId and saves it to the user’s localStorage . As the user interacts with the site, for example clicking around to different pages, Analytics.js includes this anonymousId and some contextual information with each Page and Track call. The contextual information might be the user’s IP address, browser, and more . When a user signs up to create an account on the website, the .identify(\"userId\") and .track(“Signed Up”) events fire, in that order. You pull the userId unique to the user from your systems, and send it to the Segment library so you can label that user’s later events with their ID. The later Track call (“Signed Up”) contains both the userId and the automatically-collected anonymousId for the user, and any other information you capture about them -  such as their first name, last name, and email address. The example below shows an Identify call including user traits. It uses a database ID ( 97980cfea0067 ) as the userId . analytics . identify ( \" 97980cfea0067 \" , { name : \" Peter Gibbons \" , //user trait email : \" peter@example.com \" , //user trait plan : \" premium \" //user trait }); For a Track call, information about this event is stored either in the context field or in the event properties . The example below shows a Track call including properties that tell you about the user. analytics . track ( \" Signed Up \" , { userId : \" 97980cfea0067 \" , //event property name : \" Peter Gibbons \" , //event property email : \" peter@example.com \" , //event property plan : \" premium \" //event property }); Additionally, Analytics.js adds a message_id and four timestamps to the call. Now, as the user interacts with your site and different buttons or links that you track using Segment, their userId and anonymousId are sent with each subsequent tracking API call. UserId merge examples Let’s go through some more scenarios to explain how an anonymousId is assigned and how it might be merged with a userId . Scenario #1 - Multi-day, single device If a user clicks on an ad and is directed to a webpage, they are assigned an anonymousId . While this user is anonymous, they navigate to different pages and click around on the website. Say they come back two days later from the same device, sign up, and are assigned a userId from your database. For simplicity, we’re assuming that the user has not cleared their cookies or localStorage , where the original anonymousId is stored. If they had, they’d be assigned a new anonymousId when they visited the website, and the userId they got when they register on the website would not be attached to the activities tracked with the old anonymousId . Scenario #2 - Multi-day, multi-device, single login In this scenario, the person uses both a web browser, and a mobile application to interact with your site. In each case, they are assigned a different anonymousId . In this scenario, the user signs up on the web browser, so Segment assigns their web session a userId . However, because they do not log in on the mobile application, Segment cannot tie the mobile activity to this specific user. Their mobile application activity remains anonymous unless they log in on the mobile application. Scenario #3 - Multi-day, multi-device, multiple logins Similar to the previous scenario, the user accessed both your website and mobile application, and also logged in on both. In this case, both sessions on the web and mobile app receive the user’s userId , so Segment can tie the anonymous activity on both web and mobile to this user. User profiles in warehouses Your data warehouse has a schema for each of your Segment sources. User information is stored in two tables in your source schemas - the identifies and users table. The identifies table contains all of your identify events, and the timestamps for these events. Every time you make an Identify call, Segment adds the userId , anonymousId , any updated or added user traits from the call, as well as the timestamp of when the call was made. Your identifies table is your first stop when you have questions about users and their traits. The users table contains only unique Identify method calls, and is a collation of the identifies table. The users table is the single source of truth for a user’s most up-to-date traits. These tables only contain information about a user once they have been identified. However, you can still find information about an anonymous user on the pages , screens , and tracks tables, as well as the individual track event tables. ID expiration and overwriting The Segment ID cookie is set with a one year expiration. However, there are some ways an ID can be reset or overwritten: If you call reset during a user’s browser session, it removes both their userId and anonymousId , which means the user generates a new anonymousId on the next visit. If the user manually clears their cookies and local storage, they generate a new anonymousId on the next visit. If you invoke any call before you set an anonymousId , Segment automatically sets the anonymousId first. This means if you explicitly set an anonymousId , you might give the user two anonymousId s or overwrite an existing one. If you fetch the anonymousId using analytics.user().anonymousId() before one is set, Segment generates and sets an anonymousId rather than returning null . If you call analytics.identify() with a userId that is different from the currently cached userId , this can overwrite the existing one and cause attribution problems. If you generate a new anonymousId on a server library, and pass it from the server to the browser, this could overwrite the user’s existing anonymousId . Remember, if a user has multiple devices, they can have different anonymousId s on each different device. Linking server and client generated Ids If you’re tracking on the client and on the server, the anonymousId can be retrieved from localStorage on the client and passed to the server. You can access a user’s anonymousId using the following call: analytics . user (). anonymousId () If you’re identifying on the server, then you will want to pass the user ID from the server to the client using an Identify call with the anonymousId . That will allow the userId to be aliased with the existing anonymousId and stored in the cookie in localStorage. With that, all previous anonymous activity and all subsequent activity is associated to the newly generated userId , as well as existing anonymousId s. There are some advantages to sending details about your users directly from your server once the user registers. Server library Identify calls are invisible to the end user, making them more secure, and much more reliable. Or, if you want to send user data that is sensitive or which you don’t want to expose to the client, then you can make an Identify call from the server with all the traits you know about the user. More about collecting data on the client or server in Segment’s documentation. Aliasing from a server library If you plan to track anonymous visitors from the browser and only make Identify calls from your server libraries, Kissmetrics and Mixpanel might require that you make an Alias call to link the records. The Alias call links client-side anonymous visitors with server-identified users. This isn’t recommended, but if you do this, read the Kissmetrics and Mixpanel specific alias docs. Common questions There are a few things that might cause your numbers to be off. Missing sign-ups The most common problem people run into when tracking new user signups client-side is that only a portion of their new users are showing up in reports. This is usually caused by the page redirecting or reloading before the tracking calls get a chance to run. Segment recommends that you make those calls from a welcome page after the user registers, rather than trying to squeeze in the tracking calls on the sign-up page itself. Anonymous history is lost This is usually only an issue in Mixpanel , since it’s the only destination that requires a call to alias in the browser to link anonymous browsing history to a new identified user. Remember that for destinations that require aliasing, you must make the Alias call before you make the Identify call for that user. Even if you make an Identify call from a server library, it can’t happen before the client-side alias . Can you update a userId? Unfortunately, there is no way to change an existing userId within Segment. Historical data with an existing userId remains the same, and a new userId will not replace the existing userId in Segment event call logs. For downstream destinations, consult the corresponding docs about user profile behaviors when using a new userId . Changing a userId is incredibly hard to do, as that is a fundamental part of analytics. While some downstream analytics tools let you change a userId once set, others don’t and the process will be different for each tool. This page was last modified: 15 Mar 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Identifying users AnonymousId generation Best options for userIds When to call Identify Soft User Registration Full User Registration Merging Identified and Anonymous user profiles User profiles in warehouses ID expiration and overwriting Linking server and client generated Ids Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Best Practices for Identifying Users"
      },
      {
        "level": 2,
        "text": "Identifying users"
      },
      {
        "level": 2,
        "text": "AnonymousId generation"
      },
      {
        "level": 2,
        "text": "Best options for userIds"
      },
      {
        "level": 2,
        "text": "When to call Identify"
      },
      {
        "level": 2,
        "text": "Soft User Registration"
      },
      {
        "level": 2,
        "text": "Full User Registration"
      },
      {
        "level": 2,
        "text": "Merging Identified and Anonymous user profiles"
      },
      {
        "level": 3,
        "text": "UserId merge examples"
      },
      {
        "level": 2,
        "text": "User profiles in warehouses"
      },
      {
        "level": 2,
        "text": "ID expiration and overwriting"
      },
      {
        "level": 2,
        "text": "Linking server and client generated Ids"
      },
      {
        "level": 3,
        "text": "Aliasing from a server library"
      },
      {
        "level": 3,
        "text": "Common questions"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/getting-started/use-cases/setup//",
    "title": " Use Cases Setup | Segment Documentation",
    "content": "Home / Getting started / Use cases / Use Cases Setup Use Cases Setup On this page Use case setup overview Example setup: Personalize winback Activate your data with Unify and Engage Next steps Use Cases help you onboard quickly and efficiently to Segment by guiding you through specific steps tailored to your business needs. This page walks you through the steps to set up a use case in your Segment instance. Permissions To implement a use case, you’ll need to be a Workspace Owner for your Segment account. See the Roles documentation for more information. You can onboard to Segment with a Use Case if you’re a new Business Tier customer or haven’t yet connected a source and destination. Use case setup overview From a high level, setting Segment up with a use case takes place in four stages: Pick your business goal . What do you want to achieve?  Choose from 4 common business goals like optimizing advertising, personalizing first conversions, boosting retention, and increasing customer retention. Select a use case . After you pick your business goal, Segment shows you several potential use cases from which to choose. Follow the in-app guide . With your use case chosen, Segment shows you an interactive checklist of events to track, as well as sources and destinations that Segment recommends you connect. You’ll carry these steps out in a sandboxed development environment. Test and launch your setup . Push your connections to a production environment and verify that events flow as expected through the debugger. After you’re done, your Segment instance is up and running. Example setup: Personalize winback This section provides a detailed, step-by-step guide to setting up the Personalize Winback use case from the Personalize communications and product experiences business goal in your Segment account. All use cases follow this same setup flow. Step 1: Navigate to Use Cases Log in to your Segment account. If you see the Welcome to Segment screen, click Get Started . If logging in takes you to your Segment workspace, click Guided Setup . Step 2: Pick your business goal and select a use case Choosing a use case Segment lets you implement one use case. If you’re not sure which use case to choose, view Choosing a Use Case . In the What is your business goal? screen, select Personalize communications and product experiences , then click Next . Segment moves you to the Which use case would you like to set up? screen. Choose Personalize winback , then click Next . Segment shows you information about dev and prod labels. After you’ve read it, click Next . Segment takes you to the Setup checklist page. Working with dev and prod environments For most cases, you’ll want to start with development or staging sources to test and debug your Segment implementation. This approach lets you verify that everything is working correctly before sending live data downstream. To facilitate this, Segment automatically creates development (dev) and production (prod) spaces for you and labels your sources accordingly to simplify tracking. Segment strongly recommends beginning your setup in the dev environment. This allows for thorough testing and debugging of your configuration. Once you’re confident in your dev setup, Segment will guide you on how to apply these configurations to your live production sources. Step 3: Review suggested events Changing your use case Once you’ve reviewed the suggested events for a use case, you won’t be able to change the use case. If you want to see a full breakdown of each use case before commiting to one, click Change use case to begin the use case flow again. You can also view the Use Cases Reference guide to see what Segment recommends for each use case. On the Setup checklist page, you’ll see the full checklist for the use case you’ve chosen. This checklist applies to all use cases, though the suggested events, sources, and destinations differ between use cases. In the Review suggested events list item, click Review . Segment shows you the recommended events and properties typically tracked for your use case. Set up event tracking based on the events and properties Segment shows. This table shows Segment’s recommended events and properties for the Personalize winback use case: Events Properties Page Viewed page_category , page_name Page Scrolled pct_scrolled , page_category Order Completed num_items , order_id , checkout_id , total , revenue , shipping , tax , affiliation , products Make sure that you’re tracking these events to get the most of the Personalize winback campaign. For more information on event tracking, see Data Collection Best Practices . Step 4: Connect dev sources You’re now ready to connect sources to your dev environment. In the Connect dev sources step, Segment shows you the recommended sources you should connect. For Personalized winback, these include Website, Mobile, and Reverse ETL. Review the recommended sources, then click Connect . Segment takes you to the Add a source setup. Choose the source(s) you want to add, then click Next . Name your source, then click Create source . Carry out the source-specific steps, then click Next . Test your connection and troubleshoot it, if necessary. Click Done . (Optional:) Click Connect More and repeat steps 2 through 6 to add more sources. Adding a warehouse as a souce If you connect a warehouse as a source, Segment automatically creates a Profiles destination that shows up in the Connect your data tab. Do not delete this destination, as Segment requires this destination to create profiles from your warehouse. Cloud object sources If you connect a cloud object source, you’ll need to create a warehouse to sync profiles into Segment. For more information, see Cloud Sources . Step 5: Connect dev destinations With sources connected, you can now connect destinations to your dev environment. Under the Connect dev destinations step, Segment shows you the recommended sources you should connect. For Personalize winback, these include Reverse ETL, Personalization, and Analytics. Review the recommended destinations, then click Connect . Segment takes you to the Choose a Destination setup. Choose the destination(s) you want to add, then click Next . Name your destination, then click Create Destination . Choose a source to connect to the destination, then click Next . Carry out the destination-specific steps, then click Done . (Optional:) Click Connect More and repeat steps 2 through 6 to add more destinations. Step 6: Publish your setup to a prod environment Until this point, you’ve set up event tracking and connected sources and destinations to a development environment. After you’ve confirmed that data is flowing from your sources into your destinations as expected, you’re ready to publish your setup to a production environment. On the Setup checklist page, click the Prod environment tab. On the Connect 1 prod source radio button, click Connect . Segment shows you the sources you previously connected in your dev environment. Click the source you want to connect to prod, then click Continue . Carry out any additional steps in the Add a Source page, click Create Source , then click Next . Segment returns you to the Prod environment tab. Publish the events set up in your dev environment sources to production. Check the debugger to verify that data is flowing into Segment correctly, then click Mark as complete . On the Connect 1 prod destination bullet, click Connect . Segment shows you the destinations you previously connected in your dev environment. Click the source you want to connect to prod, then click Continue . Choose a source to connect to the destination, then click Next . Name your destination, then click Create Destination . Your data is now in production, and you’ve successfully configured Segment. Activate your data with Unify and Engage Now that you’ve successfully set up Connections and Destinations, you can build upon your Segment implementation with Unify and Engage. Accessing Unify and Engage Unify and Engage may not yet be enabled for your account. To add Engage to your Segment workspace, click Request a demo in the Unify and Engage tabs on the Guided Setup page. Step 1: Set up identifiers with Unify In the Guided Setup page, click Build profiles from your data . Click Add default identifiers . Segment displays the Select Identifiers popup. Select as many of the recommended identifiers that best fit your use case; Segment recommends selecting all identifiers. Click Save . On the Guided Setup page, click Mark complete . Your identifiers are now set up in your dev space, though it could take a few minutes for Segment to create profiles from your selected identifiers. For more information, see the Unify documentation . Step 2: Create audiences with Engage Click the Engage customers with your data tab , then click Create audience . Segment takes you to the New Audience Builder. On the Select Audience Type page, select either Users or Accounts, then click Next . Configure, preview, and create your audience. Segment then begins sending your new audience(s) to the destinations in your dev environment. Verify in those destinations that the audiences are coming through as intended, then click Mark complete . For more information on Audiences, see the Engage documentation . Step 3: Republish to a prod environment At this point, you’ll have already published your initial setup to a prod environment. Next, you’ll publish your Unify and Engage setup to the same prod environment. Return to the Prod environment tab. In the Build profiles from your data tab, click Import rules . Review the rules that Segment will import, then click Import . In the Engage customers with your data tab, click Create audience Configure, preview, and create your audience. Segment returns you to the Guided Setup page. Segment then begins sending your new audience(s) to the destinations in your dev environment. Verify in those destinations that your audiences are coming through as intended, then click Mark complete . Next steps Use Cases pulls together a number of core Segment features, like Sources , Destinations , data collection , and Reverse ETL . View the documentation for each to learn how you can continue to expand and build on what you’ve alreay achieved. This page was last modified: 08 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Use case setup overview Example setup: Personalize winback Activate your data with Unify and Engage Next steps Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Use Cases Setup"
      },
      {
        "level": 2,
        "text": "Use case setup overview"
      },
      {
        "level": 2,
        "text": "Example setup: Personalize winback"
      },
      {
        "level": 3,
        "text": "Step 1: Navigate to Use Cases"
      },
      {
        "level": 3,
        "text": "Step 2: Pick your business goal and select a use case"
      },
      {
        "level": 3,
        "text": "Step 3: Review suggested events"
      },
      {
        "level": 3,
        "text": "Step 4: Connect dev sources"
      },
      {
        "level": 3,
        "text": "Step 5: Connect dev destinations"
      },
      {
        "level": 3,
        "text": "Step 6: Publish your setup to a prod environment"
      },
      {
        "level": 2,
        "text": "Activate your data with Unify and Engage"
      },
      {
        "level": 3,
        "text": "Step 1: Set up identifiers with Unify"
      },
      {
        "level": 3,
        "text": "Step 2: Create audiences with Engage"
      },
      {
        "level": 3,
        "text": "Step 3: Republish to a prod environment"
      },
      {
        "level": 2,
        "text": "Next steps"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/usage-and-billing/startup-program/",
    "title": " Segment Startup Program | Segment Documentation",
    "content": "Home / Guides / Usage and billing / Segment Startup Program Segment Startup Program On this page Frequently Asked Questions Segment offers a Startup Program to enable early startups to track data and test the marketing and analytics tools necessary to grow their business. The program is open to any early-stage startup that meets the following eligibility requirements: Incorporated less than two years ago Raised no more than $5MM in total funding Located in Google Cloud eligible territory haven’t previously received other Segment discounts The Segment Startup Program includes three components: Segment’s Startup Deal - Participating startups receive $25,000* in annual credit toward our monthly Team plan for as long as they meet our eligibility requirements (up to 2 years). Partner Startup Deals - Segment partners with other technology companies that offer valuable tools for startups to offer exclusive deals and promotions from marketing, data warehouse, and analytics tools. Startup Resources - Segment offers learning materials on topics like analytics, product-market fit, and more for founders to become experts on data analytics and making the most of Segment’s technology. Interested companies can apply on the Startup Program site. Application deadline Effective January 6, 2025, Segment will no longer accept applications for the Segment Startup Program. Applications submitted before 11:59 PM PT on December 5, 2024 will be reviewed and honored. Any applications received after this deadline won’t be accepted. There will be no exceptions. *Can vary based on affiliated accelerator and VC partners. Frequently Asked Questions How are the Segment credits applied? Credits are applied to your monthly bill, covering up to $25,000* in total usage per year. Any additional usage costs are not covered by the program. How do I redeem the Segment credits? Eligible startups can apply directly for the Segment Startup Program. How do I find out if I’ve been accepted to the Segment Startup Program? If you’ve been accepted to the program, you’ll receive an email with a welcome message and next steps. If you haven’t received an email, you can also check in your Segment workspace and look for a Startup Program icon in the top right corner. Where can I view the credits applied to my Segment account? The Startup Program credits are reflected in the Workspace usage and billing page. Do I have to be a “new” customer to receive a coupon? New and current Segment users who have not previously received any other coupon are eligible to apply. What happens if I go over my total credit applied? If you go over the total credit applied, you will be charged for the additional usage for that month. What happens when my credits expire? Once you’ve used your total credits, you might be eligible to renew for another year at a discounted rate. Otherwise, we can talk about options for upgrading your plan. How do I get the startup partner deals? Once you’ve been accepted to the Segment Startup Program, you can apply for the partner deals using this Airtable form . (You can view a list of the available deals in a section of the Airtable form .) How do I know if my accelerator/incubator/VC firm has a relationship with Segment? Ask your program manager to see if they participate in the Segment Startup Program. If they do not, you can request that they apply to become a partner . This page was last modified: 19 Dec 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Frequently Asked Questions Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Segment Startup Program"
      },
      {
        "level": 2,
        "text": "Frequently Asked Questions"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/getting-started/02-simple-install/",
    "title": " A Basic Segment Installation | Segment Documentation",
    "content": "Home / Getting started / A Basic Segment Installation A Basic Segment Installation On this page Before you begin Create a Segment source Find your write key Installing Segment Test that it’s working Set up your first destination When you implement Segment, you add Segment code to your website, app, or server. This code generates messages based on specific triggers you define. In a basic implementation, the code can be a snippet of JavaScript that you copy and paste into the HTML of a website to track page views. It can also be as complex as Segment calls embedded in a React mobile app to send messages when the app is opened or closed, when the user performs different actions, or when time based conditions are met (for example “ticket reservation expired” or “cart abandoned after 2 hours”). The best way to learn about how Segment works is to see it in action. This tutorial walks you through an installation using one of Segment’s libraries: JavaScript, PHP, or the iOS library. Before you begin Before you start your Segment implementation, you need: A Segment user account and a workspace. If you’re not already part of an organization with a Segment Workspace, you can sign up for a free account and workspace . Access to the code for a basic website, PHP website, or an iOS app. Tip ! If you don’t have any of those things, consider creating a simple GitHub Pages website . Create separate dev and prod sources When you develop and test sources, Segment recommends you to create and use separate sources for each of your environments (production, development, staging) to prevent testing and development activities from filling production systems with invalid data. You can give each source an environment label when you create it, and Segment strongly suggests that you use these labels to sort your sources. When you create a source during the steps below, make sure you enter an environment label. Double-check when you enter write keys for dev and production environments to make sure that you send the right data to the right place. Create a Segment source To create a Segment source: Go to your Segment workspace, and navigate to the Sources catalog . Select your source. You can choose from either the Javascript source , the PHP source , or the iOS source . Click Add Source . Enter a name for the source. Segment recommends that you include the word demo , test , or quickstart in the name so you can easily find and delete this source later. (Optional) Add an Environment label of dev to the source in the Labels field. Segment recommends you do this so that you know this demo source isn’t part of a production installation. (Optional) Add the website URL. Segment provides this field so that you can flag the website being tracked to the source. Segment does not use this URL anywhere else. Find your write key The write key is a unique identifier for a source that tells Segment which source the data comes from, to which workspace the data belongs, and which destinations should receive the data. To find your write key: Go to Connections > Sources and select your source. Click the Settings tab for the source and click API Keys . Make note of or write down your write key, as you’ll need it in the next steps. Any time you change a library’s settings in the Segment App, the write key regenerates. Cloud-sources do not have write keys, as they use a token or key from your account with that service. Cloud-sources have other considerations and aren’t part of this tutorial. Installing Segment Click a tab below to see the tutorial content for the specific library you chose. Javascript quickstart iOS Mobile quickstart PHP quickstart Step 1: Copy the Snippet Navigate Connections > Sources > JavaScript in the Segment app and copy the snippet from the JavaScript Source overview page and paste it into the <head> tag of your site. That snippet loads Analytics.js onto the page asynchronously , so it won’t affect your page load speed. Once the snippet runs on your site, you can turn on destinations from the destinations page in your workspace and data starts loading on your site automatically. Note: If you only want the most basic Google Analytics setup you can stop reading right now. You’re done! Just toggle on Google Analytics from the Segment App. The Segment snippet version history available on GitHub . Segment recommends that you use the latest snippet version whenever possible. Step 2: Identify Users The identify method is how you tell Segment who the current user is. It includes a unique User ID and any optional traits you know about them. You can read more about it in the identify method reference . Note: You don’t need to call identify for anonymous visitors to your site. Segment automatically assigns them an anonymousId , so just calling page and track works just fine without identify . Here’s an example of what a basic call to identify might look like: analytics . identify ( ' f4ca124298 ' , { name : ' Michael Brown ' , email : ' mbrown@example.com ' }); This identifies Michael by his unique User ID (in this case, f4ca124298 , which is what you know him by in your database) and labels him with name and email traits. When you put that code on your site, you need to replace those hard-coded trait values with the variables that represent the details of the currently logged-in user. To do that, Segment recommends that you use a backend template to inject an identify call into the footer of every page of your site where the user is logged in. That way, no matter what page the user first lands on, they will always be identified. You don’t need to call identify if your unique identifier ( userId ) is not known. Depending on your templating language, your actual identify call might look something like this: analytics . identify ( ' {{user.id}} ' , { name : ' {{user.fullname}} ' , email : ' {{user.email}} ' }); With that call in your page footer, you successfully identify every user that visits your site. Note: If you only want to use a basic CRM set up, you can stop here. Just enable Salesforce, Intercom, or any other CRM system from your Segment workspace, and Segment starts sending all of your user data to it. Step 3: Track Actions The track method is how you tell Segment about the actions your users are performing on your site. Every action triggers what Segment calls an “event”, which can also have associated properties. You can read more about track in the track method reference . Here’s an example of what a call to track might look like when a user signs up: analytics . track ( ' Signed Up ' , { plan : ' Enterprise ' }); This example shows that your user triggered the Signed Up event and chose your hypothetical 'Enterprise' plan. Properties can be anything you want to record, for example: analytics . track ( ' Article Bookmarked ' , { title : ' Snow Fall ' , subtitle : ' The Avalanche at Tunnel Creek ' , author : ' John Branch ' }); If you’re just getting started, some of the events you should track are events that indicate the success of your site, like Signed Up , Item Purchased or Article Bookmarked . Segment recommends that you track a few important events as you can always add more later. Once you add a few track calls, you’re done with setting up Segment. You successfully installed Analytics.js tracking. Now you’re ready to turn on any destination you like from the Segment App. Step 1: Install the SDK To install Analytics-iOS, Segment recommends you to use CocoaPods , because it allows you to create a build with specific bundled destinations, and because it makes it simple to install and upgrade. 1) Add the Analytics dependency to your Podfile by adding the following line: pod 'Analytics' , '~> 3.0' 2) In your application delegate’s - application:didFinishLaunchingWithOptions: method, set up the SDK like so: SEGAnalyticsConfiguration * configuration = [ SEGAnalyticsConfiguration configurationWithWriteKey : @\"YOUR_WRITE_KEY\" ]; configuration . trackApplicationLifecycleEvents = YES ; // Enable this to record certain application events automatically! configuration . recordScreenViews = YES ; // Enable this to record screen views automatically! [ SEGAnalytics setupWithConfiguration : configuration ]; You don’t need to use initialization config parameters to track lifecycle events ( Application Opened , Application Installed , Application Updated ) and screen views automatically, but Segment highly recommends that you do, so you can start off already tracking some important core events. 3) Import the SDK in the files that you use it by adding the following line: #import <Analytics/SEGAnalytics.h> Bundling Client Side SDKs To keep the Segment SDK lightweight, the Analytics pod only installs the Segment library. This means all of the data goes first to Segment’s servers, and is then forwarded to any destination tools which accept the data from Segment . Some destinations don’t accept data from the Segment servers, and instead require that you collect the data from the device. In these cases you must bundle some additional destination code with the Segment SDK. This document skips over this part, but you can see the instructions on how to bundle the destination tools . Now that the SDK is installed and set up, you’re ready to start making calls. Step 2: Identify Users The identify method is how you tell Segment who the current user is. It takes a unique User ID, and any optional traits you know about them. You can read more about it in the identify reference . Here’s an example of what a basic call to identify might look like: [[ SEGAnalytics sharedAnalytics ] identify : @\"f4ca124298\" traits: @{ @\"name\" : @\"Michael Brown\" , @\"email\" : @\"mbrown@example.com\" }]; This call identifies Michael by his unique User ID ( f4ca124298 , which is the one you know him by in your database) and labels him with name and email traits. Note: When you put that code in your iOS app, you need to replace those hard-coded trait values with the variables that represent the details of the currently logged-in user. Step 3: Track Actions The track method is how you tell Segment about the actions your users are performing in your app. Every action triggers what we call an “event”, which can also have associated properties. You can read more about track in the track method reference . The Segment iOS SDK can automatically track a few important common events, such as Application Installed , Application Updated , and Application Opened . You can enable this option during initialization by adding the following lines: SEGAnalyticsConfiguration * configuration = [ SEGAnalyticsConfiguration configurationWithWriteKey : @\"YOUR_WRITE_KEY\" ]; configuration . trackApplicationLifecycleEvents = YES ; [ SEGAnalytics setupWithConfiguration : configuration ]; You should also track events that indicate success in your mobile app, like Signed Up , Item Purchased , or Article Bookmarked . Segment recommends that you track a few important events as you can always add more later. Here’s what a track call might look like when a user signs up: [[ SEGAnalytics sharedAnalytics ] track : @\"Signed Up\" properties: @{ @\"plan\" : @\"Enterprise\" }]; This tells us that your user triggered the Signed Up event, and chose your hypothetical 'Enterprise' plan. Properties can be anything you want to record, for example: [[ SEGAnalytics sharedAnalytics ] track : @\"Article Bookmarked\" properties: @{ @\"title\" : @\"Snow Fall\" , @\"subtitle\" : @\"The Avalanche at Tunnel Creek\" , @\"author\" : @\"John Branch\" }]; Once you’ve added a few track calls, you’re all set. You successfully instrumented your app, and can enable destinations from your Segment workspace. Step 1: Download the library To install the library: 1) Clone the repository from GitHub into your desired application directory. (If you’re a composer user, you can use this .) git clone https://github.com/segmentio/analytics-php /my/application/folders/ 2) Add the following to your PHP script to load the Segment analytics library in your code: require_once ( \"/path/to/analytics-php/lib/Segment.php\" ); use Segment\\Segment ; 3) In your initialization script, make the following call (In the example, Segment first renames this module to Analytics for convenience): # Set up our Segment tracking and # alias to Analytics for convenience class_alias ( 'Segment' , 'Analytics' ); Segment :: init ( \"YOUR_WRITE_KEY\" ); 4) Replace YOUR_WRITE_KEY with the actual write key, which you can find in Segment under your project settings. Otherwise, all that data goes straight to /dev/null . You only need to call init once when your php file is requested. All of your files then have access to the same Analytics client. Note: The default PHP consumer is the libcurl consumer . If this is not working well for you, or if you have a high-volume project, you might try one of Segment’s other consumers like the fork-curl consumer . Step 2: Identify Users The identify method is how you tell Segment who the current user is. It includes a unique User ID and any optional traits that you might know about them. Here’s what a basic call to identify might look like: Segment :: identify ( array ( \"userId\" => \"f4ca124298\" , \"traits\" => array ( \"name\" => \"Michael Brown\" , \"email\" => \"mbrown@example.com\" ) )); This identifies Michael by his unique User ID (in this case, f4ca124298 , which is what you know him by in your database) and labels him with name and email traits. Note: When you actually put that code on your site, you need to replace those hard-coded trait values with the variables that represent the details of the currently logged-in user. The easiest way in PHP is to keep a $user variable in memory. Segment :: identify ( array ( \"userId\" => $user -> id , \"traits\" => array ( \"name\" => $user -> fullname , \"email\" => $user -> email ) )); With that call on the page, you’re now identifying every user that visits your site. If you only want to use a basic CRM set up, you can stop here. Just enable Salesforce, Intercom, or any other CRM system from your Segment workspace, and Segment starts sending all of your user data to it. Step 3: Track Actions The track method is how you tell Segment about the actions your users are performing on your site. Every action triggers what Segment calls an “event”, which can also have associated properties. Here’s what a call to track might look like when a user signs up: Segment :: track ( array ( \"userId\" => \"f4ca124298\" , \"event\" => \"Signed Up\" , \"properties\" => array ( \"plan\" => \"Enterprise\" ) )); This tells us that the user triggered the Signed Up event, and chose your hypothetical Enterprise plan. Properties can be anything you want to record, for example: Segment :: track ( array ( \"userId\" => \"f4ca124298\" , \"event\" => \"Article Bookmarked\" , \"properties\" => array ( \"title\" => \"Snow Fall\" , \"subtitle\" => \"The Avalanche at Tunnel Creek\" , \"author\" => \"John Branch\" ) )); If you’re just getting started, some of the events you should track are events that indicate the success of your site, like Signed Up , Item Purchased or Article Bookmarked . To get started, Segment recommends you to track track a few important events as you can always add more later. Step 4: Flush the data Call the Segment flush() method. This manually sends all the queued call data to make sure it makes it to the Segment servers. This is normally done automatically by the runtime, but some PHP installations won’t do it for you, so it’s worth calling at the end of your script, just to be safe. Segment :: flush (); You’ve successfully installed PHP tracking. Now you’re ready to turn on any destination from the Segment App. Test that it’s working Once you’ve set up your Segment library, and instrumented at least one call, you can look at the Debugger tab for the Source to check that it produces data as you expected. The Source Debugger is a real-time tool that helps you confirm that API calls made from your website, mobile app, or servers arrive at your Segment Source, so you can quickly see how calls are received by your Segment source, so you can troubleshoot quickly without having to wait for data processing. The Debugger is separate from your workspace’s data pipeline, and is not an exhaustive view of all the events ever sent to your Segment workspace. The Debugger only shows a sample of the events that the Source receives in real time, with a cap of 500 events. The Debugger is a great way to test specific parts of your implementation to validate that events are being fired successfully and arriving to your Source. Tip : To see a more complete view of all your events, you might consider setting up either a warehouse or an S3 destination . The Debugger shows a live stream of sampled events arriving at the Source, but you can also toggle from “Live” to “Pause” to stop the stream and prevent it from displaying new events. Events continue to arrive to your Source while you Pause the stream, they just are not displayed. You can search on any information you know is available in an event payload to search in the Debugger and show only matching payloads. You can also use advanced search options to limit the results to a specific event. Two views are available when viewing a payload: The Pretty view is a recreation of the API call you made that was sent to Segment. The Raw view is the complete JSON object Segment received from the calls you sent. These calls include all the details about what is being tracked: timestamps, properties, traits, ids, and contextual information Segment automatically collects the moment the data is sent. Set up your first destination Once you’re satisfied that data is arriving from your new source, it’s time to set up your first destination! As long as you have page or screen data coming from the source, you can quickly enable Google Analytics to look at the page view statistics. If you don’t have a Google Analytics account, you can either set up a free account, or look at the Destination Catalog for a different destination to enable. You’ll need a tracking ID for Google Analytics (either a “website” or “serverside” tracking ID), or another API key if you’re substituting another destination. Make a note of this ID or key as you’ll need it to connect your destination. To set up your first destination: Go to your Segment workspace, click Destinations , and click Add Destination to go to the Catalog . Search for the destination you want to add. In this case, search for Google Analytics . Click the tile for the destination to see information about it. Click Configure Google Analytics . Select the source that you set up earlier in this quickstart, then click Confirm Source . On the settings page, locate the setting line for the tracking ID or other API key to connect to your destination. Enter the ID or API key and click Save . Click Back to Destination , then click the toggle to enable the destination. Congratulations! Data is now flowing from the source you set up, to the first destination. Do some test browsing on your site or app, then log in to your downstream tool to see the data in place. You can click around and load pages to see your Segment calls in action, watch them arrive in the Debugger, and see them arrive in the destination tool. Note: When you’re done with this test source and destination, you can delete them. This prevents you from getting unplanned “demo” data in your production environment later. back What is Segment The basics of the Segment platform and what you can do with it. next Planning a Full Installation Think through your goals, plan your calls, and set yourself up for success. This page was last modified: 13 Aug 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Before you begin Create a Segment source Find your write key Installing Segment Test that it’s working Set up your first destination Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "A Basic Segment Installation"
      },
      {
        "level": 2,
        "text": "Before you begin"
      },
      {
        "level": 3,
        "text": "Create separate dev and prod sources"
      },
      {
        "level": 2,
        "text": "Create a Segment source"
      },
      {
        "level": 2,
        "text": "Find your write key"
      },
      {
        "level": 2,
        "text": "Installing Segment"
      },
      {
        "level": 3,
        "text": "Step 1: Copy the Snippet"
      },
      {
        "level": 3,
        "text": "Step 2: Identify Users"
      },
      {
        "level": 3,
        "text": "Step 3: Track Actions"
      },
      {
        "level": 3,
        "text": "Step 1: Install the SDK"
      },
      {
        "level": 3,
        "text": "Step 2: Identify Users"
      },
      {
        "level": 3,
        "text": "Step 3: Track Actions"
      },
      {
        "level": 3,
        "text": "Step 1: Download the library"
      },
      {
        "level": 3,
        "text": "Step 2: Identify Users"
      },
      {
        "level": 3,
        "text": "Step 3: Track Actions"
      },
      {
        "level": 3,
        "text": "Step 4: Flush the data"
      },
      {
        "level": 2,
        "text": "Test that it’s working"
      },
      {
        "level": 2,
        "text": "Set up your first destination"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/storage/data-lakes/sync-history/",
    "title": " Data Lakes Sync History and Health | Segment Documentation",
    "content": "Home / Connections / Storage / Data lakes / Data Lakes Sync History and Health Data Lakes Sync History and Health Free x Team x Business ✓ Add-on x ? Data Lakes is available for the listed account plans only. See the available plans , or contact Support . On this page Sync history Health Data Lakes reports FAQ The Segment Data Lakes sync history and health tabs generate real-time information about data syncs so you can monitor the health and performance of your data lakes. These tools provide monitoring and debugging capabilities within the Data Lakes UI, so you can identify and proactively address data sync or data pipeline failures. Sync history The Sync History table shows detailed information about the latest 100 syncs to the data lake. The table includes the following fields: Field Description Sync status The status of the sync: either Success , indicating that all rows synced correctly, Partial Success , indicating that some rows synced correctly, or Failed , indicating that no rows synced correctly Start time The time the sync began Duration How long the sync took to complete Synced rows The number of rows that synced to the data lake Notices Any notes or warnings about the sync Selecting a row in the Sync History table opens a sidebar showing the number of rows from each collection that synced. To access the Sync History page from the Segment app, open the My Destinations page and select the data lake. On the data lakes Settings page, select the Sync History tab. Health The health tab provides an overview of the rows that synced to your data lake both today and each day for the last 30 days. The bar chart, ‘Daily Synced Rows,’ shows an overview of the rows synced for each of the last 30 days. Hovering over a date shows the number of rows that were synced for that day. Selecting a date from the bar chart opens the Daily Row Volume table, which provides a breakdown of which collections synced, how many rows from each collection synced, and the percentage of all synced rows from each collection. The Daily Row Volume table contains the following information: Collections: The name of each collection of properties synced to the data lake Rows: The number of rows synced from each collection % of Total: The percentage of the total number of rows synced that each collection represents Above the Daily Row Volume table is an overview of the total syncs for the current day, showing the number of rows synced, the number of collections that synced, and the current date. To access the Sync history page from the Segment app, open the My Destinations page and select the data lake. On the data lakes settings page, select the Health tab. Data Lakes reports FAQ How long is a data point available? The health tab shows an aggregate view of the last 30 days worth of data, while the sync history retains the last 100 syncs. How do sync history and health compare? The sync history feature shows detailed information about the most recent 100 syncs to a data lake, while the health tab shows just the number of rows synced to the data lake over the last 30 days. What timezone is the time and date information in? All dates and times on the sync history and health pages are in the user’s local time. When does the data update? The sync data for both reports updates in real time. When do syncs occur? Syncs occur approximately every two hours. Users cannot choose how frequently the data lake syncs. This page was last modified: 03 Aug 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Sync history Health Data Lakes reports FAQ Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Data Lakes Sync History and Health"
      },
      {
        "level": 2,
        "text": "Sync history"
      },
      {
        "level": 2,
        "text": "Health"
      },
      {
        "level": 2,
        "text": "Data Lakes reports FAQ"
      },
      {
        "level": 3,
        "text": "How long is a data point available?"
      },
      {
        "level": 3,
        "text": "How do sync history and health compare?"
      },
      {
        "level": 3,
        "text": "What timezone is the time and date information in?"
      },
      {
        "level": 3,
        "text": "When does the data update?"
      },
      {
        "level": 3,
        "text": "When do syncs occur?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/protocols/faq/",
    "title": " Protocols Frequently Asked Questions | Segment Documentation",
    "content": "Home / Protocols / Protocols Frequently Asked Questions Protocols Frequently Asked Questions Free x Team x Business ✓ + Protocols ✓ ? Protocols is available as an add-on for Business plans only. See the available plans , or contact Support . On this page Protocols Notifications Protocols Tracking Plan Protocols Validation Protocols Enforcement Protocols Transformations Protocols Notifications How can I subscribe to Protocols notifications? You can subscribe to a variety of Protocols specific alerts through the workspace Activity Feed settings. To subscribe, visit your workspace Settings > User Preferences > Activity Notifications > Protocols . How can I get notified when someone makes a change to my tracking plan? You can forward notifications from Protocols to a new Segment source, which can then send them to notification tools such as Slack webhook. You can also forward these Protocols alerts to any (cloud-mode) Segment destination that accepts Track calls, including data warehouses. Most customers record these activity feed events to a data warehouse for analysis. How do I get notified when new violations are generated? Can I create custom violation notifications? You can enable violation event forwarding to start delivering violations as Track calls to a Segment source. From there, you can forward the events to any Segment destination that accepts Track calls. You can also use the Slack Actions destination to set event triggers for context fields, meaning events with violations are sent as Track calls directly from the source. Protocols Tracking Plan What is the Segment Consent Preference Updated event, and who added it to my Tracking Plans? Consent Management users see the Segment Consent Preference Updated event automatically added to all existing Tracking Plans after they create their first consent category, or when they create a new Tracking Plan after configuring Consent Management. Segment recommends that you do not remove this event. How do I add Page and Screen events to my Tracking Plan? To consolidate the views in the Schema tab, Segment automatically converts page and screen calls into Page Viewed and Screen Viewed events that appear in the Schema Events view. Segment recommends adding a Page Viewed or Screen Viewed event to your Tracking Plan with any properties you want to validate against. At this time, to validate that a specific named page/screen ( analytics.page('Homepage') | analytics.screen('Home') ) has a specific set of required properties, you will need to use the JSON Schema . How can I see who made changes to my Tracking Plan? Each Tracking Plan includes a Changelog, which shows which changes were made by which users. To view it, open a Tracking Plan, click the … button (also known as the dot-dot-dot, or ellipses menu) next to the Edit Tracking Plan button, and click View Changelog . How many Sources can I connect to a Tracking Plan? The Tracking Plan to Source relationship is a one-to-many relationship. This means you can connect as many Sources to a Tracking Plan as you need. However Segment recommends connecting 1-3 Sources per Tracking Plan, because it’s rare to have more than three Sources that share an identical set of events, especially when tracking events across platforms. For example, many Segment mobile SDKs (iOS and Android) automatically collect events that would not make sense to collect in a web app. Segment doesn’t recommend including events in a Tracking Plan that would never be tracked in a Source. Can I duplicate a Tracking Plan in the Segment UI? You can duplicate Tracking Plans in the Segment web app by following the instructions to copy a tracking plan . You can also use the Public API to copy the underlying JSON schema from one Tracking Plan to another. How do I handle versioning with mobile apps? Segment currently supports the ability to create multiple versions of an event in a Tracking Plan. This is ideal for mobile apps, where a breaking change like adding a new required property to an event could cause all previous app versions on user devices to generate violations. You must manually add a context.protocols.event_version property to the specific track call so that Segment can correctly validate the event against the defined version. Learn more in the Tracking Plan event versioning documentation . How do I handle null property values? In the Tracking Plan editor, click on the data type dropdown for a given property and toggle “Allow Null Values”. Enabling null values means only null values will be accepted for that property. Can I group specific events in a Tracking Plan? Yes. Tracking Plan Labels are an excellent way to organize events in a Tracking Plan by priority, platform, product, or similar metadata for each event. How do I send someone a specific event or group of events to implement? You can search in a Tracking Plan to find a specific event, and then copy the URL for the search results page and share it. You can also filter by label to share a group of events. The person you send the URL to must have access to the Workspace and tracking plan to see the results page. (See the Access Management documentation for more details.) Can I create a master Tracking Plan that supersedes all other Tracking Plans? Yes. Tracking Plan Libraries makes it easy to create groups of events or properties that can be easily imported into multiple Tracking plans. Can I copy a Tracking Plan into a library? No. Unfortunately it’s not yet possible to automatically transfer events from a Tracking Plan to Libraries. To import events into a new event library, import them directly from a source. Can I transfer a Tracking Plan between production and staging environments? Yes. Using the Public API , you can copy the underlying JSON schema from a Tracking Plan in one Workspace to a Tracking Plan in another Workspace. If you discarded events as a part of your original Tracking Plan, you must connect to the same Source and configure identical Schema Controls in your other Workspace so that blocked events behave as expected. Can I connect a Source to more than one Tracking Plan? Unfortunately, Sources cannot be connected to more than one Tracking Plan. If you were able to connect more than one Tracking Plan to a Source, it could create conflict if events overlapped. How do Tracking Plans work? Segment’s code uses built-in logic to verify if an event exists in the Tracking Plan. If an event does not exist, it will follow the configuration the Schema Configuration settings for each source connected to the Tracking Plan. Why are my unplanned properties still getting sent to my destinations even though I’ve set the dropdown to “Omit Properties”? Unplanned property omission is only supported for cloud-mode destinations. Unplanned properties will not be omitted when they’re sent to device-mode destinations. Why do I have two different Tracking Plan IDs? When you access a Tracking Plan, you’ll come across two IDs: tp_ and rs_ . Segment uses the two IDs to identify your Tracking Plan in the two APIs you can use to manage your workspace: the Public API and the Config API . To view the two IDs for your Tracking Plan, navigate to the Tracking Plan you’d like to view the ID for and select the dropdown next to Tracking Plan ID . If you’re using the Public API, you’ll need the ID that starts with tp_ . If you’re using the Config API, you’ll need the ID that starts with rs . How do I import events from a Source Schema into a Tracking Plan? When you first create your Tracking Plan, you can add events from your Source Schema by selecting the Import events from Source button on the Tracking Plan editor page. You can manually add these events after you’ve connected your Source Schema to your Tracking Plan by clicking the (+) next to the event on your Source Schema page. Can I import events from my Source Schema into a Tracking Plan? When you initially create your Tracking Plan, you can import events into it from a Source Schema. Manually add these events by clicking the the (+) next to the event in your Source Schema page after connecting your Tracking Plan. Can I recover a Tracking Plan that was deleted? You cannot recover a deleted Tracking Plan and Segment cannot recover it on your behalf. Please delete Tracking Plans with caution. Protocols Validation What is the difference between Violations Emails and the Violations page in the Segment UI? Violations Daily Digest The Violations Daily Digest is a great way to keep informed of new violations that might be easy to overlook on the Protocols Violations page. The digest sends one email digest per source, every day at approximately 12AM EST. You cannot currently opt in or out of specific sources. The digest contains all violations for that source that are unique in the previous 48 hours. For example, if an event testEvent had violations on the first day of the month, then those violations won’t appear in the digest until the third of the month. The email includes information about the violation to help you track down its source and correct it. It includes the event name and property name fields, the violation type, the number of times that specific type of violation was seen, and the last time it was seen. Protocols Violations Page The Protocols Violations page shows a live count for violations. You can adjust the timeframe to show violations in the last hour, the last 24 hours, or the last seven days. You might see a difference between the count on the Violations page and the count in the Violations email digests. This can happen due to differences between the time periods available (24 hours in in the live page, 48 hours in the daily digest email), and the fact that the digest only shows unique violations. The fields displayed on the Violations page are more detailed than those included in the email digest. Why do I see root listed on my Violations page? You may see violations related to (root). For example: ( root ) Must validate all the schemas // Or ( root ) Must validate \" then \" as \" if \" was valid These violations are related to your common JSON Schema if you’ve applied custom rules. In this instance (root), refers to the top level of the JSON object (Segment event). Protocols Enforcement Why can’t I use the Schema to filter my events? The schema functionality is a reactive way to clean up your data, where the Tracking Plan functionality is a proactive , intentional way to clean and unify all future data. Segment has found that the best data driven companies invest the time required to build strong processes and controls around their data. The investment pays off exponentially. That being said, there are plenty of scenarios where the reactive Schema functionality solves immediate needs for customers. Often times, customers will use both Schema Controls and Tracking Plan functionality across their Segment Sources. For smaller volume Sources with less important data, the Schema functionality often works perfectly. If I enable blocking, what happens to the blocked events? Are events just blocked from specific Destinations or the entire Segment pipeline? Blocked events are blocked from sending to all Segment Destinations, including warehouses and streaming Destinations. When an Event is blocked using a Tracking Plan, it does not count towards your MTU limit. They will, however, count toward your MTU limit if you enable blocked event forwarding in your Source settings. If I omit unplanned properties or properties that generate JSON schema violations, what happens to them? Segment doesn’t store unplanned properties and properties omitted due to JSON Schema Violations in Segment logs. Segment drops omitted properties from the events. You can find the omitted properties in the context.violations object of an event payload. If you forward Violations to a new source, then you can also see the omitted properties in the Violation Generated event under violationField in the properties object. Segment only stores fully blocked events for 30 days. Why am I seeing unplanned properties/traits in the payload when violations are triggered, despite using schema controls to omit them? If you’re seeing unplanned properties/traits in your payload despite using Schema Controls, you might want to select a new degree of blocking controls. Segment’s Schema Controls provide three options to omit properties/traits. Select the one that aligns with your requirements: Standard Schema Controls/”Unplanned Properties/Traits” : Segment checks the names of incoming properties/traits against your Tracking Plan. Standard Schema Controls/”JSON Schema Violations” : Segment checks the names and evaluates the values of properties/traits. This is useful if you’ve specified a pattern or a list of acceptable values in the JSON schema for each Track event listed in the Tracking Plan. Advanced Blocking Controls/”Common JSON Schema Violations” : Segment evaluates incoming events thoroughly, including event names, context field names and values, and the names and values of properties/traits, against the Common JSON schema in your Tracking Plan. Why am I still seeing unplanned properties in my Source Schema when I’ve added the properties to a new version of my Tracking Plan? The source schema only validates events against the oldest event version in a Tracking Plan. If, for example, you have a version 1 and version 2 of your Tracking Plan, the schema only checks against version 1 of your Tracking Plan. Do blocked and discarded events count towards my MTU counts? Blocking events within a Source Schema or Tracking Plan excludes them from API call and MTU calculations, as the events are discarded before they reach the pipeline that Segment uses for calculations. Do warehouse connectors use the data type definitions when creating a warehouse schema? Warehouse connectors don’t use data type definitions for schema creation. The data types for columns are inferred from the first event that comes in from the source. Can I use schema controls to block events forwarded to my source from another source? You can only use schema controls to block events at the point that they are ingested into Segment. When you forward an event that Segment has previously ingested from another source, that event bypasses the pipeline that Segment uses to block events and cannot be blocked a second time. Protocols Transformations Do transformations work with Segment replays? If you create a destination scoped transformation and request a replay for that destination, the transformation will transform events into the destination. Segment doesn’t recommended requesting a replay to resend events to a destination as that will likely result in duplicate events in the destination. Why can’t I create multiple transformations of the same type for the same event? To reduce the risk of creating circular and conflicting transformations, Segment only allows a single transformation to be created for each distinct source, event, destination and type pairing. That means you cannot create two Rename track event transformations for a order_completed event. This eliminates the possibility of different stakeholders creating conflicting transformations to satisfy their own needs. It also simplifies the Transformations list view, making it much easier to sort and filter by source, event, destination, etc. Why can’t I select multiple events or destinations in a single transformation? In early transformations prototypes, Segment allowed users to select multiple events and destinations for a single transformation rule. Segment realized, however, that this created a structure that was impossible to scale, and likely to generate unintended consequences. For example, if Segment allows multiple track events to be selected for a property name change, it’d be possible to create conflicting changes. Instead, by enforcing a single event, Segment can check to see if a transformation rule exists and smartly link you to that rule using a warning. What permissions are required to create and edit transformations? Only workspace admins are allowed to create transformations. What permissions are required to view transformations? All users with Protocols admin or read-only permissions can view transformations. Why can’t Segment support transformations for device-mode destinations? Transformations introduce advanced logic that at scale may impact performance of client-side libraries. If you are interested in testing new functionality which supports device-mode destination transformations in analytics.js, contact your account rep. Are Destination Filters applied before or after my Protocols Transformations? That depends. If you are working with source-level Transformations, the Protocols conversion will come first. If you are dealing with a destination scoped transformation (which is set to only impact data going to a specific destination), Destination Filters will be applied prior to Protocols Transformations. Why do I need Protocols to use transformations? Transformations are but one tool among many to help you improve data quality. Segment highly recommends that all customers interested in improving data quality start with a well defined Tracking Plan. The Tracking Plan serves as a roadmap for how you want to collect data. Without a clear roadmap, it’s nearly impossible to build alignment around how transformations should be used to improve data quality, leading to more data quality issues than it solves. Are transformations applied when using the Event Tester? Transformations are not applied to events sent through the Event Tester . The Event Tester operates independently from the Segment pipeline, focusing solely on testing specific connections to a destination. For a transformation to take effect, the event must be processed through the Segment pipeline. Why am I getting the error “rules must contain less than or equal to 200 items” when using the Public API? Can I increase this limit? This error occurs because there is a limit of 200 rules per API update. This restriction is by design to ensure stable API performance. Segment is not able to increase this limit on your behalf. To work around this, split your update into smaller batches, each with 200 or fewer rules. This page was last modified: 08 Jan 2025 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Protocols Notifications Protocols Tracking Plan Protocols Validation Protocols Enforcement Protocols Transformations Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Protocols Frequently Asked Questions"
      },
      {
        "level": 2,
        "text": "Protocols Notifications"
      },
      {
        "level": 3,
        "text": "How can I subscribe to Protocols notifications?"
      },
      {
        "level": 3,
        "text": "How can I get notified when someone makes a change to my tracking plan?"
      },
      {
        "level": 3,
        "text": "How do I get notified when new violations are generated? Can I create custom violation notifications?"
      },
      {
        "level": 2,
        "text": "Protocols Tracking Plan"
      },
      {
        "level": 3,
        "text": "What is the Segment Consent Preference Updated event, and who added it to my Tracking Plans?"
      },
      {
        "level": 3,
        "text": "How do I add Page and Screen events to my Tracking Plan?"
      },
      {
        "level": 3,
        "text": "How can I see who made changes to my Tracking Plan?"
      },
      {
        "level": 3,
        "text": "How many Sources can I connect to a Tracking Plan?"
      },
      {
        "level": 3,
        "text": "Can I duplicate a Tracking Plan in the Segment UI?"
      },
      {
        "level": 3,
        "text": "How do I handle versioning with mobile apps?"
      },
      {
        "level": 3,
        "text": "How do I handle null property values?"
      },
      {
        "level": 3,
        "text": "Can I group specific events in a Tracking Plan?"
      },
      {
        "level": 3,
        "text": "How do I send someone a specific event or group of events to implement?"
      },
      {
        "level": 3,
        "text": "Can I create a master Tracking Plan that supersedes all other Tracking Plans?"
      },
      {
        "level": 3,
        "text": "Can I copy a Tracking Plan into a library?"
      },
      {
        "level": 3,
        "text": "Can I transfer a Tracking Plan between production and staging environments?"
      },
      {
        "level": 3,
        "text": "Can I connect a Source to more than one Tracking Plan?"
      },
      {
        "level": 3,
        "text": "How do Tracking Plans work?"
      },
      {
        "level": 3,
        "text": "Why are my unplanned properties still getting sent to my destinations even though I’ve set the dropdown to “Omit Properties”?"
      },
      {
        "level": 3,
        "text": "Why do I have two different Tracking Plan IDs?"
      },
      {
        "level": 3,
        "text": "How do I import events from a Source Schema into a Tracking Plan?"
      },
      {
        "level": 3,
        "text": "Can I import events from my Source Schema into a Tracking Plan?"
      },
      {
        "level": 3,
        "text": "Can I recover a Tracking Plan that was deleted?"
      },
      {
        "level": 2,
        "text": "Protocols Validation"
      },
      {
        "level": 3,
        "text": "What is the difference between Violations Emails and the Violations page in the Segment UI?"
      },
      {
        "level": 3,
        "text": "Why do I see root listed on my Violations page?"
      },
      {
        "level": 2,
        "text": "Protocols Enforcement"
      },
      {
        "level": 3,
        "text": "Why can’t I use the Schema to filter my events?"
      },
      {
        "level": 3,
        "text": "If I enable blocking, what happens to the blocked events? Are events just blocked from specific Destinations or the entire Segment pipeline?"
      },
      {
        "level": 3,
        "text": "If I omit unplanned properties or properties that generate JSON schema violations, what happens to them?"
      },
      {
        "level": 3,
        "text": "Why am I seeing unplanned properties/traits in the payload when violations are triggered, despite using schema controls to omit them?"
      },
      {
        "level": 3,
        "text": "Why am I still seeing unplanned properties in my Source Schema when I’ve added the properties to a new version of my Tracking Plan?"
      },
      {
        "level": 3,
        "text": "Do blocked and discarded events count towards my MTU counts?"
      },
      {
        "level": 3,
        "text": "Do warehouse connectors use the data type definitions when creating a warehouse schema?"
      },
      {
        "level": 3,
        "text": "Can I use schema controls to block events forwarded to my source from another source?"
      },
      {
        "level": 2,
        "text": "Protocols Transformations"
      },
      {
        "level": 3,
        "text": "Do transformations work with Segment replays?"
      },
      {
        "level": 3,
        "text": "Why can’t I create multiple transformations of the same type for the same event?"
      },
      {
        "level": 3,
        "text": "Why can’t I select multiple events or destinations in a single transformation?"
      },
      {
        "level": 3,
        "text": "What permissions are required to create and edit transformations?"
      },
      {
        "level": 3,
        "text": "What permissions are required to view transformations?"
      },
      {
        "level": 3,
        "text": "Why can’t Segment support transformations for device-mode destinations?"
      },
      {
        "level": 3,
        "text": "Are Destination Filters applied before or after my Protocols Transformations?"
      },
      {
        "level": 3,
        "text": "Why do I need Protocols to use transformations?"
      },
      {
        "level": 3,
        "text": "Are transformations applied when using the Event Tester?"
      },
      {
        "level": 3,
        "text": "Why am I getting the error “rules must contain less than or equal to 200 items” when using the Public API? Can I increase this limit?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/privacy/consent-management/consent-in-retl/",
    "title": " Consent in Reverse ETL | Segment Documentation",
    "content": "Home / Privacy / Consent management / Consent in Reverse ETL Consent in Reverse ETL Free x Team x Business ✓ Addon x ? Consent Management is available to customers on Business tier plans. See the available plans , or contact Support . On this page Prerequisites Step 1: Create consent categories in the Segment app Step 2: Add your Reverse ETL source Step 3: Identify consent columns Step 4: Connect your downstream destinations Validate your consent mapping With Consent Management in Reverse ETL, you can enforce your end-users’ consent preferences that are captured by your consent management platform (CMP) and stored in your warehouse. To enforce consent stored in your warehouse, build a Reverse ETL model that identifies consent categories. You can create a “consent to” column mapping in a new data model or update an existing data model to include a “consent to” mapping. Consent in Reverse ETL supports Reverse ETL-supported Actions destinations and Segment Connections At this time, Consent in Reverse ETL does not support adding consent to Segment Profiles using the Segment Profiles destination. To enforce consent data in your classic Segment destinations, use the Segment Connections destination . Prerequisites Consent management edit and update capabilities limited to Workspace Owners Only users with the Workspace Owner role are able to create, edit, and disable consent categories. All other users have read-only access to Consent Management features. Before you can enforce consent stored in your warehouse, take the following steps: Set up your third-party consent management tool and create consent categories . Take note of your consent categories and the key or ID associated with each category. Know how your company uses each destination . You need to know which destinations to map to each category. Store your end user consent in a warehouse that Segment supports for Reverse ETL . Segment supports Reverse ETL capabilities in Azure, BigQuery, Databricks, Postgres, Snowflake, and Redshift data warehouses. Other data warehouses are not supported. Step 1: Create consent categories in the Segment app Limited availability of destinations Reverse ETL supports the Actions destinations in the Reverse ETL catalog and Segment Connections . From the Segment homepage , select the Privacy tab and click Consent Management . On the Consent management page, click Create categories . Confirm that you have completed the required prerequisites, and click Next . On the Create consent categories page, add the following information to the category form: Category name : Enter a name that describes your use case for the data sent to this destination. This field only accepts category names that are 20 characters or less. Category ID : In OneTrust, this is a string of up to five alphanumeric characters, but other CMPs may have a different format. This field is case sensitive. Mapped destinations : Select one or more of your Reverse ETL destinations to map to this category. Category mappings apply to all instances of a destination. After you’ve finished setting up your category or categories, click Save . Segment recommends mapping all Reverse ETL destinations to a category Segment assumes all destinations without a mapping do not require user consent and will receive all events containing a consent object. If a destination is mapped to multiple categories, a user must consent to all categories for data to flow to the destination. To edit or disable consent categories, view the Configure Consent Management documentation. Step 2: Add your Reverse ETL source If you’ve already added a Reverse ETL source to your workspace, you can proceed to Step 3: Identify consent columns . If you haven’t already configured a Reverse ETL source in your workspace, follow the instructions in the Reverse ETL: Add a source documentation to add your warehouse as a data source. When you’ve configured your Reverse ETL source, proceed to Step 3: Identify consent columns . Step 3: Identify consent columns After you set up consent categories in the Segment app, you must identify the columns in your data warehouse that store end user consent by creating a model , or SQL query that defines the set of data you want to synchronize to your Reverse ETL destinations. When building your data model, Segment recommends that you represent consent as a boolean true or false value and map one consent category to one column. Creating a data model that does not include information about consent preferences results in no consent enforcement If you create consent categories in your workspace but fail to identify columns that contain consent preferences in your data model, events flow to all destinations in your workspace regardless of end user consent preferences. Identify consent when building your model To identify consent when building your model: Navigate to Connections > Sources and select the Reverse ETL tab. Select your source and click Add Model . Click SQL Editor as your modeling method. Create the SQL query that’ll define your model. Your model is used to map data to your Reverse ETL destinations. Choose a column to use as the unique identifier for each record in the Unique Identifier column field.\n The Unique Identifier should be a column with unique values per record to ensure checkpointing works as expected. It can be a primary key. This column is used to detect new, updated, and deleted records. Click Preview to see a preview of the results of your SQL query. The data from the preview is extracted from the first 10 records of your warehouse. Click Next . Enter your Model Name. Click Create Model . Select Add consent mapping . On the Add consent mapping popup, identify the column in your model that holds the consent preferences for the consent category. Select Add consent mapping to identify columns for all of your consent categories. When you’re satisfied with your consent mappings, click Save . Update your Reverse ETL model to include consent To update an existing Reverse ETL model to include consent enforcement: Navigate to Connections > Destinations and select the Reverse ETL tab. Select the source and the model you want to edit. Select the Query Builder tab to edit your query. When you’re editing your query, include columns that store information about end user consent preferences. When you’ve finished making changes, click Save Query . Navigate to Settings > Consent settings . Select Add consent mapping . On the Add consent mapping popup, identify the column in your model that holds the consent preferences for the consent category. Select Add consent mapping to identify columns for all of your consent categories. When you’re satisfied with your consent mappings, click Save . You can select the Settings tab and click Consent settings to verify that the consent categories in your model match the consent categories you configured in your workspace. You can store each consent category in its own column in your warehouse, or store your consent information in one single blob column. Segment requires your consent categories to be in their own column in your data model. The following sample model maps consent categories from each column in your database: select USERID , name , email , distinctid , Ads , Personalization , Analytics , from CONSENT_PREFERENCES ; The following sample model maps consent categories from one blob column in your database: select USERID , name , email , distinctid , CAST ( CONSENT_OBJ : consent . cookie . Advertising as Boolean ) as Ads , CAST ( CONSENT_OBJ : consent . cookie . Personalization as Boolean ) as Personalization , CAST ( CONSENT_OBJ : consent . cookie . Analytics as Boolean ) as Analytics , from CONSENT_PREFERENCES ; Failing to identify consent columns in your warehouse might lead to unintentional data loss If you have destinations mapped to consent categories in the Segment app but fail to identify a column in your warehouse that stores consent for a category, then consent preference for that category will be considered to be false and no data will flow to destinations mapped to the category . Step 4: Connect your downstream destinations After you set up categories in the Segment app and create a SQL model that extracts consent information, connect your downstream destinations to complete the consent enforcement process. Consent in Reverse ETL supports Reverse ETL-supported Actions destinations and Segment Connections At this time, Consent in Reverse ETL does not support enforcing consent in the Segment Profiles destination. To enforce consent data in your classic Segment destinations, use the Segment Connections destination . To add your first destination: Navigate to Connections > Destinations and select the Reverse ETL tab. Click Add Reverse ETL destination . Select the destination you want to connect to and click Configure . Select the Reverse ETL source you want to connect the destination to. Enter the Destination name and click Create Destination . Enter the required information on the Settings tab of the destination. Navigate to the destination settings tab and enable the destination. If the destination is disabled, then Segment won’t be able to start a sync. Segment does not count Reverse ETL records filtered by Consent Management toward your Reverse ETL limits Records filtered out by Consent Management are not counted as part of your Reverse ETL limits. For more information about Reverse ETL limits, see the Reverse ETL Limits documentation. Validate your consent mapping You can validate that you successfully created your consent mapping in Segment Connections or supported Reverse ETL Actions destinations using the following methods. Segment Connections destination Segment automatically adds the consent object to every event that’s routed downstream to your Segment Connections destination. Consent enforcement in Connections validates that only consenting data flows downstream to any classic Segment destinations connected to your Segment Connections instance. Open the Source Debugger for your Reverse ETL source and confirm that the consent object appears on every event and that the consent object has the categories you mapped in Step 2: Identify consent columns . Reverse ETL Actions destinations Segment automatically filters out data from users who have not consented to the category mapped to your destination. To verify that this behavior is working as intended, open Delivery Overview for a RETL-supported Actions destination and view the events that were successfully delivered to the destination. The events in your destination should only come from users that consented to send data to the category that your supported Actions destination belongs to. This page was last modified: 25 Jul 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Prerequisites Step 1: Create consent categories in the Segment app Step 2: Add your Reverse ETL source Step 3: Identify consent columns Step 4: Connect your downstream destinations Validate your consent mapping Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Consent in Reverse ETL"
      },
      {
        "level": 2,
        "text": "Prerequisites"
      },
      {
        "level": 2,
        "text": "Step 1: Create consent categories in the Segment app"
      },
      {
        "level": 2,
        "text": "Step 2: Add your Reverse ETL source"
      },
      {
        "level": 2,
        "text": "Step 3: Identify consent columns"
      },
      {
        "level": 3,
        "text": "Identify consent when building your model"
      },
      {
        "level": 3,
        "text": "Update your Reverse ETL model to include consent"
      },
      {
        "level": 2,
        "text": "Step 4: Connect your downstream destinations"
      },
      {
        "level": 2,
        "text": "Validate your consent mapping"
      },
      {
        "level": 3,
        "text": "Segment Connections destination"
      },
      {
        "level": 3,
        "text": "Reverse ETL Actions destinations"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/reverse-etl/system/",
    "title": " Reverse ETL System | Segment Documentation",
    "content": "Home / Connections / Reverse etl / Reverse ETL System Reverse ETL System On this page Record diffing Limits View reference information about how Segment detects data changes in your warehouse and the rate and usage limits associated with Reverse ETL. Record diffing Reverse ETL computes the incremental changes to your data directly within your data warehouse. The Unique Identifier column is used to detect the data changes, such as new, updated, and deleted records. Delete Records Payload The only value passed for deleted records is their unique ID, which can be accessed as __segment_id . As of September 24, 2024, deleted records also contain all columns selected by your model, with null values in place of data. For Segment to compute the data changes within your warehouse, Segment needs to have both read and write permissions to the warehouse schema table. At a high level, the extract process requires read permissions for the query being executed. Segment keeps track of changes to the query results through tables that Segment manages in a dedicated schema (for example, _segment_reverse_etl ), which requires some write permissions. There may be cost implications to having Segment query your warehouse tables. Limits To provide consistent performance and reliability at scale, Segment enforces default use and rate limits for Reverse ETL. Usage limits Reverse ETL usage limits are measured based on the number of records processed to each destination – this includes both successful and failed records. For example, if you processed 50K records to Braze and 50K records to Mixpanel, then your total Reverse ETL usage is 100K records. Processed records represents the number of records Segment attempts to send to each destination. Keep in mind that not all processed records are successfully delivered, for example, such as when the destination experiences an issue. Your plan determines how many Reverse ETL records you can process in one monthly billing cycle. When your limit is reached before the end of your billing period, your syncs will pause and then resume on your next billing cycle. To see how many records you’ve processed using Reverse ETL, navigate to Settings > Usage & billing and select the Reverse ETL tab. Plan Number of Reverse ETL records you can process to destinations per month How to increase your number of Reverse ETL records Free 500K Upgrade to the Teams plan in the Segment app by navigating to Settings > Usage & billing . Teams 1 million Contact your sales representative to upgrade your plan to Business. Business 50 x the number of MTUs or .25 x the number of monthly API calls Contact your sales rep to upgrade your plan. If you have a non-standard or high volume usage plan, you may have unique Reverse ETL limits or custom pricing. To see your Reverse ETL limits in the Segment app, select Settings > Usage & Billing . Configuration limits Name Details Limit Model query length The maximum length for the model SQL query. 65,535 characters Model identifier column name length The maximum length for the ID column name. 191 characters Model timestamp column name length The maximum length for the timestamp column name. 191 characters Sync frequency The shortest possible duration Segment allows between syncs. 15 minutes Extract limits The extract phase is the time spent connecting to your database, executing the model query, updating internal state tables and staging the extracted records for loading. Name Details Limit Record count The maximum number of records a single sync will process. If a sync would contain more than 150 million records, Segment separates the data into multiple syncs, each containing no more than 150 million records Note: This is the number of records extracted from the warehouse, not the limit for the number of records loaded to the destination (for example, new/update/deleted). * 150 million records Column count The maximum number of columns a single sync will process. 512 columns Column name length The maximum length of a record column. 128 characters Record JSON size The maximum size for a record when converted to JSON (some of this limit is used by Segment). 512 KiB Column JSON size The maximum size of any single column value. 128 KiB * : If Segment identifies a sync would be larger than 150 million records, Segment extracts 150 million of the records in the initial sync and syncs any additional records during the next scheduled or manual sync. For example, if a sync would contain 700 million records, Segment would run an initial 150 million record sync, and during the next three scheduled or manual syncs, would sync 150 million records. The fifth scheduled or manual sync would contain the remaining 100 million records. This page was last modified: 25 Sep 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Record diffing Limits Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Reverse ETL System"
      },
      {
        "level": 2,
        "text": "Record diffing"
      },
      {
        "level": 2,
        "text": "Limits"
      },
      {
        "level": 3,
        "text": "Usage limits"
      },
      {
        "level": 3,
        "text": "Configuration limits"
      },
      {
        "level": 3,
        "text": "Extract limits"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/content/mobile-push/",
    "title": " Mobile Push Template | Segment Documentation",
    "content": "Home / Engage / Content / Mobile Push Template Mobile Push Template Free x Team x Business ✓ + Engage Premier ✓ ? Engage Premier requires a Business tier account and includes Engage Foundations and Unify. See the available plans , or contact Support . On this page Mobile push template types Build a mobile push message template Test your mobile push template Advanced settings Personalize with merge tags Next steps Engage Premier entered an End of Sale (EOS) period effective June 10, 2024. Existing Segment customers will continue to have access and support to Engage Premier until an end-of-life (EOL) date is announced. Segment recommends exploring the following pages in preparation of a migration or future MCM needs: Twilio Marketing Campaigns Preferred ISV Partners: Airship Blog Bloomreach Blog Braze Blog Insider Blog Klaviyo Blog Twilio Engage Foundations Documentation Use Twilio Engage to build mobile push templates to include throughout your marketing campaigns. Mobile push template types You can choose between two mobile push template types: Media , which contains media and text content Text , which contains text content Build a mobile push message template To build mobile push templates in Engage, first configure Engage for mobile . Follow these steps to build a mobile push template: Navigate to Engage > Content and click Create template . Select Push , then click Configure . Enter a template name and select your template’s language. Select your template’s content type, then click Next . For media templates, enter your message’s title in the Title field, its body in the Body field, add the media URL, then add any desired merge tags . For text templates, enter your message’s title in the Title field, its body in the Body field, then add any desired merge tags. Select a click behavior . Click Test or Save to save your template. Click behaviors When you build a mobile push template, you can choose between three click behaviors, which determine what happens when a user taps on the mobile push: Behavior Description Open app Opens an app. You can specify a URL to take the user to a specific screen with your app. If you don’t enter a URL, this behavior will take the user to the app’s home screen. Open URL Opens the specified URL. Custom action Takes any value as text input. Your app determines how to handle the value. For example, you could enter a custom action of open_settings , and then instruct your application to open the settings application when a user taps the push and the push arrives with click behavior = open_settings . Test your mobile push template Push tokens Push tokens are unique identifiers Segment associates with each profile. For mobile push, you’ll need to configure identity resolution settings for the push tokens ios.push_token and android.push_token . Using the Profile explorer, you can find a profile’s push tokens by opening a profile and then selecting the Identities tab. You can only send mobile pushes to profiles with push tokens enabled. Follow these steps to test your mobile push: Choose a template to test: For new templates, select Test once you’ve finished building a template. For existing templates, navigate to Engage > Content > Push , select the template you want to test, then click Test . Mobile push templates have a content size limit of 4KB. Choose a messaging service and add a recipient. You can add recipients using an email address or user ID. Click Send test push . Segment verifies that the profile you’re sending a test to has a push token, then sends the test. If the test mobile push doesn’t work as expected, confirm that the profile you’re sending to has a push token. Advanced settings Badge count settings Badge counts appear in the corner of an app icon on your user’s device. Badge counts show the number of unread notifications. During push notification setup, you can set badge count behavior from the badge count dropdown. Choose from these badge count settings: Increase by : for each new notification, the badge count increases by the number you enter. Increase by is the standard behavior for badge counts. Decrease by : for each new notification, the previous badge count decreases by the number you enter. Use Decrease by to send notifications quietly. Set to : replaces all previous sent notifications with the number you enter. Action buttons Action buttons sit below a push notification and let your users take action on the push. You can use action buttons to encourage users to make a purchase, visit a website, or share content on social media, for example. Follow these steps to add an action button: Under Advanced Settings , click + Add action button . Enter an action button identifier. Enter the action button text. This is the text the user will see on the action button. Choose an open action. You can choose from open app, open URL, or a custom action. You can add up to three action buttons for each push notification. Personalize with merge tags Personalize mobile push content in Engage using profile traits as merge tags in your messages. To personalize a mobile push, click Add merge tags in the template builder and select the profile traits to include in your message. Engage inserts the selected traits inside merge tags based on cursor placement in the message. This allows you to personalize each mobile push you send to recipients. You can also use liquid templating to create dynamic content in the template editor. To learn more about profile traits, visit Segment’s Computed Traits and SQL Traits documentation. Next steps Now that you’ve built a mobile push template, you’re ready to begin sending mobile push campaigns . This page was last modified: 15 Jul 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Mobile push template types Build a mobile push message template Test your mobile push template Advanced settings Personalize with merge tags Next steps Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Mobile Push Template"
      },
      {
        "level": 2,
        "text": "Mobile push template types"
      },
      {
        "level": 2,
        "text": "Build a mobile push message template"
      },
      {
        "level": 3,
        "text": "Click behaviors"
      },
      {
        "level": 2,
        "text": "Test your mobile push template"
      },
      {
        "level": 2,
        "text": "Advanced settings"
      },
      {
        "level": 3,
        "text": "Badge count settings"
      },
      {
        "level": 3,
        "text": "Action buttons"
      },
      {
        "level": 2,
        "text": "Personalize with merge tags"
      },
      {
        "level": 2,
        "text": "Next steps"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/traits/recommended-items/",
    "title": " Recommended Items | Segment Documentation",
    "content": "Home / Unify / Traits / Recommended Items Recommended Items Free x Team x Business ✓ + Unify Plus ✓ ? Unify Plus requires a business tier account and is included with Engage See the available plans , or contact Support . On this page How Recommended Items works Create a Recommended Items trait Example use case: personalized album recommendations Best practices With Recommended Items, you can add personalized item recommendations as a computed trait to each user profile. Based on a user’s past interactions, this trait generates a list of up to 5 items, like products, articles, or songs, that each user is most likely to engage with. Segment designed Recommended Items for cases where you want to personalize experiences, like email content, in-app recommendations, or website suggestions, to fit each user’s unique preferences. On this page, you’ll learn how Recommended Items works, how to create a Recommended Item trait, and best practices to get the most out of your recommendations. . How Recommended Items works Recommended Items uses your interaction events (like order_completed , product_added , and product_searched ) along with event metadata to generate personalized recommendations for each user. Here’s an overview of the process: Data collection : Segment captures user interactions from your chosen events. Pattern analysis : Machine learning models analyze these interactions to recognize patterns and user preferences. Item ranking : Based on this analysis, Segment generates an ordered list of recommended items for each user, ranked from most to least likely to engage. Profile storage : Segment then saves these recommendations as an array on each eligible user profile. Once Segment attaches the recommendation array to a profile, you can use it to: Personalize experiences with the Profile API Send Recommended Items traits to downstream destinations Build further segments based on Recommended Items Trigger customized campaigns and experiences tailored to individual users Create a Recommended Items trait Before you begin Before you create Recommended Item traits, you’ll first need to set up a Recommendation Catalog. The catalog setup process involves mapping your interaction events and providing product metadata to support recommendations. If you haven’t yet set up your Recommendation Catalog, follow the steps in the Product Based Audiences documentation . To create a Recommended Item trait: In your Segment workspace, navigate to Unify > Traits > + Create computed trait . In the New Computed Trait builder, click Recommendation , then click Next . In Select users , click + Add condition to choose the users who should receive recommendations. You can create recommendations for up to 2 million non-anonymous customers. In Define recommended items , choose the item type you want to recommend. This is based on your product catalog. Choose how many item types you want to return onto each profile. You can select up to 5 item types. Click Calculate to get a preview of the number of users who will receive your recommendations, then click Next . ( Optional ) Select destinations you want to sync the trait to, then click Next . Give your trait a name, then click Create Trait . Segment begins creating your new trait. This process could take up to 48 hours. Example use case: personalized album recommendations Suppose you’re managing a music streaming app and want to give each user personalized music recommendations based on their listening habits. Here’s how you could configure this trait: Step Configuration Select users Use an audience based on up to 2 million active, non-anonymous listeners who played at least one song in the past month. Item type Select Albums as the item type to recommend. Because you have an extensive catalog of music, this lets each listener receive recommendations tailored to their interests. Number of item types You decide to return a maximum of 5 albums for each profile, keeping the recommendations relevant and concise. Calculate Clicking Calculate gives you an overview of how many users will receive the album recommendations. Use it to ensure your conditions and catalog mapping meet your criteria. Sync to destinations This optional step lets you sync the trait to third-party destinations to deliver album recommendations over email, in-app messaging, or push notifications. Trait naming Name your trait Personalized Album Recommendations , making it easy to identify for future campaigns. By setting up a trait like this, each user profile now includes personalized recommendations that reflect individual tastes. You can use these recommendations across a range of touchpoints, like in-app sections, personalized email content, or targeted messaging, to create a more engaging and customized user experience. Best practices Keep the following in mind as you work with Recommended Items: Limit recommendations to key items : Start with 5-7 items per profile. This keeps recommendations concise and tailored to each user’s preferences. Consider audience size : Larger audiences can dilute engagement rates for each recommended item. Focusing on the top 20% of users keeps recommendations relevant and impactful. Give the system time to build the trait : Recommended Item traits can take up to 48 hours to build, depending on data volume and complexity. Segment recommends waiting until 48 hours have passed before using the trait in campaigns. This page was last modified: 31 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page How Recommended Items works Create a Recommended Items trait Example use case: personalized album recommendations Best practices Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Recommended Items"
      },
      {
        "level": 2,
        "text": "How Recommended Items works"
      },
      {
        "level": 2,
        "text": "Create a Recommended Items trait"
      },
      {
        "level": 2,
        "text": "Example use case: personalized album recommendations"
      },
      {
        "level": 2,
        "text": "Best practices"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/protocols/enforce/forward-blocked-events/",
    "title": " Forward blocked events | Segment Documentation",
    "content": "Home / Protocols / Enforce / Forward blocked events Forward blocked events Free x Team x Business ✓ + Protocols ✓ ? Protocols is available as an add-on for Business plans only. See the available plans , or contact Support . If you’re concerned about permanently discarding blocked events, you can enable blocked event forwarding on a Segment Source. To set up forwarding, navigate to the settings tab of the Source, then Schema Configuration. Select the source you’ll forward events to from the Blocked Events and Traits dropdown. Segment recommends that you create a new Source for forwarded events to avoid contaminating production data and enable blocking only when you are confident about the quality of your data. Since forwarding happens server to server, Segment recommends creating a HTTP Tracking API source , though any server-side source will work. Only blocked events are forwarded to the source. Events with omitted traits are not forwarded. Instead, Segment inserts a context.protocols object into the event payload which contains the omitted properties or traits. Billing Note: Events forwarded to another Source count towards to your MTU counts. Blocking and discarding events does not contribute to your MTU counts. This page was last modified: 03 Aug 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Forward blocked events"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/user-subscriptions/subscription-states/",
    "title": " User Subscription States | Segment Documentation",
    "content": "Home / Engage / User subscriptions / User Subscription States User Subscription States Free x Team x Business ✓ + Engage Premier ✓ ? Engage Premier requires a Business tier account and includes Engage Foundations and Unify. See the available plans , or contact Support . On this page Subscription states overview Understanding subscription states Setting user subscriptions Engage Premier entered an End of Sale (EOS) period effective  June 10, 2024. Existing Segment customers will continue to have access and support to Engage Premier until an end-of-life (EOL) date is announced. We recommend exploring the following pages in preparation of a migration or future MCM needs: Twilio Marketing Campaigns Preferred ISV Partners: Airship Blog Bloomreach Blog Braze Blog Insider Blog Klaviyo Blog Twilio Engage Foundations Documentation Customer profiles in your Segment audiences contain contact vectors . A contact vector is a piece of unique, specific contact information associated with a customer, like the customer’s email address or phone number. Segment associates one of four user subscription states with each contact vector in a customer profile. These subscription states indicate the level of consent customers give you to send them your marketing materials. A customer profile, then, may have contact vectors with different subscription states. For example, a customer may consent to receive email campaigns but not SMS campaigns. Subscription states, then, describe permissions at the contact vector level, not at the customer level. Understanding the four user subscription states helps you improve campaign deliverability and comply with sending guidelines and legislation. This page explains the four subscription states and how each impacts your sending ability. Subscription states overview The following table displays the four subscription states: subscription states description example subscribed A user has given you their contact information and consented to receive marketing campaigns. Users that have signed up for a weekly newsletter unsubscribed A user has given you their contact information but doesn’t want to receive campaigns. Users that subscribed, then unsubscribed, from a weekly newsletter did-not-subscribe A user gave you their contact information but made no decision about receiving marketing campaigns. A user provided their email address or phone number in an online transaction, but didn’t sign up to receive your weekly newsletter. No subscription status A user did not give you their contact information and made no decision about receiving marketing campaigns. Segment collected an email or phone number through identity resolution. No user actively provided the email or phone number. Understanding subscription states You can gain insight into your audience profiles by learning how and why each subscription state is associated with a user’s profile.  Below, you’ll find the four states described in detail, along with common scenarios that produce those states. Subscribed A subscribed user has, at some point, given you explicit permission to send them your marketing materials. Subscribed users have intentionally requested to receive your marketing materials and have taken voluntary action to confirm that choice. You may have received this consent from a number of sources, including the following: A user who opted in to receive marketing campaigns during online checkout A user who signed up for your marketing campaigns on your website’s signup form A user who signed up for marketing campaigns at an in-person event, like a conference It’s your responsibility to ensure that Segment correctly reflects your users’ subscription choices. Failure to do so may put you in violation of legislation like CAN-SPAM , TCPA , or GDPR . Unsubscribed An unsubscribed user has intentionally opted out of receiving your marketing materials. You cannot send Engage campaigns to unsubscribed users. Users commonly unsubscribe in the following ways: By clicking an unsubscribe link in an email campaign By replying with STOP to an SMS campaign By contacting you in writing to request that you unsubscribe them You must include an unsubscribe option in all Engage email and SMS campaigns. Did not subscribe Users with the did-not-subscribe state associated with their email address or phone number gave you their contact information without explicitly agreeing to receive your marketing materials. The following scenarios often lead to an email or phone number with the did-not-subscribe subscription state: A user provides their email or phone number during an online transaction but doesn’t opt in to your marketing materials. The user’s email address was obtained from a support request. Emails or phone numbers with a did-not-subscribe status won’t receive your marketing campaigns. No subscription status Profiles with no subscription status , or a blank status, indicate that Segment has created a profile for the user, but that the user never actually provided their contact information. Some situations that lead to the no subscription status state include the following: Publicly available email addresses or phone numbers Email addresses or phone numbers you acquired through other audience lists Segment collected the email address or phone number through standard platform tracking methods. Some contacts within your Segment space may fall into the no subscription status category. Identity resolution , for example, may result in a user profile created from connecting an email address with an anonymous ID. In this case, the profile would exist within your audience despite the fact that the user never had the option to subscribe or unsubscribe. Setting user subscriptions You can set subscription states by either CSV file upload or, programmatically, with the Public API . Uploading contacts with a CSV file works best for initial batches of contacts you’d like to bring into Engage. Syncing programmatically with the Public API is best suited for real-time and ongoing subscription maintenance, like when a user signs up for a form on your site or unsubscribes from your marketing campaigns within their notification center or account settings. To learn more about both options, reference the Engage documentation on using the CSV uploader and setting user subscriptions. Sync subscription statuses with SQL Use SQL to import user subscription states from your data warehouse back to Engage. When you sync with SQL, you can query user subscription data at automated intervals. Pull subscription statuses for each contact vector and use your data warehouse as a single source of truth for subscription data. This option is especially useful if you don’t have the ability to set subscription states with CSVs or Segment’s Public API. View Subscriptions with SQL Traits for more information. Troubleshooting subscription states On occasion, a user’s subscription state may not be up-to-date. For example, a user may have unsuccessfully attempted to unsubscribe from your marketing campaigns. The Public API will resolve most subscribe and unsubscribe requests in real time. In some circumstances, however, you’ll need to take action to update a user’s subscription state.  The following table lists some situations in which you may find a manual update useful: issue cause resolution Unsubscribed user still getting marketing campaigns Potential API call failure when updating the subscription state Ask the user to attempt to unsubscribe again; upload a CSV file with the user’s profile and a state of unsubscribed . User no longer receives desired email campaigns User may have accidentally clicked unsubscribe on an email campaign The user must resubscribe to your campaigns, or you can upload a CSV file with the contact and their corrected state. User no longer receives desired SMS campaigns User may have replied STOP to an SMS campaign You cannot change the state on your own; the user must send START, YES, or UNSTOP to the original campaign number from their own device. Reach out to support with questions you may have about resolving a user’s subscription state. This page was last modified: 15 Jul 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Subscription states overview Understanding subscription states Setting user subscriptions Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "User Subscription States"
      },
      {
        "level": 2,
        "text": "Subscription states overview"
      },
      {
        "level": 2,
        "text": "Understanding subscription states"
      },
      {
        "level": 3,
        "text": "Subscribed"
      },
      {
        "level": 3,
        "text": "Unsubscribed"
      },
      {
        "level": 3,
        "text": "Did not subscribe"
      },
      {
        "level": 3,
        "text": "No subscription status"
      },
      {
        "level": 2,
        "text": "Setting user subscriptions"
      },
      {
        "level": 3,
        "text": "Sync subscription statuses with SQL"
      },
      {
        "level": 3,
        "text": "Troubleshooting subscription states"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/audiences/organization/",
    "title": " Organizing Your Audiences | Segment Documentation",
    "content": "Home / Engage / Audiences / Organizing Your Audiences Organizing Your Audiences Free x Team x Business ✓ + Engage Foundations ✓ ? Engage Foundations requires a Business tier account and includes Unify. See the available plans , or contact Support . On this page Working with folders Editing and disbanding folders Moving Audiences into folders Clone Audiences Delete an Audience To add structure to your Spaces , you can organize Audiences into folders and clone Audiences within, and between, Spaces. Working with folders Folders allow you to group Audiences together. You can create, edit, and search through folders directly within the Engage Audiences page. Creating a folder To create a Folder, follow the steps below: Navigate to the Audiences tab within your Space. Click Create , then select Folder from the dropdown menu. Give your Folder a unique name, then click Add Audiences . Search for and select the Audience(s) you want to add to the Folder. To confirm the new Folder, click Add Audiences . Editing and disbanding folders To edit the name or description of a Folder you’ve created, click the More Options icon and select Edit . Once you’ve made your desired changes, click Save . To disband a Folder you’ve made, click the More Options icon and select Disband . Audiences from the disbanded Folder return to your main Audience list. Disbanding folders does not delete audiences. Moving Audiences into folders To move an Audience to a Folder you’ve already created, follow the steps below: Navigate to the Audiences tab within your Space. Hover over the Audience you want to move. Check the selection box that appears next to the Audience name. (Optional) : Repeat Steps 2 and 3 to move multiple Audiences. Click the Move icon that appears in the Audiences header. Select your destination Folder from the modal window. Click Move to confirm and move the selected Audiences. Clone Audiences Audience cloning creates a copy of your Audience. You can clone an Audience within the same space, or clone an Audience to a different space. Clone an Audience inside a Space To clone an Audience within the same Space, follow the steps below: Navigate to the Audiences tab within your Space. Click the More Options icon next to the Audience you want to clone. From the dropdown menu, click Clone . Select Current Space , then click Continue . Configure the Audience, click Preview Results , then click Select Destination . (Optional) : On the next screen, connect the Audience to a Destination.  Click Review & Create . Give your Audience a unique name, then click Create Audience . Cloning an Audience between Spaces You may wish to clone an Audience between spaces for a number of use cases, including the following: Copying an Audience between testing and production spaces Copying an Audience between business units Copying an Audience between teams Note When you clone an Audience to a different space, first verify that the target Space includes the same events and traits for the cloned Audience. To clone an Audience between Spaces, follow the steps below: Navigate to the Audiences tab within your Space. Click the More Options icon next to the Audience you want to clone. From the dropdown menu, click Clone . Select Different Space , choose your target Space, then click Continue . Configure the Audience, click Preview Results , then click Select Destination . (Optional) : On the next screen, connect the Audience to a Destination.  Click Review & Create . Give your Audience a unique name, then click Create Cloned Audience . If your target Space doesn’t include the cloned Audience’s events and traits, Engage prompts you to resolve the Space incompatibilities during Step 5.  As a best practice, verify that the target Space includes the Audience’s traits and events before cloning. Delete an Audience To delete an Audience, follow the steps below: Navigate to the Audiences tab within your Space. Select the Audience you want to delete, then click Settings . Click Enabled to toggle to Disabled , then click Delete Audience… . On the Delete Audience prompt, click Delete Audience to confirm. This page was last modified: 28 Jun 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Working with folders Editing and disbanding folders Moving Audiences into folders Clone Audiences Delete an Audience Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Organizing Your Audiences"
      },
      {
        "level": 2,
        "text": "Working with folders"
      },
      {
        "level": 3,
        "text": "Creating a folder"
      },
      {
        "level": 2,
        "text": "Editing and disbanding folders"
      },
      {
        "level": 2,
        "text": "Moving Audiences into folders"
      },
      {
        "level": 2,
        "text": "Clone Audiences"
      },
      {
        "level": 3,
        "text": "Clone an Audience inside a Space"
      },
      {
        "level": 3,
        "text": "Cloning an Audience between Spaces"
      },
      {
        "level": 2,
        "text": "Delete an Audience"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/oauth/",
    "title": " OAuth 2.0 | Segment Documentation",
    "content": "Home / Connections / OAuth 2.0 OAuth 2.0 Free x Team x Business ✓ Add-on x ? OAuth 2.0 is available to customers on Business tier plans. See the available plans , or contact Support . On this page Permissions Create an OAuth app Connect a source to OAuth Enable a source to OAuth Obtain the access token Edit an OAuth application Delete an OAuth app Revoke a token Supported sources Supported scopes OAuth 2.0 is an online authorization standard that uses tokens to grant access to API resources like Segment’s tracking API. You can use OAuth 2.0 as a security requirement for connections to third-party tools. Permissions Depending on your workspace permissions, your access to OAuth apps is limited. Segment Role Permission Workspace Owner You can view, create, and edit OAuth apps. Workspace Member You cannot view, create, or edit OAuth apps. Source Admin You can view and edit OAuth apps. You can connect and disconnect OAuth apps. You can enable or disable OAuth enforcement. Source Read-only You can only view OAuth apps. Function Admin You can view and edit OAuth apps. You can connect and disconnect OAuth apps. You can enable and disable OAuth enforcement. Function Read-only You can only view OAuth apps. Create an OAuth app You must have already created a workspace in Segment to use OAuth. To create a new OAuth application: Navigate to Settings > Workspace settings and select the Access Management tab. Select the OAuth application tab within the Access Management page. Click Create OAuth app . Enter the configuration settings: Settings Details Application name The name of the OAuth app. Public key Upload a public key in PEM format to authenticate through the OAuth application. You can upload a second public key after you create the OAuth application. You can create a public key by running the script: openssl rsa -in private.pem -pubout -outform PEM -out public.pem Public key name Enter a name for your public key. Token expiration period You can choose between: 1 day, 2 days, 3 days, 1 week, 2 weeks, 3 weeks, 30 days. Scope This specifies what type of access you need for each API. See the list of supported scopes . Click Create . Once you create your OAuth app, you can now connect a source to your OAuth app. Connect a source to OAuth OAuth only supports server-side sources. See the list of supported sources . To connect a source to OAuth: Navigate to Connections > Sources . Select the source you want to enable OAuth for. Go to the Settings tab of the source page and select OAuth app . Click Connect OAuth app . Select the OAuth app you want to connect the source to. Click Connect . To disconnect your source from OAuth, click Disconnect . Enable a source to OAuth Once you’ve connected your source to OAuth, you can enable it. To enable your source: Navigate to Connections > Sources and select your source. Go to the Settings tab of the source and select OAuth app . Turn the toggle on for Enable OAuth . To disable your source from OAuth, turn the toggle off for Enable OAuth . Obtain the access token You can obtain an access token once you create an OAuth application and enable a source to OAuth. Access tokens are only valid within a region. The supported regional authorization servers are: Oregon - https://oauth2.segment.io Dublin - https://oauth2.eu1.segmentapis.com To obtain the access token: Create a JWT token with the header and payload as below: Header {\n     \"alg\":\"RS256\", \n     \"typ\":\"JWT\", \n     \"kid\":\"<<KID>>\"\n } Payload {\n     \"iss\":\"<<ISS>>\",\n     \"sub\":\"<<SUB>>\",\n     \"aud\":\"<<AUD>>\", \n     \"iat\":\"<<IAT>>\",\n     \"exp\":\"<<EXP>>\",\n     \"jti\":\"<<JTI>>\"\n } Field Description KID The key ID of the public key in the OAuth application. ISS The identifier of the JWT issuer. SUB The OAuth application ID. IAT The epoch time in seconds when the token was issued. EXP The expiry time in seconds. This is expected to be valid only for a short duration under a minute. JTI The unique identifer for the token. Send a form-url-encoded POST request to the regional authorization server’s \\token route with the following parameters: grant_type=client_credentials\n client_assertion_type=urn:ietf:params:oauth:client-assertion-type:jwt-bearer\n client_assertion=<<JWT>>\n scope=<<SCOPE>> Field Description JWT The signed JWT token string from Step 1. SCOPE Scopes for which token is requested. See supported scopes . To use the access token, see an example of how to use the access token in the HTTP API source . Edit an OAuth application To edit an existing OAuth application: Navigate to Settings > Workspace settings and select the Access Management tab. Select the OAuth application tab within the Access Management page. Click the application name of the OAuth application you want to edit. On the Overview tab you can: Revoke a token Copy the Application ID and the Public key Delete the OAuth application Select the Settings tab on the right window where you can: Edit the Application name Delete a public key Add a new public key Change the token expiration period Edit your scope Click Save changes . Delete an OAuth app To delete an OAuth app, you must remove all connected sources from the app. To delete an OAuth app: Navigate to Settings > Workspace settings and select the Access Management tab. Select the OAuth application tab within the Access Management page. Select the App name of the OAuth app you want to delete. Select Delete OAuth app . Enter the name of the OAuth app you want to delete. Click Delete OAuth app . Revoke a token When security incidents expose access tokens, you can revoke your access token. To revoke a token: Navigate to Settings > Workspace settings and select the Access Management tab. Select the *OAuth application tab within the Access Management page. Select the App name with the token you want to delete. Enter the complete token Click Revoke token . Supported sources OAuth 2.0 currently supports these sources: HTTP Tracking API Node.js Public API Python Source Functions Supported scopes OAuth 2.0 currently supports these scopes: Tracking API scopes tracking_api:write Source Functions scopes functions:write Public API scopes public_api:read_write This page was last modified: 03 Sep 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Permissions Create an OAuth app Connect a source to OAuth Enable a source to OAuth Obtain the access token Edit an OAuth application Delete an OAuth app Revoke a token Supported sources Supported scopes Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "OAuth 2.0"
      },
      {
        "level": 2,
        "text": "Permissions"
      },
      {
        "level": 2,
        "text": "Create an OAuth app"
      },
      {
        "level": 2,
        "text": "Connect a source to OAuth"
      },
      {
        "level": 2,
        "text": "Enable a source to OAuth"
      },
      {
        "level": 2,
        "text": "Obtain the access token"
      },
      {
        "level": 2,
        "text": "Edit an OAuth application"
      },
      {
        "level": 2,
        "text": "Delete an OAuth app"
      },
      {
        "level": 2,
        "text": "Revoke a token"
      },
      {
        "level": 2,
        "text": "Supported sources"
      },
      {
        "level": 2,
        "text": "Supported scopes"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/api/public-api/",
    "title": " Public API | Segment Documentation",
    "content": "Home / Api / Public API Public API Free x Team ✓ Business ✓ Add-on x ? The Public API is available to customers on Team or Business plans. See the available plans , or contact Support . On this page Config API vs Public API Create a Public API token API Token Security FAQs Troubleshooting The Segment Public API helps you manage your Segment workspaces and its resources. You can use the API to perform CRUD (create, read, update, delete) operations at no extra charge. This includes working with resources such as Sources, Destinations, Warehouses, Tracking Plans, and the Segment Destinations and Sources Catalogs. The Public API is available to Team and Business Tier customers. All CRUD endpoints in the API follow REST conventions and use standard HTTP methods. Different URL endpoints represent different resources in a workspace. Segment Public API Documentation Research and test the Public API's available endpoints. If your application is built in Javascript / Typescript, Go, Java, or Swift, check out Segment’s Public API SDKs . Config API vs Public API The Public API includes the following benefits over the Config API: Benefit Details Future Enhancements Future improvements will be added to the Public API only. Improved error handling The Public API offers more specific error messages, for faster issue resolution. Versioning Each endpoint on the Public API can have multiple versions. Stable versions can coexist with beta or alpha versions. Higher rate limits The Public API can offer higher rate limits when needed or different rate limits per endpoint or token. Improved architecture The Public API is built with improved security, checks for authentication, authorization, input validation, HTTPS exposed services, auto-scaling, and more in mind. Cleaner mapping The Public API uses unique IDs for reference, in place of slugs in the Config API. Unique IDs are, by design, unique. Available in Europe The Public API is accessible to both US and EU-based workspaces. Increased reliability The Public API features more stable endpoints, and a 99.8% success rate Create a Public API token Only Workspace Owners can create a Public API token Only users with the Workspace Owner role can create a Public API token. For more information about roles, see Segment’s Roles documentation. To create a Public API token in your Segment workspace: Navigate to Settings > Workspace settings > Access Management > Tokens. Click the + Create Token button. Create a description for the token and assign it either Workspace Owner or Workspace Member access. Click Create . Copy your workspace token somewhere secure and click Done . To begin sending requests to the Public API, make sure to include the Public API Token into your HTTP requests with the Authorization Header and configured with Bearer Token and the value of the newly generated Public API token. API Token Security To enhance API token security, Segment partners with GitHub to prevent fraudulent use of exposed API tokens found in public git repositories. This helps to prevent malicious actors from using exposed tokens to perform unauthorized actions in your Segment workspace. Within seconds, GitHub scans each commit in public repositories for Public API tokens, and sends detected tokens to Segment. Valid tokens are automatically revoked and workspace owners are notified. Learn more about GitHub’s secret scanning program . FAQs What should I do if I see a notification that my token was exposed? In most cases, identifying and revoking an exposed token takes seconds. Segment recommends you check the audit trail to ensure no unauthorized actions were taken with the token. How did my token get exposed? Developers can accidentally commit tokens to public repositories, exposing them to the public. This can happen when developers use a token in a local development environment and forget to remove it before committing their code. Why are exposed tokens automatically revoked? By automatically revoking the exposed token, Segment helps keep your workspace secure and prevents potential abuse of the token. How do I enable this feature? This feature is automatically enabled for all workspaces on Team or Business tier plans. What should I do when I see a CORS error? If you see a CORS error, this means you’re attempting to make a request to the Public API on the front-end. The Public API is used for server-side only. To get rid of the error, move all Public API requests to a server. What User Role / Workspace permissions are required to generate Public API tokens? Only users that have a Workspace Owner role can create Public API Tokens. Troubleshooting The Update Schema Settings in Source endpoint returns error for field forwardingViolationsTo and forwardingBlockedEventsTo When you don’t have a source to forward violations or blocked events to, then exclude the fields forwardingViolationsTo or forwardingBlockedEventsTo entirely from the request and the setting will be disabled. PATCH endpoint : https://api.segmentapis.com/sources/{sourceId}/settings {\n    \"group\": {\n      \"allowTraitsOnViolations\": false,\n      \"allowUnplannedTraits\": false,\n      \"commonEventOnViolations\": \"ALLOW\"\n    },\n    \"identify\": {\n      \"allowTraitsOnViolations\": true,\n      \"allowUnplannedTraits\": true,\n      \"commonEventOnViolations\": \"Block\"\n    },\n    \"track\": {\n      \"allowEventOnViolations\": false,\n      \"allowPropertiesOnViolations\": false,\n      \"allowUnplannedEventProperties\": false,\n      \"allowUnplannedEvents\": false,\n      \"commonEventOnViolations\": \"OMIT_PROPERTIES\"\n    }\n  } What is the difference between a destination’s Instance ID and Meta ID? The destination’s Instance ID is specific to a single destination within your workspace. The destination’s Meta ID, which is returned by the delivery metrics endpoint, identifies which integration you’ve set up. For example, if you had a dev Mixpanel (Actions) destination and a prod Mixpanel (Actions) destination, they would have the same Meta ID but two different Instance IDs. This page was last modified: 24 Jun 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Config API vs Public API Create a Public API token API Token Security FAQs Troubleshooting Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Public API"
      },
      {
        "level": 2,
        "text": "Config API vs Public API"
      },
      {
        "level": 2,
        "text": "Create a Public API token"
      },
      {
        "level": 2,
        "text": "API Token Security"
      },
      {
        "level": 2,
        "text": "FAQs"
      },
      {
        "level": 2,
        "text": "Troubleshooting"
      },
      {
        "level": 3,
        "text": "What is the difference between a destination’s Instance ID and Meta ID?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/storage/data-lakes/",
    "title": " Segment Data Lakes Overview | Segment Documentation",
    "content": "Home / Connections / Storage / Segment Data Lakes Overview Segment Data Lakes Overview Free x Team x Business ✓ Add-on x ? Data Lakes is available for the listed account plans only. See the available plans , or contact Support . On this page How Data Lakes work Set up Segment Data Lakes (Azure) Data Lakes schema FAQ Segment Data Lakes will enter Limited Access in October 2024 After Segment Data Lakes enters Limited Access, new customers will no longer be able to create Segment Data Lake instances. Existing Segment customers with Data Lakes instances will continue to receive data and can create Data Lakes Destinations. Segment recommends considering alternative solutions, like AWS S3 or Databricks . A data lake is a centralized cloud storage location that holds structured and unstructured data. Data lakes typically have four layers: Storage layer: Holds large files and raw data. Metadata store: Stores the schema, or the process used to organize the files in the object store. Query layer: Allows you to run SQL queries on the object store. Compute layer: Allows you to write to and transform the data in the storage layer. Segment Data Lakes sends Segment data to a cloud data store, either AWS S3 or Azure Data Lake Storage Gen2 (ADLS), in a format optimized to reduce processing for data analytics and data science workloads. Segment data is great for building machine learning models for personalization and recommendations, and for other large scale advanced analytics. Data Lakes reduces the amount of processing required to get real value out of your data. Segment Data Lakes deletion policies Segment Data Lakes (AWS) and Segment Data Lakes (Azure) do not support Segment’s user deletion and suppression capabilities, as you retain your data in systems that you manage. To learn more about Segment Data Lakes, check out the Segment blog post Introducing Segment Data Lakes . How Data Lakes work Segment supports Data Lakes hosted on two cloud providers: Amazon Web Services (AWS) and Microsoft Azure. Each cloud provider has a similar system for managing data, but offer different query engines, post-processing systems, and analytics options. How Segment Data Lakes (AWS) works Data Lakes store Segment data in S3 in a read-optimized encoding format (Parquet) which makes the data more accessible and actionable. To help you zero-in on the right data, Data Lakes also creates logical data partitions and event tables, and integrates metadata with existing schema management tools, such as the AWS Glue Data Catalog. The resulting data set is optimized for use with systems like Spark, Athena, EMR, or machine learning vendors like DataBricks or DataRobot. Segment sends data to S3 by orchestrating the processing in an EMR (Elastic MapReduce) cluster within your AWS account using an assumed role. Customers using Data Lakes own and pay AWS directly for these AWS services. How Segment Data Lakes (Azure) works Data Lakes store Segment data in ADLS in a read-optimized encoding format (Parquet) which makes the data more accessible and actionable. To help you zero-in on the right data, Data Lakes also creates logical data partitions and event tables, and integrates metadata with existing schema management tools, like the Hive Metastore. The resulting data set is optimized for use with systems like Power BI and Azure HDInsight or machine learning vendors like Azure Databricks or Azure Synapse Analytics. Set up Segment Data Lakes (Azure) For detailed Segment Data Lakes (Azure) setup instructions, see the Data Lakes setup page . Set up Segment Data Lakes (AWS) When setting up your data lake using the Data Lakes catalog page , be sure to consider the EMR and AWS IAM components listed below. EMR Data Lakes uses an EMR cluster to run jobs that load events from all sources into Data Lakes. The AWS resources portion of the set up instructions sets up an EMR cluster using the m5.xlarge node type. Data Lakes keeps the cluster always running, however the cluster auto-scales to ensure it’s not always running at full capacity. Check the Terraform module documentation for the EMR specifications . AWS IAM role Data Lakes uses an IAM role to grant Segment secure access to your AWS account. The required inputs are: external_ids : External IDs are the part of the IAM role which Segment uses to assume the role providing access to your AWS account. You will define the external ID in the IAM role as the Segment Workspace ID in which you want to connect to Data Lakes. The Segment Workspace ID can be retrieved from the Segment app by navigating to Settings > General Settings > ID . s3_bucket : Name of the S3 bucket used by the Data Lake. Set up Segment Data Lakes (Azure) To connect Segment Data Lakes (Azure), you must set up the following components in your Azure environment: Azure Storage Account : An Azure storage account contains all of your Azure Storage data objects, including blobs, file shares, queues, tables, and disks. Azure KeyVault Instance : Azure KeyVault provides a secure store for your keys, secrets, and certificates. Azure MySQL Database : The MySQL database is a relational database service based on the MySQL Community Edition, versions 5.6, 5.7, and 8.0. Databricks Instance : Azure Databricks is a data analytics cluster that offers multiple environments (Databricks SQL, Databricks Data Science and Engineering, and Databricks Machine Learning) for you to develop data-intensive applications. Databricks Cluster : The Databricks cluster is a cluster of computation resources that you can use to run data science and analytics workloads. Service Principal : Service principals are identities used to access specific resources. For more information about configuring Segment Data Lakes (Azure), see the Data Lakes setup page . Data Lakes schema Segment Data Lakes applies a standard schema to make the raw data easier and faster to query. Partitions are applied to the S3 data for granular access to subsets of the data, schema components such as data types are inferred, and a map of the underlying data structure is stored in a Glue Database. Segment Data Lakes (AWS) schema S3 partition structure Segment partitions the data in S3 by the Segment source, event type, then the day and hour an event was received by Segment, to ensure that the data is actionable and accessible. The file path looks like: s3://<top-level-Segment-bucket>/data/<source-id>/segment_type=<event type>/day=<YYYY-MM-DD>/hr=<HH> Here are a few examples of what events look like: s3:YOUR_BUCKET/segment-data/data/SOURCE_ID/segment_type=identify/day=2020-05-11/hr=11/ s3:YOUR_BUCKET/segment-data/data/SOURCE_ID/segment_type=identify/day=2020-05-11/hr=12/ s3:YOUR_BUCKET/segment-data/data/SOURCE_ID/segment_type=identify/day=2020-05-11/hr=13/ s3:YOUR_BUCKET/segment-data/data/SOURCE_ID/segment_type=page_viewed/day=2020-05-11/hr=11/ s3:YOUR_BUCKET/segment-data/data/SOURCE_ID/segment_type=page_viewed/day=2020-05-11/hr=12/ s3:YOUR_BUCKET/segment-data/data/SOURCE_ID/segment_type=page_viewed/day=2020-05-11/hr=13/ By default, the date partition structure is day=<YYYY-MM-DD>/hr=<HH> to give you granular access to the S3 data. You can change the partition structure during the set up process , where you can choose from the following options: Day/Hour [YYYY-MM-DD/HH] (Default) Year/Month/Day/Hour [YYYY/MM/DD/HH] Year/Month/Day [YYYY/MM/DD] Day [YYYY-MM-DD] AWS Glue data catalog Data Lakes stores the inferred schema and associated metadata of the S3 data in AWS Glue Data Catalog. This metadata includes the location of the S3 file, data converted into Parquet format, column names inferred from the Segment event, nested properties and traits which are now flattened, and the inferred data type. New columns are appended to the end of the table in the Glue Data Catalog as they are detected. Glue database The schema inferred by Segment is stored in a Glue database within Glue Data Catalog. Segment stores the schema for each source in its own Glue database to organize the data so it is easier to query. To make it easier to find, Segment writes the schema to a Glue database named using the source slug by default. The database name can be modified from the Data Lakes settings. The recommended IAM role permissions grant Segment access to create the Glue databases on your behalf. If you do not grant Segment these permissions, you must manually create the Glue databases for Segment to write to. Segment Data Lakes (Azure) schema Segment Data Lakes (Azure) applies a consistent schema to make raw data accessible for queries. A transformer automatically calculates the desired schema and uploads a schema JSON file for each event type to your Azure Data Lake Storage (ADLS) in the /staging/ directory. Segment partitions the data in ALDS by the Segment source, event type, then the day and hour an event was received by Segment, to ensure that the data is actionable and accessible. The file path looks like this: <storage-account-name>/<container-name>/staging/<source-id>/ Data types Data Lakes infers the data type for an event it receives. Groups of events are polled every hour to infer the data type for that each event. The data types supported in Segment Data Lakes are: bigint boolean decimal(38,6) string timestamp Schema evolution Once Data Lakes sets a data type for a column, all subsequent data will attempt to be cast into that data type. If incoming data does not match the data type, Data Lakes tries to cast the column to the target data type. Size mismatch If the data type in Glue is wider than the data type for a column in an on-going sync (for example, a decimal vs integer, or string vs integer), then the column is cast to the wider type in the Glue table. If the column is narrower (for example, integer in the table versus decimal in the data), the data might be dropped if it cannot be cast at all, or in the case of numbers, some data might lose precision. The original data in Segment remains in its original format, so you can fix the types and replay to ensure no data is lost. Learn more about type casting by reading the W3School’s Java Type Casting page. Data mismatch If Data Lakes sees a bad data type, for example text in place of a number or an incorrectly formatted date, it attempts a best effort conversion to cast the field to the target data type. Fields that cannot be cast may be dropped. You can also correct the data type in the schema to the desired type and Replay to ensure no data is lost. Contact Segment Support if you find a data type needs to be corrected. Data Lake deduplication In addition to Segment’s 99% guarantee of no duplicates for data within a 24 hour look-back window, Data Lakes have another layer of deduplication to ensure clean data in your Data Lake. Segment removes duplicate events at the time your Data Lake ingests data.  Data Lakes deduplicate any data synced within the last seven days, based on the messageId field. Using a Data Lake with a Data Warehouse The Data Lakes and Warehouses products are compatible using a mapping, but do not maintain exact parity with each other. This mapping helps you to identify and manage the differences between the two storage solutions, so you can easily understand how the data in each is related. You can read more about the differences between Data Lakes and Warehouses . When you use Data Lakes, you can either use Data Lakes as your only source of data and query all of your data directly from S3 or ADLS or you can use Data Lakes in addition to a data warehouse. FAQ Can I send all of my Segment data into Data Lakes? Data Lakes supports data from all event sources, including website libraries, mobile, server and event cloud sources. Data Lakes doesn’t support loading object cloud source data , as well as the users and accounts tables from event cloud sources. Are user deletions and suppression supported? Segment doesn’t support User deletions in Data Lakes, but supports user suppression . How does Data Lakes handle schema evolution? As the data schema evolves, both Segment Data Lakes (AWS) and Segment Data Lakes (Azure) can detect new columns and add them to Glue Data Catalog or Azure Data Lake Storage (ADLS). However, Segment can’t update existing data types. To update Segment-created data types, please reach out to AWS Support or Azure Support . How does Data Lakes work with Protocols? Data Lakes has no direct integration with Protocols . Any changes to events at the source level made with Protocols also change the data for all downstream destinations, including Data Lakes. Mutated events - If Protocols mutates an event due to a rule set in the Tracking Plan, then that mutation appears in Segment’s internal archives and reflects in your data lake. For example, if you use Protocols to mutate the event product_id to be productID , then the event appears in both Data Lakes and Warehouses as productID . Blocked events - If a Protocols Tracking Plan blocks an event, the event isn’t forwarded to any downstream Segment destinations, including Data Lakes. However events which are only marked with a violation are passed to Data Lakes. Data types and labels available in Protocols aren’t supported by Data Lakes. Data Types - Data Lakes infers the data type for each event using its own schema inference systems instead of using a data type set for an event in Protocols. This might lead to the data type set in a data lake being different from the data type in the tracking plan. For example, if you set product_id to be an integer in the Protocols Tracking Plan, but the event is sent into Segment as a string, then Data Lakes may infer this data type as a string in the Glue Data Catalog. Labels - Labels set in Protocols aren’t sent to Data Lakes. How frequently does my Data Lake sync? Data Lakes offers 12 syncs in a 24 hour period and doesn’t offer a custom sync schedule or selective sync. What is the cost to use AWS Glue? You can find details on Amazon’s pricing for Glue page. For reference, Data Lakes creates 1 table per event type in your source, and adds 1 partition per hour to the event table. What is the cost to use Microsoft Azure? You can find details on Microsoft’s pricing for Azure page. For reference, Data Lakes creates 1 table per event type in your source, and adds 1 partition per hour to the event table. What limits does AWS Glue have? AWS Glue has limits across various factors, such as number of databases per account, tables per account, and so on. See the full list of Glue limits for more information. The most common limits to keep in mind are: Databases per account: 10,000 Tables per database: 200,000 Characters in a column name: 250 Segment stops creating new tables for the events after you exceed this limit. However you can contact your AWS account representative to increase these limits. You should also read the additional considerations in Amazon’s documentation when using AWS Glue Data Catalog. What analytics tools are available to use with Segment Data Lakes (Azure)? Segment Data Lakes (Azure) supports the following analytics tools: PowerBI Azure HDInsight Azure Synapse Analytics Databricks This page was last modified: 02 Aug 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page How Data Lakes work Set up Segment Data Lakes (Azure) Data Lakes schema FAQ Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Segment Data Lakes Overview"
      },
      {
        "level": 2,
        "text": "How Data Lakes work"
      },
      {
        "level": 3,
        "text": "How Segment Data Lakes (AWS) works"
      },
      {
        "level": 3,
        "text": "How Segment Data Lakes (Azure) works"
      },
      {
        "level": 2,
        "text": "Set up Segment Data Lakes (Azure)"
      },
      {
        "level": 3,
        "text": "Set up Segment Data Lakes (AWS)"
      },
      {
        "level": 3,
        "text": "Set up Segment Data Lakes (Azure)"
      },
      {
        "level": 2,
        "text": "Data Lakes schema"
      },
      {
        "level": 3,
        "text": "Segment Data Lakes (AWS) schema"
      },
      {
        "level": 3,
        "text": "Segment Data Lakes (Azure) schema"
      },
      {
        "level": 3,
        "text": "Data types"
      },
      {
        "level": 3,
        "text": "Schema evolution"
      },
      {
        "level": 3,
        "text": "Data Lake deduplication"
      },
      {
        "level": 3,
        "text": "Using a Data Lake with a Data Warehouse"
      },
      {
        "level": 2,
        "text": "FAQ"
      },
      {
        "level": 3,
        "text": "Are user deletions and suppression supported?"
      },
      {
        "level": 3,
        "text": "How does Data Lakes handle schema evolution?"
      },
      {
        "level": 3,
        "text": "How does Data Lakes work with Protocols?"
      },
      {
        "level": 3,
        "text": "How frequently does my Data Lake sync?"
      },
      {
        "level": 3,
        "text": "What is the cost to use AWS Glue?"
      },
      {
        "level": 3,
        "text": "What is the cost to use Microsoft Azure?"
      },
      {
        "level": 3,
        "text": "What limits does AWS Glue have?"
      },
      {
        "level": 3,
        "text": "What analytics tools are available to use with Segment Data Lakes (Azure)?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/warehouses/",
    "title": " Engage and Warehouses | Segment Documentation",
    "content": "Home / Engage / Engage and Warehouses Engage and Warehouses Free x Team x Business ✓ + Engage Foundations ✓ ? Engage Foundations requires a Business tier account and includes Unify. See the available plans , or contact Support . On this page Set up Identify calls for audiences Identify calls for computed traits Warehouse schema for Engage identify calls Warehouse schema for Engage track calls Users table Sync frequency Common questions Engage provides a complete, up-to-date view of your users customer journey as it unfolds, and one of the best ways to understand the data produced by this journey is by analyzing the data in your data warehouse using SQL. With Engage, you can send Computed Traits and Audiences to a data warehouse like Redshift, BigQuery, or Snowflake. This allows you to perform analysis and reporting around key customer audiences and campaigns, as well set up your user data as input into predictive models. Segment makes it easy to load your customer profile data into a clean schema, so your analysts can help answer some of your toughest business questions. Set up When you build an audience or computed trait, you can configure it to send an identify call or a track call to your data warehouse, and additionally include mobile ids. Identify calls for audiences If you chose to send your Engage data as an identify call, Engage usually sends one call per user. When you send audiences as an identify call, Engage includes a boolean trait that matches the audience name. When a user enters an audience the boolean is set to true , and when they exit, the boolean is set to false . In the example below, you can see that the identify payload includes a trait of the audience first_time_shopper with the value of true. { \" type \" : \" identify \" , \" userId \" : u123 , \" traits \" : { \" first_time_shopper \" : true // false when a user exits the audience } } Identify calls for computed traits When you send computed traits as an identify call, Engage sends a similar call with the computed value for that trait. In the example below, the trait total_revenue_180_days includes the calculated value of 450.00 . { \" type \" : \" identify \" , \" userId \" : u123 , \" traits \" : { \" total_revenue_180_days \" : 450.00 } } Warehouse schema for Engage identify calls Engage identify calls appear in your warehouse using a similar format as normal Connections identify calls. Identify calls appear in two tables per Engage space. These tables are named with a prefix of engage_ , then the Engage space name, followed by identifies or users . The identifies table contains a record of every identify call, and the users table contains one record per user_id with the most recent value. The engage_ schema name is specific to the Engage space and cannot be modified. Additional audiences and computed traits appear as additional columns in these tables. engage_default.identifies user_id first_time_shopper total_revenue_180_days u123 true u123 450.0 engage_default.users user_id first_time_shopper total_revenue_180_days u123 true 450.00 Track calls for audiences When you send audiences using track calls, Engage sends an Audience Entered event when a user enters, and an Audience Exited event when the user exits, by default. These event names are configurable. Engage also sends two event properties about the audience: the audience_key , which records the name of the audience that the event modifies, and the audience name and its value, as a separate key and value pair. The value of the audience key is populated with a boolean value. In the example below, you can see that the audience_key is set to record a modification to the first_time_shopper audience, and the first_time_shopper value is set to true . { \" type \" : \" track \" , \" userId \" : u123 , \" event \" : \" Audience Entered \" , \" traits \" : { \" audience_key \" : \" first_time_shopper \" , \" first_time_shopper \" : true } } Track calls for computed traits When you send computed traits , Engage sends a Trait Computed event that records which computed trait it updates, then records the updated key and value. You can also customize this event name. In the example below, the Trait Computed event contains the trait_key which records which computed trait is being modified, and then includes the key total_revenue_180_days with the updated value of 450.00 . { \" type \" : \" track \" , \" userId \" : u123 , \" event \" : \" Trait Computed \" , \" traits \" : { \" trait_key \" : \" total_revenue_180_days \" , \" total_revenue_180_days \" : 450.00 } } Warehouse schema for Engage track calls Similar to track calls in Connections, Engage track calls appear in your warehouse as one table per event name. For example, if you configure your events called Audience Entered , Audience Exited , and Trait Computed , Engage would create tables like the following examples in your warehouse: engage_default.audience_entered user_id audience_key first_time_shopper u123 first_time_shopper true engage_default.audience_exited user_id audience_key first_time_shopper u123 first_time_shopper false engage_default.trait_computed user_id total_revenue_180_days trait_key u123 450.00 total_revenue_180_days Users table The users table is an aggregate view based on the user_id field. This means that anonymous profiles with just an anonymous_id identifier aren’t included in this view. You can still view identify calls for anonymous audiences and computed traits in the identifies table. The users table is synced as soon as the warehouse is connected as a destination in Engage, if you’ve previously created Engage computations. As a result, the table might contain data from computations not directly connected to the warehouse. Sync frequency Although Engage can compute audiences and traits in real-time, these calculations are subject to the sync schedule allowed by your warehouses plan, which is usually hourly. You can check the warehouse sync history to see details about past and upcoming syncs. When you look at the sync schedule, sources with the engage_ prefix sync data from Engage. Common questions Can I prevent a table, a computed trait, or audience from syncing to my warehouse? Yes. You can use Warehouses Selective Sync to manage which traits, audiences, and tables get synced from Engage. Why are there multiple schemas prefixed with engage_ in my warehouse when I only have one space? Segment can only connect a source to one instance of each destination. For example, one source cannot send to two different Amplitude instances. As a workaround, Engage creates multiple sources to send events to the destinations connected to your space. For example, if you have three webhook destinations in your space, Engage creates three different sources to send events to them. This creates three different warehouse schemas, and is usually the reason you have more schemas than spaces. This approach doesn’t apply to messaging destinations, however. Messaging destinations connected from journeys and broadcasts don’t generate multiple background sources. This page was last modified: 30 Jan 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Set up Identify calls for audiences Identify calls for computed traits Warehouse schema for Engage identify calls Warehouse schema for Engage track calls Users table Sync frequency Common questions Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Engage and Warehouses"
      },
      {
        "level": 2,
        "text": "Set up"
      },
      {
        "level": 2,
        "text": "Identify calls for audiences"
      },
      {
        "level": 2,
        "text": "Identify calls for computed traits"
      },
      {
        "level": 2,
        "text": "Warehouse schema for Engage identify calls"
      },
      {
        "level": 3,
        "text": "Track calls for audiences"
      },
      {
        "level": 3,
        "text": "Track calls for computed traits"
      },
      {
        "level": 2,
        "text": "Warehouse schema for Engage track calls"
      },
      {
        "level": 2,
        "text": "Users table"
      },
      {
        "level": 2,
        "text": "Sync frequency"
      },
      {
        "level": 2,
        "text": "Common questions"
      },
      {
        "level": 3,
        "text": "Can I prevent a table, a computed trait, or audience from syncing to my warehouse?"
      },
      {
        "level": 3,
        "text": "Why are there multiple schemas prefixed withengage_in my warehouse when I only have one space?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/product-limits/",
    "title": " Engage Default Limits | Segment Documentation",
    "content": "Home / Engage / Engage Default Limits Engage Default Limits Free x Team x Business ✓ + Engage Foundations ✓ ? Engage Foundations requires a Business tier account and includes Unify. See the available plans , or contact Support . On this page Default limits Audiences and Computed Traits SQL Traits Journeys Channels To provide consistent performance and reliability at scale, Segment enforces default use and rate limits within Engage. Most customers do not exceed these limits. To learn more about custom limits and upgrades, contact your dedicated Customer Success Manager or friends@segment.com . Beginning August 18, 2023, Segment has updated product limits that apply to new Engage and Unify users. Default limits Name limit Details Inbound Data Throughput 1000 events per second Total event stream from sources connected to Engage, including historical data replays. Segment may slow request processing once this limit is reached. Outbound Downstream Destination Rate Limits Reduced retries when failures exceed 1000 events per second Outbound Destination requests may fail for reasons outside of Segment’s control.  For example, most Destinations enforce their own rate limits. As a result, Segment may deliver data faster than the Destination can accept. When Destination requests fail, Segment tries to deliver the data again. However, if more than 1000 requests per second fail or if the failure rate exceeds 50% for over 72 hours, Segment may reduce additional delivery attempts until the failure condition resolves. Audiences and Computed Traits name limit Details Compute Concurrency 5 new concurrent audiences or computed traits Segment computes five new audiences or computed traits at a time. Once the limit is reached, Segment queues additional computations until one of the five finishes computing. Edit Concurrency 2 concurrent audiences or computed traits You can edit two concurrent audiences or computed traits at a time. Once the limit is reached, Segment queues and locks additional computations until one of the two finishes computing. Batch Compute Concurrency Limit 10 (default) per space The number of batch computations that can run concurrently per space. When this limit is reached, Segment delays subsequent computations until current computations finish. Compute Throughput 10000 computations per second Computations include any Track or Identify call that triggers an audience or computed trait re-computation. Once the limit is reached, Segment may slow audience processing. Events Lookback History 3 years The period of time for which Segment stores audience and computed traits computation events. Real-time to batch destination sync frequency 12-15 hours The frequency with which Segment syncs real-time audiences to batch destinations. Event History 1970-01-01 Events with a timestamp less than 1970-01-01 aren’t always ingested, which could impact audience backfills with event timestamps prior to this date. Engage Data Ingest 1x the data ingested into Connections The amount of data transferred into the Compute Engine. Audience Frequency Update 1 per 8 hours Audiences that require time windows (batch audiences), funnels , dynamic properties , or account-level membership are processed on chronological schedules. The default schedule is once every eight hours; however, this can be delayed if the “Batch Compute Concurrency Limit” is reached. Unless otherwise agreed upon, the audiences will compute at the limit set forth. Event Properties (Computed Traits) 10,000 For Computed Traits that exceed this limit, Segment will not persist any new Event Properties and will drop new trait keys and corresponding values. SQL Traits name limit Details SQL Traits 25 The number of SQL traits you can sync to your Space. SQL Traits - Sync Frequency customizable, up to hourly The frequency with which Segment runs your SQL traits. Contact your account team to customize your schedule. SQL Traits - Rows 25 million The number of rows each SQL trait can return. SQL Traits - Columns 25 The number of columns each SQL trait can return. Journeys Item Limit description Details Steps 100 The maximum number of steps per Journey. Step Name Maximum length of 170 characters Once the limit is reached, you cannot add additional characters to the name. Key Maximum length of 255 characters Once the limit is reached, you cannot add additional characters to the key. Journey Name Maximum length of 73 characters Once the limit is reached, you cannot add additional characters to the name. Compute credits Half a credit for each step (up to 250 compute credits) Each step in a published Journey consumes half of one compute credit. Channels Item Limit description Details Channels Does not support Regional Segment Workspaces with Channels functionality enabled must be deployed in the default region (Oregon, US). This page was last modified: 31 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Default limits Audiences and Computed Traits SQL Traits Journeys Channels Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Engage Default Limits"
      },
      {
        "level": 2,
        "text": "Default limits"
      },
      {
        "level": 2,
        "text": "Audiences and Computed Traits"
      },
      {
        "level": 2,
        "text": "SQL Traits"
      },
      {
        "level": 2,
        "text": "Journeys"
      },
      {
        "level": 2,
        "text": "Channels"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/",
    "title": " Unify Overview | Segment Documentation",
    "content": "Home / Unify Overview Unify Overview Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Getting started Identity Resolution Profile explorer Enrich profiles with traits Profile API Profiles Insights Profiles Sync Next steps: activate your profiles with Engage Use Segment Unify, formerly known as Profiles, for a complete view of your customers. With Identity Resolution , track every interaction across the entire user journey to create unified, real-time customer identities. View user profiles in one place through the Profile explorer in the Segment app. Use the Profile API to programmatically query user profiles, traits, and events. You can then use this interaction data with customer engagement tools, such as Engage, to deliver personalized, omnichannel experiences. If you need to troubleshoot or learn about your profile data, use Profiles Insights for a transparent view of your Unify profiles. Getting started Unify is an add-on to Segment Connections Business Tier. It’s also a required add-on for Twilio Engage.\nTo use Computed Traits and Audiences with Unify, you must have access to Engage. To set up and get data flowing through Unify, visit Segment’s Onboarding Guide . Identity Resolution Set Identity Resolution rules to take event data from across devices and channels and intelligently merge it into complete user- or account-level profiles. This enables you to understand customer behavior as it evolves in real-time across multiple touchpoints. With Identity Resolution: Understand behaviors that lead a user from an anonymous window shopper to a loyal customer. Track customer activity across multiple devices and apps. Learn how a user interacts with your brand through different channels and departments. Visit Segment’s Identity Resolution docs to learn more. Profile explorer Use the Profile explorer to view all user data, including their event history, traits, and identifiers. With the Profile explorer, you have a complete view of your customers. Visualize unified profiles : Explore profiles from a single location in Segment to understand who’s using your product. Ensure quality data : Be sure that the data you receive is the data you expect. Provide sales and support context : Look up a user profile to understand where they are on their journey with your business or product. If you’re using Engage, use the Profile explorer to view audiences, traits, journey membership, and subscription states for email and phone numbers. Enrich profiles with traits With Unify Plus, you can add detail to user profiles with new traits and use them to power personalized marketing campaigns. Add new traits to your user or account profiles using: Computed Traits: Use the Unify drag-and-drop interface to build per-user (B2C) or per-account (B2B) metrics on user profiles (for example, “lifetime value” or “lead score”). SQL Traits: Run custom queries on your data warehouse using the Unify SQL editor, and import the results into Segment. With SQL Traits, you can pull rich, uncaptured user data back into Segment. Predictions : Predict the likelihood that users will perform custom events tracked in Segment, like LTV, churn, and purchase. Profile API Use Segment’s Profile API to programmatically access all traits stored for a user. This includes the external_ids , traits , and events that make up a customer’s journey with your product. Use the Profile API to help your organization: Build in-app recommendations. Empower your sales and support teams with complete customer context. Create personalized marketing campaigns. Qualify leads faster. Visit Segment’s Profile API doc for more information. Profiles Insights Use Profiles Insights to troubleshoot your event data with a transparent view of your Unify profiles. Learn about your events and identifiers on your profiles and answer questions such as why two profiles didn’t merge, why an event wasn’t resolved to a profile, or why an external ID isn’t present. Visit the Profiles Insights doc to learn more. Profiles Sync Use Profiles Sync to connect identity-resolved customer profiles to a data warehouse of your choice. With a continual flow of synced profiles, teams can enrich and use these data sets as the basis for new audiences and models. Profiles Sync addresses a number of use cases, with applications for identity graph monitoring, attribution analysis, machine learning, and more. Visit the Profiles Sync Setup doc to learn more. Next steps: activate your profiles with Engage For Engage users, after you set up your identity rules and have data flowing through Unify, you can activate profiles to deliver personalized engagement experiences. Visit the Engage docs to learn more. This page was last modified: 26 Jun 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Getting started Identity Resolution Profile explorer Enrich profiles with traits Profile API Profiles Insights Profiles Sync Next steps: activate your profiles with Engage Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Unify Overview"
      },
      {
        "level": 2,
        "text": "Getting started"
      },
      {
        "level": 2,
        "text": "Identity Resolution"
      },
      {
        "level": 2,
        "text": "Profile explorer"
      },
      {
        "level": 2,
        "text": "Enrich profiles with traits"
      },
      {
        "level": 2,
        "text": "Profile API"
      },
      {
        "level": 2,
        "text": "Profiles Insights"
      },
      {
        "level": 2,
        "text": "Profiles Sync"
      },
      {
        "level": 2,
        "text": "Next steps: activate your profiles with Engage"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/integration_error_codes/",
    "title": " Integration Error Codes | Segment Documentation",
    "content": "Home / Connections / Integration Error Codes Integration Error Codes Error Codes Reason errors.discarded.400 Bad request - Refer to the error message to see which fields in your events might be invalid errors.discarded.401 Unauthorized - Your credentials are either invalid or have expired. Re-authenticate your account with the partner and update your authentication settings in Segment. errors.discarded.403 Forbidden - You no longer have sufficient privilege to access the partner’s API. Re-authenticate your account with the partner and update your auth settings in Segment. errors.discarded.INVALID_SETTINGS Your configurations in Segment are invalid. Refer to the error message for more details. errors.discarded.MESSAGE_REJECTED Your events are missing one or more required fields. Refer to the error message for more details. errors.awaiting-retry.429 Rate limit exceeded. contact the partner to raise your limit or avoid sending events in burst. errors.awaiting-retry.5xx The partner’s API report an internal error. Consider disabling this integration or contact the integration partner to address this issue. errors.awaiting-retry.ENOTFOUND errors.awaiting-retry.ECONNREFUSED errors.awaiting-retry.ECONNRESET errors.awaiting-retry.ECONNABORTED errors.awaiting-retry.EHOSTUNREACH errors.awaiting-retry.EAI_AGAIN Segment is unable to establish a connection with the partner’s server. This could mean your Segment configurations contain some invalid settings or that the integration is no longer operational.  If your configurations are valid, consider disabling this integration or contact the integration partner to address this issue. Others Refer to the error message you receive for more information. See the article, Testing Connections for more debugging help. This page was last modified: 06 Jul 2022 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Integration Error Codes"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/content/organization/",
    "title": " Organizing Your Templates | Segment Documentation",
    "content": "Home / Engage / Content / Organizing Your Templates Organizing Your Templates Free x Team x Business ✓ + Engage Premier ✓ ? Engage Premier requires a Business tier account and includes Engage Foundations and Unify. See the available plans , or contact Support . On this page Organize with folders Duplicate an Engage template Engage Premier entered an End of Sale (EOS) period effective  June 10, 2024. Existing Segment customers will continue to have access and support to Engage Premier until an end-of-life (EOL) date is announced. We recommend exploring the following pages in preparation of a migration or future MCM needs: Twilio Marketing Campaigns Preferred ISV Partners: Airship Blog Bloomreach Blog Braze Blog Insider Blog Klaviyo Blog Twilio Engage Foundations Documentation To add structure to your marketing content, you can organize templates into folders and duplicate them within your Segment space. Organize with folders Use folders to organize your Email, SMS/MMS, Push, and WhatsApp content templates. Group related content together to better help you manage and find your marketing resources. From the Templates overview page you can create, update, view, and delete template folders. You must have both read and write workspace permissions to create or make changes to folders. To create a folder: Navigate to Engage > Content . Select the tab for the template type (Email, SMS, WhatsApp, or Push) you’d like to create the folder for. Click Create , then select Folder . Add a folder name, then click Create . You can also rename, add templates, or disband your folder from the Templates overview page. Disbanding a folder returns all templates from the folder to the main template list, without deleting any of the templates. You can only organize templates in your folders according to template type. For example, you can’t group email and SMS templates in the same folder. Move templates to your folders From the Templates overview page, you can select individual template(s) to move to your folders. After you select the templates you’d like to move: Click Actions , and select Move Templates . Select the destination folder, then click Move templates to folder . Use the Actions button in your folder to remove templates or move them to a different location. When you remove a template, Engage returns the template to the Templates overview page, without deleting it. Duplicate an Engage template You can clone existing Engage templates to edit and use in your message campaigns. Duplicate email, SMS, and push templates To duplicate an email, SMS, or push template: Navigate to Engage > Content . Select the tab for the template type (Email, SMS, or Push) you’d like to clone. Select the … icon next to your template, then click Duplicate . Configure your duplicate template: For SMS and push, edit your template, and save the duplicate once you’re finished. For email, add a template name on the Duplicate Template popup screen, then click Duplicate . You can then edit your email template from the Templates page. Learn more about configuring email , SMS , and push templates. Duplicate WhatsApp templates To duplicate WhatsApp templates: Navigate to Engage > Content > WhatsApp . Select the template you want to duplicate. Click Duplicate . Add a template name and language, then click Duplicate . Configure and save your WhatsApp template. Learn more about configuring WhatsApp templates . This page was last modified: 15 Jul 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Organize with folders Duplicate an Engage template Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Organizing Your Templates"
      },
      {
        "level": 2,
        "text": "Organize with folders"
      },
      {
        "level": 3,
        "text": "Move templates to your folders"
      },
      {
        "level": 2,
        "text": "Duplicate an Engage template"
      },
      {
        "level": 3,
        "text": "Duplicate email, SMS, and push templates"
      },
      {
        "level": 3,
        "text": "Duplicate WhatsApp templates"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/usage-and-billing/billing/",
    "title": " Billing and Account FAQs | Segment Documentation",
    "content": "Home / Guides / Usage and billing / Billing and Account FAQs Billing and Account FAQs On this page What is a billing cycle? How do I change my plan? Will Segment charge sales tax on my invoice? Do I qualify for a tax exemption? Do you offer refunds? Is there a free trial for paid plans? What happens when I exceed the Free plan limit? Team Trial FAQ What is a billing cycle? On the Segment monthly Team plan, your billing cycle starts the day after your 14-day trial ends. You’re billed on this day for each month while you’re on this plan. On the Segment annual Team plan, you’re billed at the end of your 14-day trial for the amount of an entire year of service including a specific number of MTUs . Annual plan subscribers are billed for MTU overages at the end of each monthly cycle. How do I change my plan? If you already have a Segment workspace, you can change which plan your workspace is on by navigating to Settings > Usage & Billing > Plans . If you cancel or downgrade your plan during the 2-week trial period, you don’t incur any charges. What if I cancel my paid plan before the end of the month? Cancellation on the monthly Team plan If you cancel your plan or downgrade to a free account before the end of your official billing period on the monthly Team plan, you’ll receive a final bill for the prorated amount for the $120 base + a charge for any MTUs you’ve used over the allotted 10,000 at the rates posted on the pricing page . Cancellation on the annual Team plan Segment doesn’t issue refunds for the pre-paid portion of your annual bill after your trial ends. Be aware that if you notify Segment of wanting to cancel your annual plan, but continue to send data to Segment’s servers, you may incur overage charges in any given month. You should fully delete your workspace or cycle your write keys to stop all data flow into Segment to avoid future charges. Will Segment charge sales tax on my invoice? All Segment customers with a US business address may be subject to state and local sales taxes. The applicable tax law applies based on your business location address, which may be different from your billing address. Customers who purchase a taxable product or service, and are located in a jurisdiction where Segment currently charges sales tax, will see the calculated sales tax on their invoice. Segment collects Value Added Tax (VAT) and Goods and Services Tax (GST) on the services sold to its international customers located in certain foreign jurisdictions. For more information about sales tax, VAT, and GST, see the Segment VAT/GST FAQs . Do I qualify for a tax exemption? If you believe your organization qualifies for a sales tax exemption (for example, because of a nonprofit or government status), you can contact tax@segment.com with the appropriate form. I submitted a form for tax exemption, why am I still charged sales tax? Tax might still be charged on your bill if either: The exemption certificate was still in review while the invoice was issued; or The exemption certificate covers a state that is different from the billing address Do you offer refunds? In most cases Segment doesn’t offer refunds, as noted in the Terms of Service . Contact support if you feel that you’re in a unique situation. Is there a free trial for paid plans? Segment offers a 2-week trial on the Team plan to let you try the plan before you purchase it. Segment also offers the Free plan, which includes up to 1,000 MTUs, at no cost to you. Find out more about the different plans and which one suits your needs best. What happens when I exceed the Free plan limit? The Free plan includes up to 1,000 MTUs at no cost. If you exceed the 1,000 MTU limit once in a 6-month period, Segment locks your account but data is still able to flow through Segment. To unlock your account, you can choose from these options: Option 1 : Wait for a full billing cycle (1 month) to go by with any overages. This will automatically unlock your account if the MTU numbers are able to go back down on their own. Option 2 : Upgrade to the Team plan . This starts a 2-week free trial that gives you 14 days to fix your implementation to decrease the traffic. If you exceed the 1,000 MTU limit twice in a 6-month period, Segment locks your account and also stops sending and receiving data. You can unlock your account by following option 2 above to upgrade to the Team plan 2-week free trial. Team Trial FAQ What is the Team trial? The Team trial is a 14-day free trial of Segment’s Team plan , and it includes all the features associated with a Team plan, including unlimited sources, two warehouse syncs per day, 10 seats, and 10,000 MTUs (with the ability to track more MTUs as needed). How do I get a two-week Team trial? You automatically receive a 2-week trial when you sign up for a Team plan. Do I have to be a “new” customer to receive the free Team trial? The free trial is available to all customers who have never had a Team plan. This includes new customers as well as customers who have previously been on the Free plan. Do you have to include your payment information when signing up for a Team trial? If you’re upgrading from a Free Plan to a Team Plan, you’re required to add your payment information. If you’re signing up for a new Team plan, you don’t have to add your payment information during sign up. If you would like to continue to use the Team plan after the 14-day trial, add your credit card information on the “Payment Information” page in your workspace before the trial ends. What happens when the two-week trial ends? If you added your payment information, your subscription automatically continues at the regular rate after the trial period expires. You can delete your workspace or downgrade to a Free plan any time during the trial to avoid charges. To activate the free trial, add your payment information. This page was last modified: 24 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page What is a billing cycle? How do I change my plan? Will Segment charge sales tax on my invoice? Do I qualify for a tax exemption? Do you offer refunds? Is there a free trial for paid plans? What happens when I exceed the Free plan limit? Team Trial FAQ Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Billing and Account FAQs"
      },
      {
        "level": 2,
        "text": "What is a billing cycle?"
      },
      {
        "level": 2,
        "text": "How do I change my plan?"
      },
      {
        "level": 3,
        "text": "What if I cancel my paid plan before the end of the month?"
      },
      {
        "level": 2,
        "text": "Will Segment charge sales tax on my invoice?"
      },
      {
        "level": 2,
        "text": "Do I qualify for a tax exemption?"
      },
      {
        "level": 3,
        "text": "I submitted a form for tax exemption, why am I still charged sales tax?"
      },
      {
        "level": 2,
        "text": "Do you offer refunds?"
      },
      {
        "level": 2,
        "text": "Is there a free trial for paid plans?"
      },
      {
        "level": 2,
        "text": "What happens when I exceed the Free plan limit?"
      },
      {
        "level": 2,
        "text": "Team Trial FAQ"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/#segment-documentation",
    "title": " Segment Documentation | Segment Documentation",
    "content": "Segment Documentation Learn how to use Segment to collect, responsibly manage, and integrate your customer data with hundreds of tools. Getting started with Segment Learn about Segment, plan and work through a basic implementation, and explore features and extensions. How can Segment help you? Simplify data collection Integrate the tools you need for analytics, growth, marketing, and more. Protect data integrity Prevent data quality issues with a tracking schema and enforcement with Protocols. Personalize experiences Build audiences and journeys from real-time customer data to personalize experiences on every channel. Respect users' privacy Keep customer data private with Segment's data discovery and policy enforcement tools. Get Data into Segment The Segment Spec helps you identify, capture, and format meaningful data for use with Segment libraries and APIs as well as downstream tools. Segment calls Use Track, Page, Identify, and other Segment tracking calls. Common traits Save time by letting Segment calls collect information for you. Use case specs Use our business-case specs to ensure that your tools get the most from your data. Learning about Segment Segment for Developers The basics of your Segment implementation. How-To Guides Over a dozen how-to guides that help you accomplish common tasks. Connect your app to Segment JavaScript Swift All other Sources Additional Resources Totally new to Analytics? Segment's Analytics Academy walks you through the wide world of analytics, including best practices, an overview of the most popular tools, and case studies of how other developers have achieved success. Want more hands-on guidance? For a more hands-on tutorial of Segment, check out Segment University. It offers step-by-step instructions, starting with first steps and going through some of our more advanced features. Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account",
    "headings": [
      {
        "level": 1,
        "text": "Segment Documentation"
      },
      {
        "level": 2,
        "text": "How can Segment help you?"
      },
      {
        "level": 2,
        "text": "Get Data into Segment"
      },
      {
        "level": 2,
        "text": "Learning about Segment"
      },
      {
        "level": 2,
        "text": "Connect your app to Segment"
      },
      {
        "level": 2,
        "text": "Additional Resources"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/profiles-sync/profiles-sync-setup/",
    "title": " Set up Profiles Sync | Segment Documentation",
    "content": "Home / Unify / Profiles sync / Set up Profiles Sync Set up Profiles Sync Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Initially Setting up Profiles Sync Profiles Sync limits Working with synced warehouses On this page, you’ll learn how to set up Profiles Sync, enable historical backfill, and adjust settings for warehouses that you’ve connected to Profiles Sync. Initially Setting up Profiles Sync Identity Resolution setup To use Profiles Sync, you must first set up Identity Resolution . To set up Profiles Sync, first create a warehouse, then connect the warehouse within the Segment app. Before you begin, prepare for setup with these tips: To connect your warehouse to Segment, you must have read and write permissions with the warehouse Destination you choose. During step 2, you’ll copy credentials between Segment and your warehouse destination. To streamline setup, open your Segment workspace in one browser tab and open another with your warehouse account. Make sure to copy any IP addresses Segment asks you to allowlist in your warehouse destination. Step 1: Select a warehouse You’ll first choose the destination warehouse to which Segment will sync profiles. Profiles Sync supports the Snowflake, Redshift, BigQuery, Azure, Postgres, and Databricks warehouse Destinations. Your initial setup will depend on the warehouse you choose. The following table shows the supported Profiles Sync warehouse destinations and the corresponding required steps for each. Select a warehouse, view its Segment documentation, then carry out the warehouse’s required steps before moving to step 2 of Profiles Sync setup: Warehouse Destination Required steps Snowflake Follow the steps in Snowflake Getting Started . Redshift Follow the steps in Redshift Getting Started . BigQuery Follow the steps in BigQuery Getting Started . Azure Follow the steps in Azure Synapse Analytics Getting Started . Postgres Follow the steps in Postgres Getting Started . Databricks Follow the steps in the Databricks Getting Started . After you’ve finished the required steps for your chosen warehouse, you’re ready to connect your warehouse to Segment. Because you’ll next enter credentials from the warehouse you just created, leave the warehouse tab open to streamline setup. Profiles Sync permissions To allow Segment to write to the warehouse you’re using for Profiles Sync, you’ll need to set up specific permissions. For example, if you’re using BigQuery, you must create a service account for Segment and assign the following roles: BigQuery Data Owner BigQuery Job User Review the required steps for each warehouse in the table above to see which permissions you’ll need. Profiles Sync roles The following Segment access roles apply to Profiles Sync: Unify and Engage read-only : Read-only access to Profiles Sync, including the sync history and configuration settings. With these roles assigned, you can’t download PII or edit Profiles Sync settings. Unify read-only and Engage user : Read-only access to Profiles Sync, including the sync history and configuration settings. With these roles assigned, you can’t download PII or edit Profiles Sync settings. Unify and Engage Admin access : Full edit access to Profiles Sync, including the sync history and configuration settings. Step 2: Connect the warehouse and enable Profiles Sync After selecting your warehouse, you can connect it to Segment. During this step, you’ll copy credentials from the warehouse you just set up and enter them into the Segment app. The specific credentials you’ll enter depend on the warehouse you chose during step 1. Segment may also display IP addresses you’ll need to allowlist in your warehouse. Make sure to copy the IP addresses and enter them into your warehouse account. To connect your warehouse: Configure your database. Be sure to log in with a user who has read and write permissions so that Segment can write to your database. Segment shows an IP address to allowlist.  Copy it to your warehouse destination. Enter a schema name to help you identify this space in the warehouse, or use the default name provided. The schema name can’t be changed after the warehouse is connected. Enter your warehouse credentials, then select Test Connection . If the connection test succeeds, Segment enables the Next button. Select it. If the connection test fails, verify that you’ve correctly entered the warehouse credentials, then try again. Step 3: Set up Selective Sync Set up Selective Sync to control the exact tables and columns that Segment will sync to your connected data warehouse. Data will be backfilled to your warehouse based on the last two months of history. You can sync the following tables: Type Tables Backfill Profile raw tables - external_id_mapping_updates - id_graph_updates - profile_traits_updates Complete Profile materialized tables - user_identifier - user_traits - profile_merges Complete Event type tables - Identify - Page - Group - Screen - Alias - Track 2 months Track event tables To view and select individual track tables, don’t sync track tables during the initial setup. Edit your sync settings after enabling Profiles Sync and waiting for the first sync to complete. 2 months Using Selective Sync Use Selective Sync to manage the data you send to your warehouses by choosing which tables and columns (also known as properties) to sync. Syncing fewer tables and properties will lead to faster and more frequent syncs, faster queries, and using less disk space. You can access Selective Sync in two ways: From the Set Selective Sync page as you connect your warehouse to Profiles Sync. From the Profiles Sync settings ( Profiles Sync > Settings > Selective sync ). You’ll see a list of event type tables, event tables, and tables Segment materializes available to sync. Select the tables and properties that you’d like to sync, and be sure the ones you’d like to prevent from syncing aren’t selected. Regardless of schema size, only the first 5,000 collections and 5,000 properties per collection can be managed using your Segment space. To edit Selective Sync settings for any collection which exceeds this limit, contact Segment support . You must be a workspace owner to change Selective Sync settings. When to use Selective Sync Use Selective Sync when you want to prevent specific tables and properties from syncing to your warehouse. Segment stops syncing from disabled tables or properties, but will not delete any historical data from your warehouse. If you choose to re-enable a table or property to sync again, only new data generated will sync to your warehouse. Segment doesn’t backfill data that was omitted with Selective Sync. Using historical backfill Profiles Sync sends profiles to your warehouse hourly once setup completes. Setup is complete after an initial automated backfill syncs all profile data. To initiate the backfill, the Profiles Sync requires live data flowing into your workspace. If live data isn’t available, you can send test data to trigger the backfill sooner. Backfill can also sync historical profiles to your warehouse. You can only use historical backfill for tables that you enable with Selective Sync during setup. Segment does not backfill tables that you disable with Selective Sync. When Segment runs historical backfills: Profile raw and materialized tables sync your entire historical data to your warehouse. Profiles Sync gathers the last two months of all events for Event type and Track event tables and syncs them to your warehouse. Segment lands the data on an internal staging location, then removes the backfill banner. Segment then syncs the backfill data to your warehouse. Reach out to Segment support if your use case exceeds the scope of the initial setup backfill. While historical backfill is running, you can start building materialized views and running sample queries . Step 4 (Optional): Materialize key views using a SQL automation tool During setup, you have the option of setting up materialized key views in one of two ways: You can choose to materialize views on your own by using profiles raw tables . \nYou may want to materialize your own tables if, for example, you want to transform additional data or join Segment profile data with external data before materialization. You can choose to use Segment’s open source dbt models by using profiles materialized tables. You can alternatively use tables that Segment materializes and syncs to your data warehouse. To start seeing unified profiles in your warehouse and build attribution models, you’ll need to materialize the tables that Profiles Sync lands into three key views: id_graph : the current state of relationships between segment ids external_id_mapping : the current-state mapping between each external identifier you’ve observed and its corresponding, fully-merged canonical_segment_id profile_traits : the last seen value for all custom traits, computed traits, SQL traits, audiences, and journeys associated with a profile in a single row See Tables you materialize for more on how to materialize these views either on your own, or with Segment’s open source dbt models . Note that dbt models are in beta and need modifications to run efficiently on BigQuery, Synapse, and Postgres warehouses. Segment is actively working on this feature. Profiles Sync limits As you use Profiles Sync, keep the following limits in mind: For event tables, Segment can only backfill up to 2,000 tables for each workspace. Segment can only initiate backfills after a successful sync with > 0 rows. For every sync, the total dataset Segment can sync is limited to 20TB. Working with synced warehouses Monitor Profiles Sync You can view warehouse sync information in the overview section of the Profiles Sync page. Segment displays the dates and times of the last and next syncs, as well as your sync frequency. In the Syncs table, you’ll find reports on individual syncs. Segment lists your most recent syncs first. The following table shows the information Segment tracks for each sync: DATA TYPE DEFINITION Sync status - Success , which indicates that all rows synced correctly - Partial success , indicating that some rows synced correctly - Failed , indicating that no rows synced correctly Duration Length of sync time, in minutes Start time The date and time when the sync began Synced rows The number of rows synced to the warehouse Selecting a row from the Syncs table opens a pane that contains granular sync information. In this view, you’ll see the sync’s status, duration, and start time. Segment also displays a nuanced breakdown of the total rows synced, sorting them into identity graph tables, event type tables, and event tables. If the sync failed, Segment shows any available error messages in the sync report. Settings and maintenance The Settings tab of the Profiles Sync page contains tools that can help you monitor and maintain your synced warehouse. Disable or delete a warehouse In the Basic settings tab, you can disable warehouse syncs or delete your connected warehouse altogether. To disable syncs, toggle Sync status to off. Segment retains your warehouse credentials but stops further syncs. Toggle Sync status back on at any point to continue syncs. To delete your warehouse, toggle Sync status to off, then select Delete warehouse . Segment doesn’t retain credentials for deleted warehouses; to reconnect a deleted warehouse, you must set it up as a new warehouse. Connection settings In the Connection settings tab, you can verify your synced warehouse’s credentials and view IP addresses you’ll need to allowlist so that Segment can successfully sync profiles. If you have write access, you can verify that your warehouse is successfully connected to Segment by entering your password and then selecting Test Connection . Changing your synced warehouse If you’d like to change the warehouse connected to Profiles Sync, reach out to Segment support . Sync schedule Segment supports hourly syncs. This page was last modified: 07 Nov 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Initially Setting up Profiles Sync Profiles Sync limits Working with synced warehouses Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Set up Profiles Sync"
      },
      {
        "level": 2,
        "text": "Initially Setting up Profiles Sync"
      },
      {
        "level": 3,
        "text": "Step 1: Select a warehouse"
      },
      {
        "level": 3,
        "text": "Step 2: Connect the warehouse and enable Profiles Sync"
      },
      {
        "level": 3,
        "text": "Step 3: Set up Selective Sync"
      },
      {
        "level": 3,
        "text": "Step 4 (Optional): Materialize key views using a SQL automation tool"
      },
      {
        "level": 2,
        "text": "Profiles Sync limits"
      },
      {
        "level": 2,
        "text": "Working with synced warehouses"
      },
      {
        "level": 3,
        "text": "Monitor Profiles Sync"
      },
      {
        "level": 3,
        "text": "Settings and maintenance"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/protocols/tracking-plan/best-practices/",
    "title": " Data Collection Best Practices | Segment Documentation",
    "content": "Home / Protocols / Tracking plan / Data Collection Best Practices Data Collection Best Practices On this page Data tracking philosophy Define business objectives Formalize your naming and collection standards Create a tracking plan Identify your users Define your Track events Define your Track event properties Figuring out what events to track in Segment can feel overwhelming. Fortunately, Segment has helped thousands of customers through this process and has amassed a ton of resources to help you get started. Whether you’re a small team just getting your app off the ground or a highly complex enterprise with hundreds of stakeholders, these resources can help. That being said, be prepared to invest time defining how you want to track data. Any investment in improving data quality will reap massive rewards, and compound over time by allowing your analytics teams to produce better insights, your marketing teams to run better campaigns and so much more. Data tracking philosophy Tracking is about learning and taking action. Think about what you want to know about your product or customers. Think about what assumptions need to be tested or invalidated. Think about the unknowns. Here are some helpful questions to get started: What kind of events or data will shed light on how your customers use your product? How do people discover, pay for, and start using your product? What are the most important steps in a customer’s journey? Define business objectives Segment recommends documenting your high-level business objectives. What measurable business outcomes do you want to achieve? Do you want to acquire new customers, activate new signups, drive incremental revenues among your current customer base? You can best answer this question by interviewing stakeholders who would consume the data in your organization. With your business goals documented, you now need to map user actions to those business goals. For example, if one of your goals is to activate new signups, you want to think about which activities are related to a signup. Ask yourself what actions people take before signing up. Do specific actions predict user signups? As an example, you may end up with a list like the following: Ad Campaign Clicked Link Clicked Article Completed Campaign Opened Form Initiated Form Submitted User Signed Up While these may only represent a portion of the total user actions you will track, focusing on business objectives helps make data collection more manageable. Formalize your naming and collection standards With your business objectives documented, it’s time to build a set of standards that you and your team will use when determining what to track. Segment’s most successful customers limit their tracking plan to a minimal number of core events with rich properties that provide context. While some customers find success with the “less is more” philosophy of tracking data, others take a more liberal “track more and analyze later” approach. Both options have pros and cons you should take into account when you consider your company’s needs. Regardless of your approach, keep the following tips in mind: Pick a casing convention. Segment recommends Title Case for event names and snake_case for property names. Make sure you pick a casing standard and enforce it across your events and properties. Pick an event name structure. As you may have noticed from the Segment specs , Segment uses the Object ( Blog Post ) + Action ( Read ) framework for event names. Pick a convention and stick to it. Don’t create event names dynamically. Avoid creating events that pull a dynamic value into the event name (like User Signed Up (11-01-2019) ). Don’t create events to track properties. Avoid adding values to event names that could be a property. Instead, add values a property (like \"blog_post_title\":\"Best Tracking Plans Ever\" ). Don’t create property keys dynamically. Avoid creating property names like \"feature_1\":\"true\" , \"feature_2\":\"false\" , as these are ambiguous and difficult to analyze. Create a tracking plan A tracking plan clarifies what events to track, where those events live in the code base, and why those events are necessary from a business perspective. Prior to Protocols, tracking plans typically lived in a spreadsheet. The tracking plan served as a project management tool to align an entire organization around data as the basis on which to make decisions. The tracking plan helps marketers, product managers, engineers, and analysts get on the same page. The tracking plan has been so instrumental in helping organizations reclaim their own data efforts that Segment invested years of product development to create Protocols . Whatever tool you choose to build your tracking plan, make sure that it represents a single source of truth for your data collection efforts. Identify your users The Identify call is important because it updates all records of the user with a set of traits. But how do you choose which traits to include? Here is a sample Identify call (with analytics.js ) for Segment: analytics . identify ({ name : ' Jane Doe ' , email : ' janedoe@iamawesome.com ' , login : ' janedoe ' , type : ' user ' , created : ' 2016-11-07T16:40:52.238Z ' , }); The traits represent dimensions in your data that you can group or pivot on. For example, in the previous sample call, you can easily create cohorts of all types that are users or accounts created within a time window of your choosing. Define your Track events After you’ve documented your event naming and collection standards , it’s time to add events to your tracking plan. Segment recommends starting with fewer events that are directly tied to one of your business objectives . This focused effort helps avoid a situation where you become overwhelmed by endless possible actions to track. As you get more comfortable, you can add more events to your tracking plan that can answer peripheral questions. Segment began by tracking these events: User Signed Up Source Data Sent Subscription Started Next, Segment added some of the following peripheral events that helped monitor performance: User Invited ;\n When users invite more people to their organization, it’s a good indicator that they’re engaged and serious about using the product. This helps measure organizational growth. Destination Enabled ;\n Turning on a destination is a key value driver for Segment’s customers. Debugger Call Expanded ;\n When Segment sees that a certain customer has used the live event stream feature a number of times, Segment can contact them to see if they need help debugging. For an ecommerce company, however, the main events might be something like: Account Created Product Added Order Completed Note that Segment has a set of “reserved” event names specifically for ecommerce, called the Segment ecommerce spec . Check it out to see which events Segments covers and how they are used in our downstream destinations. For a community, on the other hand, an entirely different set of actions indicate engagement, listed in the following pyramid. For example, a community like GrowthHackers may want to track actions like: Content Viewed Content Shared Comment Submitted Content Produced Content Curated With this, they’re able to measure key metrics around engagement and understand how users are moving towards their ultimate conversion event: curation content for others. For more information, check out this article from GrowthHackers about the events they track and why. Define your Track event properties Each Track call can accept an optional dictionary of properties , which can contain any key-value pair you want. These properties act as dimensions that allow your end tool to group, filter, and analyze the events. They give you additional detail on broader events. As mentioned earlier, events should be generic and high level, whereas properties are specific and detailed. For example, at Segment, Business Tier Workspace Created works poorly as an event name. Instead, Segment used Workspace Created with a property of account_tier and value of business : analytics . track ( ' Workspace Created ' , { account_tier : ' business ' }) Similar to the traits in the Identify call, the properties provide you a column that you can pivot against or filter on in your analytics tools or allow you to create a cohort of users in email tools. Avoid dynamically generated key ’s in the properties dictionary, as each key will create a new column in your downstream tools. Dynamically generated key ’s will clutter your tools with data that will make it difficult and confusing to use later. Here is Segment’s Lead Captured Track call: analytics . track ( userId , ' Lead Captured ' , { email : ' email ' , location : ' header navbar ' url : ' https://segment.com/ ' }); The high level event is Lead Captured and all of the details are tucked into the properties dictionary. In its downstream tools, Segment can easily look at how many leads were captured in different locations on the Segment website. If you want to learn more about how properties are used by downstream tools, check out The Anatomy of a Track Call . Want a free consultation from our Customer Success Managers on how they simplify customer’s analytics? Request a demo of Segment . This page was last modified: 28 Feb 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Data tracking philosophy Define business objectives Formalize your naming and collection standards Create a tracking plan Identify your users Define your Track events Define your Track event properties Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Data Collection Best Practices"
      },
      {
        "level": 2,
        "text": "Data tracking philosophy"
      },
      {
        "level": 2,
        "text": "Define business objectives"
      },
      {
        "level": 2,
        "text": "Formalize your naming and collection standards"
      },
      {
        "level": 2,
        "text": "Create a tracking plan"
      },
      {
        "level": 2,
        "text": "Identify your users"
      },
      {
        "level": 2,
        "text": "Define your Track events"
      },
      {
        "level": 2,
        "text": "Define your Track event properties"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/duplicate-data/",
    "title": " Handling Duplicate Data | Segment Documentation",
    "content": "Home / Guides / Handling Duplicate Data Handling Duplicate Data On this page 99% deduplication Warehouse deduplication Data Lake deduplication Segment guarantees that 99% of your data won’t have duplicates within an approximately 24 hour look-back window. Warehouses and Data Lakes also have their own secondary deduplication process to ensure you store clean data. 99% deduplication Segment has a special deduplication service that sits behind the api.segment.com endpoint and attempts to drop 99% of duplicate data. Segment stores at least 24 hours’ worth of event messageId s, which allows Segment to deduplicate any data that appears with the same messageId within the stored values. Segment deduplicates on the event’s messageId , not on the contents of the event payload. Segment doesn’t have a built-in way to deduplicate data for events that don’t generate messageId s. The message de-duplication is not scoped to a specific source or a workspace, and applies to all events being received by Segment. Keep in mind that Segment’s libraries all generate messageId s for each event payload, with the exception of the Segment HTTP API, which assigns each event a unique messageId when the message is ingested. You can override these default generated IDs and manually assign a messageId if necessary. The messageId field is limited to 100 characters. Warehouse deduplication Duplicate events that are more than 24 hours apart from one another deduplicate in the Warehouse. Segment deduplicates messages going into a Warehouse ( including Profiles Sync data ) based on the messageId , which is the id column in a Segment Warehouse. Data Lake deduplication To ensure clean data in your Data Lake, Segment removes duplicate events at the time your Data Lake ingests data. The Data Lake deduplication process dedupes the data the Data Lake syncs within the last 7 days with Segment deduping the data based on the messageId . This page was last modified: 02 Aug 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page 99% deduplication Warehouse deduplication Data Lake deduplication Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Handling Duplicate Data"
      },
      {
        "level": 2,
        "text": "99% deduplication"
      },
      {
        "level": 2,
        "text": "Warehouse deduplication"
      },
      {
        "level": 2,
        "text": "Data Lake deduplication"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/data-graph/setup-guides/bigquery-setup//",
    "title": " BigQuery Data Graph Setup | Segment Documentation",
    "content": "Home / Unify / Data graph / Setup guides / BigQuery Data Graph Setup BigQuery Data Graph Setup Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Step 1: Roles and permissions Step 2: Create a dataset for Segment to store checkpoint tables Step 3: Grant read-only access for the Data Graph (Optional) Step 4: Restrict read-only access Step 5: Validate permissions Step 6: Connect your warehouse to Segment Update user access for Segment Reverse ETL dataset BigQuery for Data Graph is in beta and Segment is actively working on this feature. Some functionality may change before it becomes generally available. This feature is governed by Segment’s First Access and Beta Preview Terms . Set up your BigQuery data warehouse to Segment for the Data Graph . Step 1: Roles and permissions You need to be an account admin to set up the Segment BigQuery connector as well as write permissions for the __segment_reverse_etl dataset. To set the roles and permissions: Navigate to IAM & Admin > Service Accounts in BigQuery. Click + Create Service Account to create a new service account. Enter your Service account name and a description of what the account will do. Click Create and Continue . Click + Add another role and add the BigQuery User role. Click Continue , then click Done . Search for the service account you just created. From your service account, click the three dots under Actions and select Manage keys . Navigate to Add Key > Create new key . In the pop-up window, select JSON for the key type, and click Create . The file will download. Copy all the content in the JSON file you created in the previous step, and save it for Step 5. Step 2: Create a dataset for Segment to store checkpoint tables Create a new dataset as Segment requires write access to the dataset for internal bookkeeping and to store checkpoint tables for the queries that are executed. Segment recommends you to create a new dataset for the Data Graph. If you choose to use an existing dataset that has also been used for Segment Reverse ETL , you must follow the additional instructions to update user access for the Segment Reverse ETL catalog. To create your dataset, navigate to the BigQuery SQL editor and create a dataset that will be used by Segment. CREATE SCHEMA IF NOT EXISTS `__segment_reverse_etl`;\nGRANT `roles/bigquery.dataEditor` ON SCHEMA `__segment_reverse_etl` TO \"serviceAccount:<YOUR SERVICE ACCOUNT EMAIL>\"; Step 3: Grant read-only access for the Data Graph Grant the BigQuery Data Viewer role to the service account at the project level. Make sure to grant read-only access to the Profiles Sync project in case you have a separate project. To grant read-only access for the Data Graph: Navigate to IAM & Admin > IAM in BigQuery. Search for the service account you just created. From your service account, click the Edit principals pencil . Click ADD ANOTHER ROLE . Select the BigQuery Data Viewer role . Click Save . (Optional) Step 4: Restrict read-only access If you want to restrict access to specific datasets, grant the BigQuery Data Viewer role on datasets to the service account. Make sure to grant read-only access to the Profiles Sync dataset. To restrict read-only access: In the Explorer pane in BigQuery, expand your project and select a dataset. Navigate to Sharing > Permissions . Click Add Principal . Enter your service account in the New principals section. Select the BigQuery Data Viewer role in the Select a role section. Click Save . You can also run the following command: GRANT `roles/bigquery.dataViewer` ON SCHEMA `YOUR_DATASET_NAME` TO \"serviceAccount:<YOUR SERVICE ACCOUNT EMAIL>\"; Step 5: Validate permissions Navigate to IAM & Admin > Service Accounts in BigQuery. Search for the service account you’ve just created. From your service account, click the three dots under Actions and select Manage permissions . Click View Access and click Continue . Select a box with List resources within resource(s) matching your query. Click Analyze , then click Run query . Step 6: Connect your warehouse to Segment Navigate to Unify > Data Graph in Segment. This should be a Unify space with Profiles Sync already set up. Click Connect warehouse . Select BigQuery as your warehouse type. Enter your warehouse credentials. Segment requires the following settings to connect to your BigQuery warehouse: Service Account Credentials: JSON credentials for a GCP Service Account that has BigQuery read/write access. This is the credential created in Step 1. Data Location: This specifies the primary data location. This can be either region or multi-region. Test your connection, then click Save . Update user access for Segment Reverse ETL dataset If you ran Segment Reverse ETL in the project you are configuring as the Segment connection project, a Segment-managed dataset is already created and you need to provide the new Segment user access to the existing dataset. If you run into an error on the Segment app indicating that the user doesn’t have sufficient privileges on an existing __segment_reverse_etl dataset, grant the BigQuery Data Editor role on the __segment_reverse_etl dataset to the service account . Note that the __segment_reverse_etl dataset is hidden in the console. Run the following SQL command: GRANT `roles/bigquery.dataEditor` ON SCHEMA `__segment_reverse_etl` TO \"serviceAccount:<YOUR SERVICE ACCOUNT EMAIL>\"; This page was last modified: 05 Dec 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Step 1: Roles and permissions Step 2: Create a dataset for Segment to store checkpoint tables Step 3: Grant read-only access for the Data Graph (Optional) Step 4: Restrict read-only access Step 5: Validate permissions Step 6: Connect your warehouse to Segment Update user access for Segment Reverse ETL dataset Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "BigQuery Data Graph Setup"
      },
      {
        "level": 2,
        "text": "Step 1: Roles and permissions"
      },
      {
        "level": 2,
        "text": "Step 2: Create a dataset for Segment to store checkpoint tables"
      },
      {
        "level": 2,
        "text": "Step 3: Grant read-only access for the Data Graph"
      },
      {
        "level": 2,
        "text": "(Optional)Step 4: Restrict read-only access"
      },
      {
        "level": 2,
        "text": "Step 5: Validate permissions"
      },
      {
        "level": 2,
        "text": "Step 6: Connect your warehouse to Segment"
      },
      {
        "level": 2,
        "text": "Update user access for Segment Reverse ETL dataset"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/storage/catalog/",
    "title": " Data Storage catalog | Segment Documentation",
    "content": "Home / Connections / Storage / Data Storage catalog Data Storage catalog AWS S3 Amazon S3 Azure Synapse Analytics Warehouse BigQuery Databricks Google Cloud Storage Beta IBM Db2 Warehouse Postgres Redshift Segment Data Lakes Snowflake Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Data Storage catalog"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/storage/warehouses/add-warehouse-users/",
    "title": " Adding Warehouse Users | Segment Documentation",
    "content": "Home / Connections / Storage / Warehouses / Adding Warehouse Users Adding Warehouse Users If you have more than one person working with your Segment Warehouse, you might want to create users for your team so that each person can have a discrete login. The three steps in this section will show you how to create a user, grant usage on a schema and then grant the privileges that the user will need to interact with that schema. 1. Creating a user with the CREATE USER command CREATE USER < name > [ IN GROUP < group > ] WITH PASSWORD < password > [ VALID UNTIL ] < abstime > The code above in [] is optional, you don’t need to group your users or give their credentials an expiration date, the code works without it. However, if you do choose to use those parameters, <abstime> should be formatted as ‘2015-09-13’ which translates to September 13th, 2015. For instance, you can create a user named flashthesloth as CREATE USER flashthesloth WITH PASSWORD 'slow_is_beautiful' This creates a user, you can run the following to get a list of users in your database. SELECT * FROM pg_user Now that we’ve confirmed that the user has been created, they already have access to the public schema that contains systems-level information about the cluster but we need to give them access to the specific schemas that they’ll be working in. 2. Grant usage on the schema Next, GRANT USAGE on the schema to the user we just created GRANT USAGE ON SCHEMA < schema_name > TO < user > The above SQL command grants the user USAGE privileges on a schema. Let’s assume you want to grant flashthesloth access to your development schema, it would look like below GRANT USAGE ON SCHEMA development TO flashthesloth Our new user now has usage rights on the development schema, now we need to grant the type of SQL commands they’ll be able to run against the cluster. For the purposes of this example, we’re going to give the user read only privileges. 3. Grant select privileges GRANT SELECT privileges so the user can query the tables GRANT SELECT ON ALL TABLES IN SCHEMA < schema_name > TO < user > The above SQL command grants the user SELECT rights on all tables in the chosen schema. For our flashthesloth user and the development schema, it would look like below. GRANT SELECT ON ALL TABLES IN SCHEMA development TO flashthesloth Doing these three steps will result in a new user that can query all the tables in a given schema. If you want to give access to more than one schema then you can simply repeat steps 2 and 3 for each additional schema. If you have any questions or if you’re running into any issues getting this set up, contact us . This page was last modified: 14 Jul 2021 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Adding Warehouse Users"
      },
      {
        "level": 3,
        "text": "1. Creating a user with theCREATE USERcommand"
      },
      {
        "level": 3,
        "text": "2. Grant usage on the schema"
      },
      {
        "level": 3,
        "text": "3. Grant select privileges"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/reverse-etl/reverse-etl-source-setup-guides/postgres-setup/",
    "title": " Postgres Reverse ETL Setup | Segment Documentation",
    "content": "Home / Connections / Reverse etl / Reverse etl source setup guides / Postgres Reverse ETL Setup Postgres Reverse ETL Setup On this page Set up guide Extra permissions Set up Postgres as your Reverse ETL source. At a high level, when you set up Postgres for Reverse ETL, the configured user/role needs read permissions for any resources (databases, schemas, tables) the query needs to access. Segment keeps track of changes to your query results with a managed schema ( __SEGMENT_REVERSE_ETL ), which requires the configured user to allow write permissions for that schema. Postgres Reverse ETL sources support Segment's dbt extension If you have an existing dbt account with a Git repository, you can use Segment’s dbt extension to centralize model management and versioning, reduce redundancies, and run CI checks to prevent breaking changes. Segment supports the following Postgres database providers: Heroku RDS Segment only supports these Postgres database providers. Postgres databases from other providers aren’t guaranteed to work. For questions or concerns about Segment-supported Postgres providers, contact Segment Support . Set up guide To set up Postgres with Reverse ETL: Log in to your Postgres account. Configure the correction network and security settings for your Postgres database. If you’re using RDS Postgres, follow this guide . Make sure the following IP addresses can access the database. Run the SQL commands below to create a user named segment . -- create a user named \"segment\" that Segment will use when connecting to your Postgres cluster. CREATE USER segment PASSWORD '<enter password here>' ; -- allows the \"segment\" user to create new schemas on the specified database. (this is the name you chose when provisioning your cluster) GRANT CREATE ON DATABASE \"<enter database name here>\" TO \"segment\" ; Make sure the user has correct access permissions to the database. Follow the steps listed in the Add a source section to finish adding Postgres as a source. Extra permissions Give the segment user read permissions for any resources (databases, schemas, tables) the query needs to access. Give the segment user write permissions for the Segment managed schema ( __SEGMENT_REVERSE_ETL ), which keeps track of changes to the query results. After you’ve successfully added your Postgres source, add a model and follow the rest of the steps in the Reverse ETL setup guide. This page was last modified: 10 Jun 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Set up guide Extra permissions Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Postgres Reverse ETL Setup"
      },
      {
        "level": 2,
        "text": "Set up guide"
      },
      {
        "level": 2,
        "text": "Extra permissions"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/functions/aws-apis/",
    "title": " Set up functions for calling AWS APIs | Segment Documentation",
    "content": "Home / Connections / Functions / Set up functions for calling AWS APIs Set up functions for calling AWS APIs The aws-sdk module is built-in, which allows you to make calls to AWS services in your own AWS accounts. The AWS SDK requires additional setup to ensure access to your AWS resources is secure. This page describes the process for allowing your functions to securely call AWS APIs in your AWS account. To set up your functions to call AWS APIs: Create an IAM role in your AWS account that your function will assume before making AWS API calls. Make sure you have these two values: Principal account ID : This is the ID number for the AWS account that your function runs in. For destination functions, this is 458175278816 and for source functions this is 300240842537 . External ID : This is the value your IAM role uses to ensure that only your functions have the ability to assume the role. Segment recommends you to choose a long string of at least 32 random characters and treat it as if it were an API key or a password. Create an IAM role in your AWS account with the minimum set of necessary permissions . Add a trust relationship to your role with the following policy, filling in the principal account ID and external ID from step 1.1: { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Principal\" : { \"AWS\" : \"<PRINCIPAL_ACCOUNT_ID>\" }, \"Action\" : \"sts:AssumeRole\" , \"Condition\" : { \"StringEquals\" : { \"sts:ExternalId\" : \"<EXTERNAL_ID>\" } } } ] } Create your function. Now that you have an IAM role in your AWS account, you can create your source or destination function. Segment recommends you to use function settings to make the IAM role configurable. This allows you to use different roles for different instances of your function and to securely store your external ID value by making it a “sensitive” setting. Here are the required settings: IAM Role ARN : A string setting that is the ARN for the IAM role above. For example, arn:aws:iam::1234567890:role/my-secure-role . IAM Role External ID : A sensitive string setting that is the external ID for your IAM role. Below is an example destination function that uploads each event received to an S3 bucket (configured using additional “S3 Bucket” and “S3 Bucket Region” settings). It uses the built-in local cache to retain S3 clients between requests to minimize processing time and to allow different instances of the function to use different IAM roles. async function getS3 ( settings ) { const ttl = 30 * 60 * 1000 ; // 30 minutes const key = [ settings . iamRoleArn , settings . s3Bucket ]. join (); return cache . load ( key , ttl , async () => { const sts = new AWS . STS (); const opts = await sts . assumeRole ({ RoleArn : settings . iamRoleArn , ExternalId : settings . iamRoleExternalId , RoleSessionName : ' segment-function ' }) . promise () . then ( data => { return { region : settings . s3BucketRegion , accessKeyId : data . Credentials . AccessKeyId , secretAccessKey : data . Credentials . SecretAccessKey , sessionToken : data . Credentials . SessionToken }; }); return new AWS . S3 (); }); } async function onTrack ( event , settings ) { const s3 = await getS3 ( settings ); return s3 . putObject ({ Bucket : settings . s3Bucket , Key : ` ${ event . type } / ${ Date . now ()} .json` , Body : JSON . stringify ( event ) }) . promise () . then ( data => { console . log ( data ); }); } This page was last modified: 11 May 2022 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Set up functions for calling AWS APIs"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/what-is-replay/",
    "title": " Replay | Segment Documentation",
    "content": "Home / Guides / Replay Replay Free x Team x Business ✓ Add-on x ? Replay is available to all Business plans. See the available plans , or contact Support . On this page Replays for tooling changes Replays for resilience Replays considerations Replay takes an archived copy of your Segment data, and re-sends it to new or existing tools providing huge benefits to mature data systems. By archiving and replaying data, you can avoid vendor lock-in, and protect your system against data loss. Replays for tooling changes With Replays, you can send your existing data to new tools.\nThis means you can send a limited sample of your data to a new tool to test it out, and run similar tools in parallel to verify the data format or accuracy of the output. Finally, when you’re ready to switch to a new tool, you can replay a full set of your data to the new tool to backfill it with data that extends before you set up the tool - no warm-up time or operational gap to disrupt your work. Note Any destinations which accept cloud-mode data (meaning data from Segment, and not directly from users’ devices) can use replay, however they must also process timestamps on the data for replay to be useful. Replays for resilience With Replays, you’re protected from outages and errors. If a destination which you rely on experiences an outage, or is temporarily unable to accept incoming data, you can use Replays to re-send data to that tool once the service recovers. You can also use Replays to recover from errors caused by misconfigurations in your Segment systems. For example, if you send data in the wrong format, or want to apply destination filters . In this case, you can change your mapping using a destination filter, clear out the bad data, and replay it to that destination. You can also use this to update the schema in your data warehouse when it changes. For more information, Contact us and our Success Engineers will walk you through the process. Replays considerations Replays are currently only available for Business Tier customers, and due to their complex nature are not self-serve. Contact us to learn more, or to request a replay for your workspace. When requesting a replay, include the workspace, the source to replay from, the destination tool or tools, and the time period. Replays can process unlimited data, but they’re rate limited to respect limitations in downstream partner tools. If you’re also sending data to the destination being replayed to in real time, then, when determining your replay’s limit, you’ll want to take into account the rate limit being used by real-time events. You should also account for a small margin of your rate limit to allow events to be retried. Replay time depends both on the tool Segment replays to and the amount of data included in the replay. Replays do not affect your MTU count , unless you are using a Repeater destination . Notify your team before initiating a Replay if you’re using a Repeater destination. Once a replay starts, you will not see replayed events in the Event Delivery tab. You can initiate replays for some or all events, but you can’t apply conditional filters that exclude certain rows of data from being replayed. You can set up destination filters to conditionally filter replayed events. The destination is not required to be enabled in order for a replay to be successful, including Destination Functions. The destination must be connected to the source, but can remain disabled while the replay is running. Destination filters are still considered when you run replays on disabled destinations. There are a few exceptions for destinations that must be enabled for the replay to be successful : Amazon S3 and Google Cloud Source (GCS). Replay-eligible destinations Replays are available for any destinations which support cloud-mode data (meaning data routed through Segment) and which also process timestamps. Destinations that are only available in device-mode (meaning where data is sent directly from the users’ devices to the destination tool) cannot receive Replays. Not all destinations support data deduplication, so you may need to delete, archive, or remove any older versions of the data before initiating a replay. contact Segment support if you have questions or want help. Replays & Destination Filters Replays are subject to the Destination Filters you’ve configured on that destination. For example, if you request that Identify calls be included in the replay, but your destination has a Destination Filter that blocks Identify events, the filter then blocks all Identify events from making it to the destination. In this case, Segment recommends that you avoid including Identify events in the replay if you know they’ll be blocked by the destination filter. When you request a replay, Segment asks you to provide a list of the events (type and/or name) that you want included in the replay. If you specify a list of events, then Segment only includes those specified events in the replay. If you need to exclude events in your replay, contact Segment support . The Segment team can help you handle filtering you’re unable to do in the replay. Replays & Engage There are two types of replays with Engage. Replay a Profile Source’s data into Engage Space, (sending a standard source’s data into an Engage Space), which can be configured to send over a specified timeframe as well as the ability to specify all or only a specific subset of events by type or name. Replay from an Engage Space to its connected destination, (sending data from an Engage Output Source to its connected destination), which includes all the computational data (Audiences, Computed Traits, Journeys) that destination is currently configured to receive, which can be configured to send over a specified timeframe as well as the ability to specify all or only a specific subset of events by type or name. Nuances to Consider for Engage Replays 1. Replay a Profile Source’s data into Engage Space When a new Profile Source is connected to an Engage Space, the default option to replay the source’s data seen over the past 30 days can be selected. To request a source’s additional historical data be replayed to the Engage Space, contact Segment Support at friends@segment.com or create a ticket . Please see this documentation on further details of this process and what to include in your support request. 2. Replay from an Engage Space to its connected destination Since each instance of a destination is connected to its own Engage “Output” source, that source contains events for all of the computations that destination is connected to received data from, the list of output sources can be found under Unify > Unify Settings > Debugger . Because of this, it’s not possible to replay only a specific computation’s data to the destination, you should instead consider reaching out to Segment support to request a resync of that computation to its destination instead. However, if you would like to replay all failed events seen by that destination, which will encompass all connected computations, that can be achieved with a replay. Note: The replay will be sending historical data to the destination, potentially overwriting the destination with outdated data if more recent data has been sent from the computation to the destination. In this case, a resync of the computation might also be more advantageous to get the most up-to-date data resent to the destination. Rate limits for replays are configurable and can be increased or decreased upon request. However, there are some destinations which have strict rate limits and cannot be configured to send data at a higher rate than what’s stated within the table on Rate limits on Engage Event Destinations . Engage : Replay versus Resync Replay : A replay resends all events, specific events by type or name, or failed events over a specified period of time to the destination. Resync : A resync sends events for a computation’s (Audience, Computed Trait, Journey) entire current user base to its connected destination. This page was last modified: 05 Jun 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Replays for tooling changes Replays for resilience Replays considerations Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Replay"
      },
      {
        "level": 2,
        "text": "Replays for tooling changes"
      },
      {
        "level": 2,
        "text": "Replays for resilience"
      },
      {
        "level": 2,
        "text": "Replays considerations"
      },
      {
        "level": 3,
        "text": "Replay-eligible destinations"
      },
      {
        "level": 3,
        "text": "Replays & Destination Filters"
      },
      {
        "level": 3,
        "text": "Replays & Engage"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/config-api/fql/",
    "title": "Redirecting…",
    "content": "",
    "headings": [
      {
        "level": 1,
        "text": "Redirecting…"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/partners/",
    "title": " Developer Center Overview | Segment Documentation",
    "content": "Home / Developer Center Overview Developer Center Overview On this page Build on Segment Development process Welcome! Here are the steps you’ll follow to build an integration on Dev Center 2.0, launch your destination to Private Beta so customers can test it, and then launch it as Public in the Segment catalog. Build on Segment Over 19,000 companies use Segment as their central hub for collecting and synthesizing first-party customer data. Customers use Segment sources to collect data across all their properties (for example, web, mobile, CRMs, or email) and send this data into destinations (SaaS tools, internal databases or queues, or a data warehouse) to perform analytics, run marketing campaigns and much more. Integration types Segment provides two different integration types to support bringing your data into Segment, and sending your data downstream to other third-party tools. Sources Sources bring users’ first-party data into Segment. While there are several types of sources (for example, web or server libraries, mobile integrations, and Cloud), the Developer Center enables you to build your own Cloud Event sources. These sources enable users to import data directly from your application into Segment. Destinations Destinations send data to other tools for processing or analysis. For example, a Segment user may want to send their data to your advertising platform or analytics tool. To accomplish this, they’ll connect your Segment destination to their workspace. All new Segment Destinations are built on the Actions framework , which enables a simplified build experience for you and a more straightforward configuration experience for your users. Development process To develop your integration in the Developer Center, complete the following steps: Become a Segment Partner Understand Segment’s conceptual model and Spec Follow Segment’s security guidance Request access to the Segment Developer Center Create your integration Write your integration’s documentation Become a Segment Partner Sign up for the Segment Select Partner Program . During the sign-up process, you’ll agree to the Segment Partner Program Agreement and Privacy Policy . Understand Segment’s conceptual model and Spec Segment’s Conceptual Model is a high-level overview of how Segment works and explains how your integration fits into the Segment catalog. The Segment Spec provides best practices for the specific data you should capture and the best way to format that data based on your use case. The Spec outlines the semantic definition of the customer data that Segment captures across all its libraries and APIs, and will be a main building block for your integration. Follow Segment’s security guidance Security for both customers and partners is a priority at Segment. Before you start building on the Developer Center, review the Acceptable Use Policy and ensure you’re following these guidelines: Follow a secure software-development lifecycle, which enables you to create code that is safe for Segment customers and their end users, and that enables you to maintain and raise the security of that code over time If you or your code comes into contact with Segment customer- or end-user data for any reason, protect it with commercially reasonable methods throughout its data lifecycle, including creation, handling, transporting, storing and destruction. If you suspect a security event, incident or breach while working on this project or afterward, contact Segment Security for assistance with your investigation and communications Practice modern and common-sense security for any scenario that is not explicitly stated. Request access to the Segment Developer Center Segment provides access to the Developer Portal on request. Open the Developer Portal page and click Sign up to request access. A Segment account is required for this step. Segment receives a large volume of requests so please include a valid company website and email address, answer all questions with details about integration’s use case as well as highlighting specific customer requests to expedite the approval process. Create your integration Follow the steps to build your source or destination . Write your integration’s documentation Documentation is integral to enabling Segment’s users to self-serve and onboard with your integration. Segment’s documentation team will work with you during this part of the process to ensure your documentation matches the Segment style and is as instructive as possible. Source Documentation Instructions Destination Documentation Instructions Submit your integration for review Before users can go hands on with your integration, a review by Segment engineers is required to ensure the integration meets security and usability standards. Destinations To submit your destination for review, follow the destination-specific instructions in the Submit a pull request docs. Sources To submit your source for review, complete the steps described in the Developer Portal and click Submit for review . This page was last modified: 12 Aug 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Build on Segment Development process Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Developer Center Overview"
      },
      {
        "level": 2,
        "text": "Build on Segment"
      },
      {
        "level": 3,
        "text": "Integration types"
      },
      {
        "level": 2,
        "text": "Development process"
      },
      {
        "level": 3,
        "text": "Become a Segment Partner"
      },
      {
        "level": 3,
        "text": "Understand Segment’s conceptual model and Spec"
      },
      {
        "level": 3,
        "text": "Follow Segment’s security guidance"
      },
      {
        "level": 3,
        "text": "Request access to the Segment Developer Center"
      },
      {
        "level": 3,
        "text": "Create your integration"
      },
      {
        "level": 3,
        "text": "Write your integration’s documentation"
      },
      {
        "level": 3,
        "text": "Submit your integration for review"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/getting-started/whats-next/",
    "title": " What's Next | Segment Documentation",
    "content": "Home / Getting started / What's Next What's Next On this page Privacy tools and filtering Improve data quality with Protocols Single view of the customer with Engage More learning resources Technical Support You’re just getting started with Segment, but there’s so much more to explore! Privacy tools and filtering Segment includes a free suite of Privacy tools to help your organization comply with regulations like the GDPR and the CCPA. The Privacy Portal allows you to easily audit, monitor, and enforce privacy rules against your Segment data, to proactively protect your customers. Improve data quality with Protocols You had a taste of the planning needed to set up clear, consistent, reliable and extensible data schemas in Planning a Full Install . Business tier customers can use Segment’s Protocols package to help with this process, to keep track of what data is being collected where, and to normalize their data as it flows through Segment. Clean, consistent data helps you move faster to build marketing campaigns and act on analytics insights. With Protocols, you can use Tracking Plans to build consensus in your organization about which events and property you intend to collect across your web, mobile or server-side data sources. Once defined, you can connect the Tracking Plan to your Sources to automatically validate the data is flowing correctly. You can also turn on enforcement to block bad data, and even fix incorrect data with Transformations . Single view of the customer with Engage Engage is a powerful personalization platform that enables you to create unified customer profiles in Segment, to build and enrich audiences, and to activate audiences across marketing tools. With Engage, you can create unified customer profiles, enrich those profiles with new traits, build Audiences using those profiles, and sync audiences to marketing tools to power personalized experiences, and better understand and market to your customers. More learning resources Segment University Segment University is Segment’s free, online classroom for learning the basics of Segment. Analytics Academy Analytics Academy is a series of lessons designed to help you understand the value of analytics as a discipline, and to help you think through your analytics needs, and get started creating robust and flexible analytics systems to help you grow. Recipes Need ideas or prior art? Segment Recipes are some cool things you can do by hooking your Segment workspace up to different Destination tools. Everything from sending tailored onboarding emails, to joining and cleaning your data with third party tools Other Resources Still hungry for more? Check out our list of other Segment Resources ! Technical Support If you’re experiencing problems, have questions about implementing Segment, or want to report a bug, you can fill out our support contact form here and our Product Support Engineers will get back to you. You need a Segment.com account in order to file a support request. Don’t worry! You can always sign up for a free workspace if you don’t already have one. Back to the index Back to the Getting Started index This page was last modified: 27 Sep 2022 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Privacy tools and filtering Improve data quality with Protocols Single view of the customer with Engage More learning resources Technical Support Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "What's Next"
      },
      {
        "level": 2,
        "text": "Privacy tools and filtering"
      },
      {
        "level": 2,
        "text": "Improve data quality with Protocols"
      },
      {
        "level": 2,
        "text": "Single view of the customer with Engage"
      },
      {
        "level": 2,
        "text": "More learning resources"
      },
      {
        "level": 3,
        "text": "Other Resources"
      },
      {
        "level": 2,
        "text": "Technical Support"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/content/email/html-editor/",
    "title": " HTML Editor | Segment Documentation",
    "content": "Home / Engage / Content / Email / HTML Editor HTML Editor On this page Getting started Visual Editor HTML Editor Personalize with merge tags Add unsubscribe links Toggle between editors Save the template Next steps Engage Premier entered an End of Sale (EOS) period effective  June 10, 2024. Existing Segment customers will continue to have access and support to Engage Premier until an end-of-life (EOL) date is announced. We recommend exploring the following pages in preparation of a migration or future MCM needs: Twilio Marketing Campaigns Preferred ISV Partners: Airship Blog Bloomreach Blog Braze Blog Insider Blog Klaviyo Blog Twilio Engage Foundations Documentation Use the HTML Editor to design your email template with both code and visual editing capabilities. Build your email template with code, copy and paste existing code, or use the Visual Editor for a code free design experience. On this page, you’ll learn how to use the HTML Editor to build personalized email templates for your Engage campaigns. Getting started You can navigate to the HTML Editor in two ways: When you build a new email template or edit an existing one. From a Send Email step in a Journey. From the Select Editor screen, select HTML Editor and click Build Email . Visual Editor Use the Visual Editor for a no-code option to design your email. With the Visual Editor, you can: Add or modify headings and text Modify text color, size, and style Insert an image Add merge tags and links Add emojis Engage updates any changes you make in the Visual Editor to the HTML Editor in real-time. Insert an image To insert an image from the Visual Editor: Select the image icon in the Visual Editor toolbar. Add the image URL source and alternative text. Edit the image width and height. You can also click and drag the corners of the image to resize it in the Visual Editor. Click Save . Preview for desktop or mobile display To preview your email template, click the preview icon in the Visual Editor toolbar. From the preview screen, you can toggle between desktop or mobile to view the email in both displays. HTML Editor Use the HTML Editor to maintain your email template with code. Copy and paste existing code or build a new template in the editor. Engage displays any changes you make in a preview screen to the right of your code. You can preview your email in both desktop and mobile display. Click Format at any time to properly indent and format your code in the HTML Editor. When you toggle from the HTML Editor to the Visual Editor, Engage may make minor changes to your code formatting. If Engage re-formats your code, it will not affect the email layout. Error flagging and content validation Engage displays in-line error flags in the code editor to help you debug your code. If there are errors, you might not see content as expected in the preview screen until you’ve debugged your code. For all content editors in Engage, you’ll see alerts for any issues in your template, such as invalid profile traits or incorrect liquid syntax . Engage both flags template issue(s), and displays recommended next steps. While you can save these templates, you must fix any issues before using them in Engage campaigns. Personalize with merge tags Add merge tags to personalize your message with user profile traits. From the text toolbar in the Visual Editor, click the Merge Tags drop-down menu. Select profile traits to add to the merge tags. Based on cursor placement, Engage adds merge tags to your template. You can also add merge tags to your email right from the code editor. Liquid templating Engage supports liquid templating to create dynamic content in the HTML Editor. For example, use {% if %} , {% elseif %} , and {% else %} tags to call a product by name if known, or use a default message: {% if profile.traits.product_title == \"Sneakers\" %}\n  Hey, view our latest sneakers!\n{% elsif profile.traits.product_title == \"Sandals\" %}\n  Hey, check out these sandals!\n{% else %}\n  Hey, check out our latest footwear.\n{% endif %} If you use liquid templating, be sure to test your email to make sure that everything renders properly. While both the HTML and Visual Editor support liquid templating, Segment recommends using the HTML Editor to write liquid templating. Engage doesn’t support liquid template syntax that produces partial blocks of HTML. To view more examples related to your use case, visit the LiquidJS docs . Add unsubscribe links It’s always best practice to include an unsubscribe link in the emails you build. Engage adds an unsubscribe link to email templates, which you can edit at any time. You can add unsubscribe links from the visual or HTML Editor. From the Visual Editor: Select the link icon in the Visual Editor toolbar. Enter [unsubscribe] in the URL field. Enter the link attributes and text. Click Save . To add a link from the code editor, use <a href = \"[unsubscribe]\"> </a> in your HTML. For more on email unsubscribe links, view SendGrid’s best practices . Toggle between editors From the editor screen, you can click Use HTML Editor or Use Visual Editor to toggle between the two editors. The Visual Editor renders your HTML in an editable preview (similar to an email client), so you might need to accept formatting changes to your HTML to use the Visual Editor. In this case, Segment displays a confirmation modal with HTML differences. Potential HTML changes include formatting, removing attributes with potentially unsuported scripts in your HTML (for example, onclick or onblur ), attribute reordering, and adding missing tags. If you don’t want to accept the changes required to use the Visual Editor, you can continue editing in the HTML Editor. Formatting your HTML In the HTML Editor, you can use the Format button to properly indent and format your code. Note that the Format button may not implement all changes necessary to use the Visual Editor. Save the template After you design the email, click Create Email Template . You can navigate to Engage > Content > Templates to view and maintain your email template. Next steps Learn more about building email templates to include in your Engage campaigns. You can also learn about the Drag and Drop Editor in Engage to build Email templates with drag and drop functionality. Once you create an email with the HTML Editor, you can’t modify it with the Drag and Drop Editor, and vice versa. This page was last modified: 15 Jul 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Getting started Visual Editor HTML Editor Personalize with merge tags Add unsubscribe links Toggle between editors Save the template Next steps Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "HTML Editor"
      },
      {
        "level": 2,
        "text": "Getting started"
      },
      {
        "level": 2,
        "text": "Visual Editor"
      },
      {
        "level": 3,
        "text": "Insert an image"
      },
      {
        "level": 3,
        "text": "Preview for desktop or mobile display"
      },
      {
        "level": 2,
        "text": "HTML Editor"
      },
      {
        "level": 3,
        "text": "Error flagging and content validation"
      },
      {
        "level": 2,
        "text": "Personalize with merge tags"
      },
      {
        "level": 3,
        "text": "Liquid templating"
      },
      {
        "level": 2,
        "text": "Add unsubscribe links"
      },
      {
        "level": 2,
        "text": "Toggle between editors"
      },
      {
        "level": 3,
        "text": "Formatting your HTML"
      },
      {
        "level": 2,
        "text": "Save the template"
      },
      {
        "level": 2,
        "text": "Next steps"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/how-to-guides/import-historical-data/",
    "title": " Importing Historical Data | Segment Documentation",
    "content": "Home / Guides / How to guides / Importing Historical Data Importing Historical Data On this page Method 1: Using a Custom Solution Method 2: Using Reverse ETL When transitioning over to Segment, customers commonly want to import historical data into tools they are migrating to or evaluating. Note: Historical imports can only be done into destinations that can accept historical timestamped data. Most analytics tools like Mixpanel, Amplitude, or Kissmetrics can handle that type of data just fine. One common destination that doesn’t accept historical data is Google Analytics, since their API cannot accept historical data. Method 1: Using a Custom Solution General Instructions Use any server-side library , which sends requests in batches to improve performance. Once you have data to import, follow the steps below: Export or collect the data to be imported. Include timestamp data in your export if the data needs to appear in end tools in a historical reference. For instance, if you’re importing emails and it’s relevant to know when someone joined your email list, you may need to export the timestamp. If no timestamp is specified when importing, the data will show a timestamp from the time the data was received . Decide which destinations need to receive the data. By default, data coming into Segment will be forwarded to all destinations connected to a given source. To limit data to specific destinations, the integrations object must be modified. With historical data, you often only want to send the data to a specific destination or into your data warehouse. For example, in Node.js set the integrations object as follows. analytics . track ({ event : ' Upgraded Membership ' , userId : ' 97234974 ' , integrations : { ' All ' : false , ' Vero ' : true , ' Google Analytics ' : false } }) Once you’ve done that, you’ll need to write an application or worker to send the data to Segment. You will need to cycle through each set of data and map it to a Segment server-side library method or build an array matching the HTTP Import API format . Tip : Segment recommends using a Segment library for this process, as they set contextual message fields like message_id (used for deduping) and sent_at (used for correctly client clock skew) that Segment’s API uses to correct behavior upon ingestion. Tip : The server-side libraries will automatically batch requests to optimize for performance and prevent linear request volume. This batching behavior is modifiable, and some of the underlying libraries implement a configurable max queue size that may discard messages if you enqueue requests much faster than the client can flush them. We recommend overriding the max queue size parameter for the library to a high value you’re comfortable you can remain under in your batch job. Demo projects The following projects are open-source and do not have official Segment support. If you encounter issues, the best way to get help is by opening an issue on the project’s GitHub page. \nFeel free to clone the repository and adjust the code to suit your unique needs. One of Segment’s Success Engineers wrote an alpha prototype Node.js app for importing data utilizing the HTTP API, which we’ve included below: Example Node.js import application Additionally, one of Segment’s Software Engineers developed a React App with more out of the box functionality for importing events. The features include a modern UI, transformations, and event format checking prior to import: Desktop React CSV uploader MarketLytics has documented their experience using the alpha prototype importer and offer some helpful visuals and tips . Alternative solution If a server-side library doesn’t meet your needs, you can use the Segment bulk import HTTP API directly. Note: When you use the HTTP API to export historical data to upload to Segment, remove all the original sent_at , message_id , and project_id fields from the archived message before forwarding them back to Segment. Method 2: Using Reverse ETL Please refer to the Reverse ETL guide for more details. This page was last modified: 14 May 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Method 1: Using a Custom Solution Method 2: Using Reverse ETL Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Importing Historical Data"
      },
      {
        "level": 2,
        "text": "Method 1: Using a Custom Solution"
      },
      {
        "level": 3,
        "text": "General Instructions"
      },
      {
        "level": 3,
        "text": "Demo projects"
      },
      {
        "level": 3,
        "text": "Alternative solution"
      },
      {
        "level": 2,
        "text": "Method 2: Using Reverse ETL"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/spec/",
    "title": " Spec Overview | Segment Documentation",
    "content": "Home / Connections / Spec Overview Spec Overview The Segment Spec provides guidance on meaningful data to capture, and the best format for it, across all of Segment’s libraries and APIs. If you implement Segment using these formats, it’s simple to translate your data to downstream tools. Segment University: The Segment Methods Check out our high-level overview of these APIs in Segment University. (Must be logged in to access.) Event and Product Limits Events ingested by Segment are subject to defined Product Limits . The Segment Spec has three components. First, it outlines the semantic definition of the customer data Segment captures across all libraries and APIs .  There are six API calls in the Spec. They each represent a distinct type of semantic information about a customer. Every call shares the same common fields . APIs Identify : who is the customer? Track : what are they doing? Page : what web page are they on? Screen : what app screen are they on? Group : what account or organization are they part of? Alias : what was their past identity? Second, it details the event data Segment captures across some cloud sources and destinations . Cloud Sources and Destinations Email Live Chat A/B Testing Third, it shares the events Segment recommends you track for a particular industry based on experience working with thousands of customers . When you respect these specs, Segment maps these events to particular features within end destinations like Google Analytics and Facebook Ads. Industry Specs Mobile E-Commerce Video B2B SaaS AI Copilot This page was last modified: 18 Apr 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Spec Overview"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/journeys/use-cases/",
    "title": " Example Journeys Use Cases | Segment Documentation",
    "content": "Home / Engage / Journeys / Example Journeys Use Cases Example Journeys Use Cases Free x Team x Business ✓ + Engage Foundations ✓ ? Engage Foundations requires a Business tier account and includes Unify. See the available plans , or contact Support . On this page E-commerce use cases B2B use cases Media use cases To help you get underway, you can reference these sample Journeys. E-commerce use cases Repeat purchase campaign This journey focuses on converting one-time buyers into repeat purchasers by delivering communications in their preferred channels. Create the entry condition with the step name One-Time Purchasers . All users who performed Order Completed exactly 1 time Add a wait duration of 14 days Add a condition called No New Transactions All users who performed Order Completed exactly 1 time Add a multi-branch split Branch 1: Customers who have the trait Most Frequent UTM Source equals Email Send to destination: Email Branch 2: Customers who have the trait Most Frequent UTM Source equals SMS Send to destination: SMS Low recency purchase winback This journey represents a campaign designed to drive returning purchases based on intent and lifetime value goals. Create the entry condition with the step name Low recency purchasers . All users who have performed the Order Completed event zero times within the last 180 days . Add a True/false split. Split the audience around a computed trait of Customer Lifetime Value > 100 . For the True branch, send the list of users to Email and Advertising destinations. For the False branch, send the list of users to an Email destination. Add a wait duration of 1 day to the True branch from step 2. Add a Wait for condition step to wait for a Page Viewed event at least 1 time and where utm_source is equal to the ad or email campaign, within 1 day. Send this list of users to an email destination, as they are more likely to accept a discount and complete the purchase. B2B use cases Trial to paid conversion This journey creates an acquisition campaign designed to convert trial accounts to paid accounts with a unified owned and paid media strategy. Create the entry condition with the step name Trial started . All users who performed Trial Started at least once and who performed Subscription Started exactly 0 times. Add a wait duration of 5 days . Add a True/false split. Split the audience around users who have performed Subscription Started For the True branch, send the list of users to Email and Support destinations. For the False branch, send the list of users to an Email destination, Support, and Advertising destinations. Onboarding flow This journey creates an onboarding flow designed to maintain new user engagement through the onboarding experience. Create the entry condition with the step name Account created . Set the condition to all users who performed Account Created at least 1 time. Add a wait duration of 1 hour . Add a True/false split. Split the audience based on those who have performed Tutorial Completed . For the True branch, send the list of users to Email, Support, and In-App destinations. For the False branch, send the list of users to Email, Support, In-App, and Advertising destinations. Media use cases Paid subscription acquisition This journey creates an acquisition campaign designed to convert trial subscriptions to paid subscriptions with a unified owned and paid media strategy. Create the entry condition with the step name Free trial . Set the condition to all users who performed Subscription Started at least 1 time, and where Subscription Plan Type is Free . Add a wait duration of 1 hour . Send the list of users to an Email destination. Add a wait duration of 7 days . Add a True/false split. Split the audience based on those who have performed Subscription Started where Subscription Plan Type is paid . For the True branch, send to an email destination. For the False branch, send to both email and advertising destinations. Re-engagement Campaign This journey aims to bring back users with personalized messaging while conserving ad spend based on user preferences. Create the entry condition with the step name Low Recency Engagement . Set the condition to all users who performed Page Viewed exactly 0 times within 60 days . Add a True/false split. Split the audience based on those who have performed Subscription Started where Subscription Plan Type is paid For the True branch, add a multi-branch split For users who have the Computed Trait user_favorite_article-category = Engineering Send to email and ads destinations For users who have the Computed Trait user_favorite_article-category = Marketing Send to email and ads destinations For the False branch, send to an email destination only. This page was last modified: 27 Sep 2022 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page E-commerce use cases B2B use cases Media use cases Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Example Journeys Use Cases"
      },
      {
        "level": 2,
        "text": "E-commerce use cases"
      },
      {
        "level": 3,
        "text": "Repeat purchase campaign"
      },
      {
        "level": 3,
        "text": "Low recency purchase winback"
      },
      {
        "level": 2,
        "text": "B2B use cases"
      },
      {
        "level": 3,
        "text": "Trial to paid conversion"
      },
      {
        "level": 3,
        "text": "Onboarding flow"
      },
      {
        "level": 2,
        "text": "Media use cases"
      },
      {
        "level": 3,
        "text": "Paid subscription acquisition"
      },
      {
        "level": 3,
        "text": "Re-engagement Campaign"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/spec/identify/",
    "title": " Spec: Identify | Segment Documentation",
    "content": "Home / Connections / Spec / Spec: Identify Spec: Identify On this page Example Identities Custom traits The Segment Identify call lets you tie a user to their actions and record traits about them.  It includes a unique User ID and any optional traits you know about the user, like their email, name, and more. Segment University: The Identify Method Check out our high-level overview of the Identify method in Segment University. (Must be logged in to access.) Segment recommends that you make an Identify call: After a user first registers After a user logs in When a user updates their info (for example, they change or add a new address) The first three examples are pretty self-explanatory, but many might ask: why you would call Identify on every page load if you’re storing the userId in the cookie/local storage? Calling Identify in one of Segment’s libraries is one of the first steps to getting started with Segment. Refer to library-specific documentation for more details. Here’s the payload of a typical Identify call with most common fields removed: { \"type\" : \"identify\" , \"traits\" : { \"name\" : \"Peter Gibbons\" , \"email\" : \"peter@example.com\" , \"plan\" : \"premium\" , \"logins\" : 5 }, \"userId\" : \"97980cfea0067\" } And here’s the corresponding JavaScript event that would generate the above payload: analytics . identify ( \" 97980cfea0067 \" , { name : \" Peter Gibbons \" , email : \" peter@example.com \" , plan : \" premium \" , logins : 5 }); Based on the library you use, the syntax in the examples might be different. You can find library-specific documentation on the Sources Overview page. Beyond the common fields, an Identify call has the following fields: Field Type Description traits optional Object Free-form dictionary of traits of the user, like email or name .\n\n  See the Traits field docs for a list of reserved trait names. userId required; optional if anonymousID is set instead String Unique identifier for the user in your database.\n\n  A userId or an anonymousId is required.\n\n  See the Identities docs for more details. Note that these traits coming in from your source events are called custom traits . Example Here’s a complete example of an Identify call: { \"anonymousId\" : \"507f191e810c19729de860ea\" , \"channel\" : \"browser\" , \"context\" : { \"ip\" : \"8.8.8.8\" , \"userAgent\" : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.115 Safari/537.36\" }, \"integrations\" : { \"All\" : false , \"Mixpanel\" : true , \"Salesforce\" : true }, \"messageId\" : \"022bb90c-bbac-11e4-8dfc-aa07a5b093db\" , \"receivedAt\" : \"2015-02-23T22:28:55.387Z\" , \"sentAt\" : \"2015-02-23T22:28:55.111Z\" , \"timestamp\" : \"2015-02-23T22:28:55.111Z\" , \"traits\" : { \"name\" : \"Peter Gibbons\" , \"email\" : \"peter@example.com\" , \"plan\" : \"premium\" , \"logins\" : 5 , \"address\" : { \"street\" : \"6th St\" , \"city\" : \"San Francisco\" , \"state\" : \"CA\" , \"postalCode\" : \"94103\" , \"country\" : \"USA\" } }, \"type\" : \"identify\" , \"userId\" : \"97980cfea0067\" , \"version\" : \"1.1\" } Create your own Identify call Use the following interactive code pen to see what your Identify calls would look like with user-provided information: Sample Identify Name: Please enter your name. Email: Please enter a valid email address. Plan: Please enter a valid Plan name. Logins: Please enter only numbers in the 'Logins' field. Street: Please enter a valid street address, including the street name and number. City: Please enter a valid city name in the 'City' field. State: Please enter a valid two-letter state code in all caps, like 'CA' for California. Zip Code: Please enter a valid five-digit zip code. Country: Please enter a two-letter country code in all caps, like 'US' for United States. Sample Identify Call Sample output goes here! Identities The Identify call specifies a customer identity that you can reference across the customer’s whole lifetime. Every Identify call must have a User ID or an Anonymous ID , depending on how much you know about the user in question. Anonymous ID There are certain cases where you don’t actually know who the user is according to your database, but you still want to be able to tie them to traits, events, or page views. For example, you may not know who a user is when tracking newsletter signups or anonymous page views. In these cases, you should use an Anonymous ID. The Anonymous ID can be any pseudo-unique identifier. For example, on your servers you can use a session id. If you don’t have any readily available identifier, you can always generate a new random one — Segment recommends UUIDv4 format . Segment’s browser and mobile libraries automatically use Anonymous IDs to keep track of users as they navigate around your website or app, so you don’t need to worry about them when using those libraries. Here’s an example of a JavaScript event for an anonymous user: analytics . identify ({ subscriptionStatus : ' inactive ' }); User ID User IDs are a more permanent and robust identifier, like a database ID. Since these IDs are consistent across a customer’s lifetime, Identify calls should include a User ID as often as possible. A User ID is usually the unique identifier that you recognize a user by in your own database. For example, if you’re using MongoDB, User IDs might look something like this: 507f191e810c19729de860ea . Segment recommends using database IDs, in uuidv4 format , instead of email addresses or usernames because database IDs never change. That guarantees that even if the user changes their email address, you can still recognize them as the same person in all of your analytics tools, and you’ll be able to correlate analytics data with your own internal database. Instead of using an email address or a username as a User ID, send them along as custom traits . Custom traits Custom traits are pieces of information you know about a user that are included in an Identify call. These could be demographics like age or gender , account-specific like plan , or even things like whether a user has seen a particular A/B test variation. Segment has reserved some custom traits that have semantic meanings for users, and will handle them in special ways. For example, Segment always expects email to be a string of the user’s email address. Segment sends this on to destinations like Mailchimp that require an email address for their tracking. Only use reserved traits for their intended meaning. Reserved custom traits Segment has standardized: Trait Type Description address Object Street address of a user optionally containing: city , country , postalCode , state , or street age Number Age of a user avatar String URL to an avatar image for the user birthday Date User’s birthday company Object Company the user represents, optionally containing: name (String), id (String or Number), industry (String), employee_count (Number) or plan (String) createdAt Date Date the user’s account was first created. Segment recommends using ISO-8601 date strings. description String Description of the user email String Email address of a user firstName String First name of a user gender String Gender of a user id String Unique ID in your database for a user lastName String Last name of a user name String Full name of a user. If you only pass a first and last name Segment automatically fills in the full name for you. phone String Phone number of a user title String Title of a user, usually related to their position at a specific company. Example: “VP of Engineering” username String User’s username. This should be unique to each user, like the usernames of Twitter or GitHub. website String Website of a user You might be used to some destinations recognizing special traits by slightly different names. For example, Mixpanel recognizes a $created trait when the user’s account was first created, while Intercom recognizes the same trait as created_at instead. Segment attempts to handle all the destination-specific conversions for you automatically. If you need help understanding if a specific field will be converted to a destination, take a look at Segment’s open source integration code , view the destination’s documentation, or contact Segment support . You can pass these reserved traits using camelCase or snake_case , so in JavaScript you can match the rest of your camelCase code by sending firstName , while in Ruby you can match your snake-case code by sending first_name . That way the API never seems alien to your code base. Keep in mind that not all destinations support these reserved traits, so sending these traits in camelCase and snake_case can result in two sets of traits in other destinations. This page was last modified: 23 Apr 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Example Identities Custom traits Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Spec: Identify"
      },
      {
        "level": 2,
        "text": "Example"
      },
      {
        "level": 3,
        "text": "Create your own Identify call"
      },
      {
        "level": 2,
        "text": "Identities"
      },
      {
        "level": 3,
        "text": "Anonymous ID"
      },
      {
        "level": 3,
        "text": "User ID"
      },
      {
        "level": 2,
        "text": "Custom traits"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/content/sms/template/",
    "title": " SMS Template | Segment Documentation",
    "content": "Home / Engage / Content / Sms / SMS Template SMS Template Free x Team x Business ✓ + Engage Premier ✓ ? Engage Premier requires a Business tier account and includes Engage Foundations and Unify. See the available plans , or contact Support . On this page SMS template types Build an SMS message template Test your SMS template Personalize with merge tags Configure Link Shortening Working with SMS message templates SMS best practices and limitations Next steps Engage Premier entered an End of Sale (EOS) period effective  June 10, 2024. Existing Segment customers will continue to have access and support to Engage Premier until an end-of-life (EOL) date is announced. We recommend exploring the following pages in preparation of a migration or future MCM needs: Twilio Marketing Campaigns Preferred ISV Partners: Airship Blog Bloomreach Blog Braze Blog Insider Blog Klaviyo Blog Twilio Engage Foundations Documentation Use Twilio Engage to build SMS message templates to include throughout your marketing campaigns. You can build an SMS template and include personalized content in messages based on user profile traits. Once you build the SMS, Twilio Engage saves the template for you to preview, maintain, and reuse. Use personalized SMS messages to connect with users in real-time, as they reach a specific step in a journey. SMS template types You can choose between two SMS template types: Media , which contains media and text content Text , which contains text content of up to 1600 characters Build an SMS message template You must first configure your SMS service with Twilio to build an SMS template in Engage. Visit the onboarding steps for more on how to connect a Twilio account. Follow these steps to build an SMS template: Navigate to Engage > Content and click Create template . Select SMS , then click Configure . Enter a template name and select your template’s language. Select your template’s content type, then click Next . For text templates, enter your message’s text in the Body field and add any desired merge tags . For media templates, enter your message’s text in the Body field, add the media URL, then add any desired merge tags. Media templates support PNG, JPEG, and GIF files. Include an opt-out message in the body of your text. For example, “Reply STOP to unsubscribe.” See SMS Best Practices for more information. Once you’ve finished adding your template’s content, click Save . Segment confirms that your template was saved. Use the SMS Templates screen to preview and update existing SMS message templates. Engage content validation For all content editors in Engage, you’ll see alerts for any issues in your template, such as invalid profile traits or incorrect liquid syntax . Engage both flags template issue(s), and displays recommended next steps. While you can save these templates, you must fix any issues before using them in Engage campaigns. Test your SMS template Send a test SMS message before you include it as a step in your Journey. After you build your SMS template, click Test SMS . If your template has profile traits, enter a trait value for the test SMS. This ensures that your merge tags work as expected. Empty fields show the default value that you’ve assigned. For example, loyal customer would be the default for the following merge tag: {{profile.traits.first_name | default: \"loyal customer\"}} . If there’s no default value, the field will be blank. Enter recipient phone numbers for the test message. Profiles that you send test messages to must have a userId in Segment. Click Send test SMS . You can also test SMS templates directly within Journeys before you send them. Personalize with merge tags Personalize SMS content in Engage using profile traits as merge tags in your messages. To personalize an SMS, click Merge Tags in the SMS builder and select the profile traits to include in your message. Engage inserts the selected traits inside merge tags based on cursor placement in the message. This allows you to personalize each SMS you send to recipients. You can also use liquid templating to create dynamic content in the SMS editor. To learn more about profile traits, visit Segment’s Computed Traits and SQL Traits documentation. Configure Link Shortening Use Link Shortening to send shorter, more manageable link URLs in your Engage SMS campaigns. Configure Link Shortening in your Twilio Console in six steps: Set up an Organization Register Domains Add Domain Name System (DNS) records Generate a TLS certificate Upload your TLS certificate Configure fallback and callback URLs (Optional) Once you’ve configured Link Shortening, Twilio automatically shortens the link URLs for recipients of your SMS messages. Link shortening occurs during the message sending process, so shortened links don’t appear in the message editor. Link Shortening is only available for SMS messages. Working with SMS message templates You can edit, duplicate, and delete SMS templates within your Engage workspace. Edit an SMS message template To edit an SMS template: Navigate to Engage > Content . Select the … icon next to template you want to edit. Click Edit . From the template’s overview page, select Edit or Settings . Edit your template, then click Update Template to save your changes. Duplicate an SMS message template To duplicate an SMS template: Navigate to Engage > Content . Select the … icon next to template you want to duplicate. Click Duplicate . From the Duplicate Template popup, click Duplicate . After you duplicate a template, you can edit it from the Templates page. Delete an SMS message template To delete an SMS template: Navigate to Engage > Content . Select the … icon next to template you want to delete. Click Delete . From the Confirm Template Deletion popup, click Delete Template . SMS best practices and limitations Include an SMS opt-out message When you build an SMS, include an opt-out message in the body of your text that informs recipients they can unsubscribe from a message channel. When an SMS recipient replies “Stop” to an SMS, they’ll receive an opt-out confirmation, and Engage updates their phone number subscription status. Visit the User Subscription States documentation to learn more about user subscriptions in Engage. SMS character limit Note that there’s a 1,600 character count limit for SMS messages.\nVisit Twilio’s SMS Character Limit documentation for more information. Next steps Use the Templates screen in Twilio Engage to build personalized email templates . This page was last modified: 15 Jul 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page SMS template types Build an SMS message template Test your SMS template Personalize with merge tags Configure Link Shortening Working with SMS message templates SMS best practices and limitations Next steps Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "SMS Template"
      },
      {
        "level": 2,
        "text": "SMS template types"
      },
      {
        "level": 2,
        "text": "Build an SMS message template"
      },
      {
        "level": 2,
        "text": "Test your SMS template"
      },
      {
        "level": 2,
        "text": "Personalize with merge tags"
      },
      {
        "level": 2,
        "text": "Configure Link Shortening"
      },
      {
        "level": 2,
        "text": "Working with SMS message templates"
      },
      {
        "level": 3,
        "text": "Edit an SMS message template"
      },
      {
        "level": 3,
        "text": "Duplicate an SMS message template"
      },
      {
        "level": 3,
        "text": "Delete an SMS message template"
      },
      {
        "level": 2,
        "text": "SMS best practices and limitations"
      },
      {
        "level": 3,
        "text": "Include an SMS opt-out message"
      },
      {
        "level": 3,
        "text": "SMS character limit"
      },
      {
        "level": 2,
        "text": "Next steps"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/functions/insert-functions/",
    "title": " Destination Insert Functions | Segment Documentation",
    "content": "Home / Connections / Functions / Destination Insert Functions Destination Insert Functions On this page Create destination insert functions Code the destination insert function Runtime and dependencies Insert Functions and Actions destinations Create settings and secrets Test the destination insert function Save and deploy the destination insert function Enable the destination insert function Batching the destination insert function Caching in destination insert functions Managing destination insert functions Destination insert functions FAQs Use Destination Insert Functions to enrich, transform, or filter your data before it reaches downstream destinations. Implement advanced data computation : Write custom computation, operations, and business logic on streaming data that you send to downstream destinations. Enrich your data : Use destination insert functions with Segment’s Profile API or third party sources to add additional context to your data and create personalized customer experiences. Support data compliance : Use destination insert functions to support data masking, encryption, decryption, improved PII data handling, and tokenization. Customize filtration for your destinations : Create custom logic with nested if-else statements, regex, custom business rules, and more to filter event data. Destination Insert Functions are not compatible with IP Allowlisting For more information, see the IP Allowlisting documentation. Create destination insert functions There are two ways you can access destination insert functions from your Segment space: From the Connections catalog . From the Destinations tab. Using the catalog To create an insert function from Segment’s catalog: Navigate to Connections > Catalog > Functions and click New Function . From the Select Type screen, select Insert and click Next: Build Function . Write and test your function code. Manually enter a sample event and click Run to test. Click Next: Configure & Create to add a function name, description, and logo. Click Create Function to create your insert function. You’ll see the insert function displayed in the Functions tab. For data to flow to your downstream destinations, you’ll need to connect your insert function to a destination: Select the insert function you’d like to connect. From the side pane, you can edit, delete, and connect the insert function. Click Connect a destination . Select the destination you’d like to connect to and click Connect to destination . Storage destinations are not compatible with Destination Insert Functions You cannot connect an Insert Function to a storage destination at this time. Using the Destinations tab To access insert functions through the Destinations tab: Navigate to Connections > Destinations . Select your destination. Select Functions and then select your insert function. Use this page to edit and manage insert functions in your workspace. You can also use this page to enable destination insert functions in your workspace. Code the destination insert function To prevent “Unsupported Event Type” errors, ensure your insert function handles all event types (page, track, identify, alias, group) that are expected to be sent to the destination. It is highly recommended to test the function with each event type to confirm they are being handled as expected. Segment invokes a separate part of the function (called a “handler”) for each event type that you send to your destination insert function. If you’ve configured a destination filter and the event doesn’t pass the filter, then your function isn’t invoked for that event as Segment applies destination filters before insert functions. The same is true for the integrations object ). If an event is configured with the integrations object not to go to a particular destination, then the insert function connected to that destination won’t be invoked. The default source code template includes handlers for all event types. You don’t need to implement all of them - just use the ones you need, and skip the ones you don’t. For event types that you want to send through the destination, return the event in the respective event handlers. Removing the handler for a specific event type results in blocking the events of that type from arriving at their destination. To keep an event type as is but still send it downstream, add a return event inside the event type handler statement. Insert functions can define handlers for each message type in the Segment spec : onIdentify onTrack onPage onScreen onGroup onAlias onDelete onBatch Each of the functions above accepts two arguments: event - Segment event object, where fields and values depend on the event type. For example, in “Identify” events, Segment formats the object to match the Identify spec . settings - Set of settings for this function. The example below shows a function that listens for “Track” events, and sends some details about them to an external service. async function onTrack ( event ) { await fetch ( ' https://example-service.com/api ' , { method : ' POST ' , headers : { ' Content-Type ' : ' application/json ' }, body : JSON . stringify ({ event_name : event . event , event_properties : event . properties , timestamp : event . timestamp }) }) return event ; } To change which event type the handler listens to, you can rename it to the name of the message type. For example, if you rename this function onIdentify , it listens for “Identify” events instead. To ensure the Destination processes an event payload modified by the function, return the event object at the handler’s end. Functions’ runtime includes a fetch() polyfill using a node-fetch package. Check out the node-fetch documentation for usage examples. Errors and error handling Segment considers a function’s execution successful if it finishes without error. You can throw an error to create a failure on purpose. Use these errors to validate event data before processing it to ensure the function works as expected. You can throw the following pre-defined error types to indicate that the function ran as expected, but the data was not deliverable: EventNotSupported InvalidEventPayload ValidationError RetryError DropEvent The examples show basic uses of these error types. async function onGroup ( event ) { if ( ! event . traits . company ) { throw new InvalidEventPayload ( ' Company name is required ' ) } } async function onPage ( event ) { if ( ! event . properties . pageName ) { throw new ValidationError ( ' Page name is required ' ) } } async function onAlias ( event ) { throw new EventNotSupported ( ' Alias event is not supported ' ) } async function onTrack ( event ) { let res try { res = await fetch ( ' http://example-service.com/api ' , { method : ' POST ' , headers : { ' Content-Type ' : ' application/json ' }, body : JSON . stringify ({ event }) }) return event ; } catch ( err ) { // Retry on connection error throw new RetryError ( err . message ) } if ( res . status >= 500 || res . status === 429 ) { // Retry on 5xx and 429s (ratelimits) throw new RetryError ( `HTTP Status ${ res . status } ` ) } } async function onIdentify ( event ) { if ( event . traits . companyName ) { // Drop Event | Do NOT forward event to destination throw new DropEvent ( ' Company name is required ' ) } return event ; } If you don’t supply a function for an event type, Segment throws an EventNotSupported error by default. You can read more about error handling below. Runtime and dependencies On March 26, 2024, Segment is upgrading the Functions runtime environment to Node.js v18, which is the current long-term support (LTS) release. This upgrade keeps your runtime current with industry standards. Based on the AWS Lambda and Node.js support schedule, Node.js v16 is no longer in Maintenance LTS . Production applications should only use releases of Node.js that are in Active LTS or Maintenance LTS . All new functions will use Node.js v18 starting March 26, 2024. For existing functions, this change automatically occurs as you update and deploy an existing function. Segment recommends that you check your function post-deployment to ensure everything’s working. Your function may face issues due to the change in sytax between different Node.js versions and dependency compatibility. Limited time opt-out option If you need more time to prepare, you can opt out of the update before March 19, 2024. Note that if you opt out: - The existing functions will continue working on Node.js v16. - You won’t be able to create new functions after July 15, 2024. - You won’t be able to update existing functions after August 15, 2024. - You won’t receive future bug fixes, enhancements, and dependency updates to the functions runtime. Contact Segment to opt-out or with any questions. Node.js 18 Segment strongly recommends updating to Node.js v18 to benefit from future runtime updates, the latest security, and performance improvements. Functions do not currently support importing dependencies, but you can contact Segment Support to request that one be added. The following dependencies are installed in the function environment by default. atob v2.1.2 exposed as atob aws-sdk v2.488.0 exposed as AWS btoa v1.2.1 exposed as btoa fetch-retry exposed as fetchretrylib.fetchretry form-data v2.4.0 exposed as FormData @google-cloud/automl v2.2.0 exposed as google.cloud.automl @google-cloud/bigquery v5.3.0 exposed as google.cloud.bigquery @google-cloud/datastore v6.2.0 exposed as google.cloud.datastore @google-cloud/firestore v4.4.0 exposed as google.cloud.firestore @google-cloud/functions v1.1.0 exposed as google.cloud.functions @google-cloud/pubsub v2.6.0 exposed as google.cloud.pubsub @google-cloud/storage v5.3.0 exposed as google.cloud.storage @google-cloud/tasks v2.6.0 exposed as google.cloud.tasks hubspot-api-nodejs exposed as hubspotlib.hubspot jsforce v1.11.0 exposed as jsforce jsonwebtoken v8.5.1 exposed as jsonwebtoken libphonenumber-js exposed as libphonenumberjslib.libphonenumberjs lodash v4.17.19 exposed as _ mailchimp marketing exposed as mailchimplib.mailchimp mailjet exposed as const mailJet = nodemailjet.nodemailjet; moment-timezone v0.5.31 exposed as moment node-fetch v2.6.0 exposed as fetch oauth v0.9.15 exposed as OAuth @sendgrid/client v7.4.7 exposed as sendgrid.client @sendgrid/mail v7.4.7 exposed as sendgrid.mail skyflow exposed as skyflowlib.skyflow stripe v8.115.0 exposed as stripe twilio v3.68.0 exposed as twilio uuidv5 v1.0.0 exposed as uuidv5.uuidv5 winston v2.4.6 exposed as const winston = winstonlib.winston xml v1.0.1 exposed as xml xml2js v0.4.23 exposed as xml2js zlib v1.0.5 exposed as zlib.zlib uuidv5 is exposed as an object. Use uuidv5.uuidv5 to access its functions. For example: async function onRequest ( request , settings ) { uuidv5 = uuidv5 . uuidv5 ; console . log ( typeof uuidv5 ); //Generate a UUID in the default URL namespace var urlUUID = uuidv5 ( ' url ' , ' http://google/com/page ' ); console . log ( urlUUID ); //Default DNS namespace var dnsUUID = uuidv5 ( ' dns ' , ' google.com ' ); console . log ( dnsUUID ); } zlib ’s asynchronous methods inflate and deflate must be used with async or await . For example: zlib = zlib . zlib ; // Required to access zlib objects and associated functions async function onRequest ( request , settings ) { const body = request . json (); const input = ' something ' ; // Calling inflateSync method var deflated = zlib . deflateSync ( input ); console . log ( deflated . toString ( ' base64 ' )); // Calling inflateSync method var inflated = zlib . inflateSync ( new Buffer . from ( deflated )). toString (); console . log ( inflated ); console . log ( ' Done ' ); } The following Node.js modules are available: crypto Node.js module exposed as crypto . https Node.js module exposed as https . Other built-in Node.js modules aren’t available. For more information on using the aws-sdk module, see how to set up functions for calling AWS APIs . Caching Basic cache storage is available through the cache object, which has the following methods defined: cache.load(key: string, ttl: number, fn: async () => any): Promise<any> Obtains a cached value for the provided key , invoking the callback if the value is missing or has expired. The ttl is the maximum duration in milliseconds the value can be cached. If omitted or set to -1 , the value will have no expiry. cache.delete(key: string): void Immediately remove the value associated with the key . Some important notes about the cache: When testing functions in the code editor, the cache will be empty because each test temporarily deploys a new instance of the function. Values in the cache are not shared between concurrently-running function instances; they are process-local which means that high-volume functions will have many separate caches. Values may be expunged at any time, even before the configured TTL is reached. This can happen due to memory pressure or normal scaling activity. Minimizing the size of cached values can improve your hit/miss ratio. Functions that receive a low volume of traffic may be temporarily suspended, during which their caches will be emptied. In general, caches are best used for high-volume functions and with long TTLs.\nThe following example gets a JSON value through the cache, only invoking the callback as needed: const ttl = 5 * 60 * 1000 // 5 minutes const val = await cache . load ( \" mycachekey \" , ttl , async () => { const res = await fetch ( \" http://echo.jsontest.com/key/value/one/two \" ) const data = await res . json () return data }) Insert Functions and Actions destinations A payload must come into the pipeline with the attributes that allow it to match your mapping triggers. You can’t use an Insert Function to change the event to match your mapping triggers. If an event comes into an Actions destination and already matches a mapping trigger, that mapping subscription will fire. If a payload doesn’t come to the Actions destination matching a mapping trigger, even if an Insert Function is meant to alter the event to allow it to match a trigger, it won’t fire that mapping subscription. Segment sees the mapping trigger first in the pipeline, so a payload won’t make it to the Insert Function at all if it doesn’t come into the pipeline matching a mapping trigger. Unlike Source Functions and Destination Functions, which return multiple events, an Insert Function only returns one event. When the Insert Function receives an event, it sends the event to be handled by its configured mappings. If you would like multiple mappings triggered by the same event : Create different types of mappings (Identify, Track, Page, etc) or multiple mappings of the same type. Configure the mapping’s trigger conditions to look for that event name/type or other available field within the payload. Configure the mapped fields to send different data. You can also configure the Insert Function to add additional data to the event’s payload before it’s handled by the mappings and configure the mapping’s available fields to reference the payload’s available fields. You may want to consider the context object’s available fields when adding new data to the event’s payload. Create settings and secrets Settings allow you to pass configurable variables to your function, which is the best way to pass sensitive information such as security tokens. For example, you might use settings as placeholders to use information such as an API endpoint and API key. This way, you can use the same code with different settings for different purposes. When you deploy a function in your workspace, you are prompted to fill out these settings to configure the function. First, add a setting in Settings tab in the code editor: Click Add Setting to add your new setting. You can configure the details about this setting, which change how it’s displayed to anyone using your function: Label - Name of the setting, which users see when configuring the function. Name - Auto-generated name of the setting to use in function’s source code. Type - Type of the setting’s value. Description - Optional description, which appears below the setting name. Required - Enable this to ensure that the setting cannot be saved without a value. Encrypted - Enable to encrypt the value of this setting. Use this setting for sensitive data, like API keys. As you change the values, a preview to the right updates to show how your setting will look and work. Click Add Setting to save the new setting. Once you save a setting, it appears in the Settings tab for the function. You can edit or delete settings from this tab. Next, fill out this setting’s value in the Test tab, so you can run the function and verify that the correct setting value is passed. (This value is only for testing your function.) Now that you’ve configured a setting and entered a test value, you can add code to read its value and run the function, as in the example below: async function onTrack ( request , settings ) { const apiKey = settings . apiKey //=> \"super_secret_string\" } When you deploy your destination insert function in your workspace, you fill out the settings on the destination configuration page, similar to how you would configure a normal destination. Test the destination insert function You can manually test your code from the functions editor: From the Test tab, click customize the event yourself and manually input your own JSON payload. If your test fails, you can check the error details and logs in the Output section. Error messages display errors surfaced from your function. Logs display any messages to console.log() from the function. The Event Tester won’t make use of an Insert Function, show how an Insert Function impacts your data, or send data downstream through the Insert Function pipeline. The Event Tester is not impacted by an Insert Function at all. Use the Function tester rather than the Event Tester to see how your Insert Function impacts your data. Save and deploy the destination insert function Once you finish building your insert function, click Next: Configure & Create to name it, then click Create Function to save it. Once you do that, you’ll see the insert function from the Functions page in your catalog. If you’re editing an existing function, you can save changes without updating the instances of the function that are already deployed and running. You can also choose to Save & Deploy to save the changes, then choose which already-deployed functions to update with your changes. You may need additional permissions to update existing functions. Enable the destination insert function You need to enable your insert function for it to process your data. To enable your insert function: Navigate to Connections > Destinations . Select your destination, then select the Functions tab. Select the Enable Function toggle, and click Enable on the pop-out window. To prevent your insert function from processing data, toggle Enable Function off. Batching the destination insert function Batch handlers are an extension of insert functions. When you define an onBatch handler alongside the handler functions for single events (for example, onTrack or onIdentity ), you’re telling Segment that the insert function can accept and handle batches of events. Batching is available for destination and destination insert functions only. When to use batching Consider creating a batch handler if: You have a high-throughput function and want to reduce cost. When you define a batch handler, Segment invokes the function once per batch , rather than once per event. As long as the function’s execution time isn’t adversely affected, the reduction in invocations should lead to a reduction in cost. Your destination supports batching . When your downstream destination supports sending data downstream in batches you can define a batch handler to avoid throttling. Batching for functions is independent of batch size supported by the destination. Segment automatically handles batch formation for destinations. If a batched function receives too low a volume of events (under one event per second) to be worth batching, Segment may not invoke the batch handler. Define the batch handler Segment collects the events over a short period of time and combines them into a batch. The system flushes them when the batch reaches a certain number of events, or when the batch has been waiting for a specified wait time. To create a batch handler, define an onBatch function within your destination insert function. You can also use the “Default Batch” template found in the Functions editor to get started quickly. async function onBatch ( events , settings ){ // handle the batch of events return events } The onBatch handler is an optional extension. Destination insert functions must still contain single event handlers as a fallback, in cases where Segment doesn’t receive enough events to execute the batch. The handler function receives an array of events. The events can be of any supported type and a single batch may contain more than one event type. Handler functions can also receive function settings. Here is an example of what a batch can look like: [ { \"type\" : \"identify\" , \"userId\" : \"019mr8mf4r\" , \"traits\" : { \"email\" : \"jake@yahoo.com\" , \"name\" : \"Jake Peterson\" , \"age\" : 26 } }, { \"type\" : \"track\" , \"userId\" : \"019mr8mf4r\" , \"event\" : \"Song Played\" , \"properties\" : { \"name\" : \"Fallin for You\" , \"artist\" : \"Dierks Bentley\" } }, { \"type\" : \"track\" , \"userId\" : \"971mj8mk7p\" , \"event\" : \"Song Played\" , \"properties\" : { \"name\" : \"Get Right\" , \"artist\" : \"Jennifer Lopez\" } } ] Configure the event types within a batch Segment batches together any event of any type that it sees over a short period of time to increase batching efficiency and give you the flexibility to decide how batches are created. If you want to split batches by event type, you can implement this in your functions code by writing a handler. async function onBatch ( events , settings ) { // group events by type const eventsByType = {} for ( const event of events ) { if ( ! ( event . type in eventsByType )) { eventsByType [ event . type ] = [] } eventsByType [ event . type ]. push ( event ) } // concurrently process sub-batches of a specific event type const promises = Object . entries ( eventsByType ). map (([ type , events ]) => { switch ( type ) { case ' track ' : return onTrackBatch ( events , settings ) case ' identify ' : return onIdentifyBatch ( events , settings ) // ...handle other event types here... } }) try { const results = await Promise . all ( promises ); const batchResult = []. concat (... results ); // Combine arrays into a single array return batchResult ; } catch ( error ) { throw new RetryError ( error . message ); } } async function onTrackBatch ( events , settings ) { // handle a batch of track events return events } async function onIdentifyBatch ( events , settings ) { // handle a batch of identify events return events } Configure your batch parameters By default, Functions waits up to 10 seconds to form a batch of 20 events. You can increase the number of events included in each batch (up to 400 events per batch) by contacting Segment support . Segment recommends users who wish to include fewer than 20 events per batch use destination insert functions without the onBatch handler. Test the batch handler The Functions editing environment supports testing batch handlers. To test the batch handler: In the right panel of the Functions editor, click customize the event yourself to enter Manual Mode. Add events as a JSON array, with one event per element. Click Run to preview the batch handler with the specified events. The Sample Event option tests single events only. You must use Manual Mode to add more than one event so you can test batch handlers. The editor displays logs and request traces from the batch handler. The Public API Functions/Preview endpoint also supports testing batch handlers. The payload must be a batch of events as a JSON array. Handling filtering in a batch Events in a batch can be filtered out using custom logic. The filtered events will be surfaced in the Event Delivery page with reason as Filtered at insert function async function onBatch ( events , settings ) { let response = []; try { for ( const event of events ) { // some business logic to filter event. Here filtering out all the events with name `drop` if ( event . properties . name === ' drop ' ) { continue ; } // some enrichments if needed event . properties . message = \" Enriched from insert function \" ; // Enriched events are pushed to response response . push ( event ); } } catch ( error ) { console . log ( error ) throw new RetryError ( ' Failed function ' , error ); } // return a subset of transformed event return response ; } Handling batching errors Standard function error types apply to batch handlers. Segment attempts to retry the batch in the case of Timeout or Retry errors. For all other error types, Segment discards the batch. Destination insert functions error types Bad Request - Any error thrown by the function code that is not covered by the other errors. Invalid Settings - A configuration error prevented Segment from executing your code. If this error persists for more than an hour, contact Segment Support . Message Rejected - Your code threw InvalidEventPayload or ValidationError due to invalid input. Unsupported Event Type - Your code doesn’t implement a specific event type (for example, onTrack() ) or threw an EventNotSupported error. Retry - Your code threw RetryError indicating that the function should be retried. Segment only attempts to send the event to your destination insert function again if a Retry error occurs. You can view Segment’s list of Integration Error Codes for more information about what might cause an error. Destination insert functions logs If your function throws an error, execution halts immediately. Segment captures the event, any outgoing requests/responses, any logs the function might have printed, as well as the error itself. Segment then displays the captured error information in the Event Delivery page for your destination. You can use this information to find and fix unexpected errors. You can throw an error or a custom error and you can also add helpful context in logs using the console API . For example: async function onTrack ( event , settings ) { const userId = event . userId console . log ( ' User ID is ' , userId ) if ( typeof userId !== ' string ' || userId . length < 8 ) { throw new ValidationError ( ' User ID is invalid ' ) } console . log ( ' User ID is valid ' ) } Don’t log sensitive data, such as personally-identifying information (PII), authentication tokens, or other secrets. Avoid logging entire request/response payloads. The Function Logs tab may be visible to other workspace members if they have the necessary permissions. Caching in destination insert functions Functions execute only in response to incoming data, but the environments that functions run in are generally long-running. Because of this, you can use global variables to cache small amounts of information between invocations. For example, you can reduce the number of access tokens you generate by caching a token, and regenerating it only after it expires. Segment cannot make any guarantees about the longevity of environments, but by using this strategy, you can improve the performance and reliability of your Functions by reducing the need for redundant API requests. This example code fetches an access token from an external API and refreshes it every hour: const TOKEN_EXPIRE_MS = 60 * 60 * 1000 // 1 hour let token = null async function getAccessToken () { const now = new Date (). getTime () if ( ! token || now - token . ts > TOKEN_EXPIRE_MS ) { const resp = await fetch ( ' https://example.com/tokens ' , { method : ' POST ' }). then ( resp => resp . json ()) token = { ts : now , value : resp . token } } return token . value } Managing destination insert functions Functions permissions Functions have specific roles which can be used for access management in your Segment workspace. Access to functions is controlled by two permissions roles : Functions Admin: Create, edit, and delete all functions, or a subset of specified functions. Functions Read-only: View all functions, or a subset of specified functions. You also need additional Source Admin permissions to enable source functions, connect destination functions to a source, or to deploy changes to existing functions. Editing and deleting functions If you are a Workspace Owner or Functions Admin , you can manage your function from the Functions page. Destination insert functions FAQs Can I see who made changes to a function? Yes, Functions access is logged in the Audit Trail , so user activity related to functions appears in the logs. Does Segment retry failed function invocations? Yes, Segment retries invocations that throw RetryError or Timeout errors (temporary errors only). Segment’s internal system retries failed functions API calls for four hours with a randomized exponential backoff after each attempt. This substantially improves delivery rates. Retries work the same for both functions and cloud-mode destinations in Segment. Are events guaranteed to send data in order? No, Segment can’t guarantee the order in which the events are delivered to an endpoint. Do I Need to specify an endpoint for my Insert function? No, specifying an endpoint is not always required for insert functions. If your function is designed to transform or filter data internally—such as adding new properties to events or filtering based on existing properties—you won’t need to specify an external endpoint. However, if your function aims to enrich event data by fetching additional information from an external service, then you must specify the endpoint. This would be the URL of the external service’s API where the enriched or captured data is sent. Can I use Insert Functions with Device Mode destinations? No, Destination Insert Functions are currently available for use with Cloud Mode (server-side) destinations only. Segment is in the early phases of exploration and discovery for supporting customer web plugins for custom Device Mode destinations and other use cases, but this is unsupported today. Can I use Insert Functions with Storage destinations? Insert Functions are only supported by Cloud Mode (server-side) destinations and aren’t compatible with Storage destinations. Can I connect an insert function to multiple destinations? Yes, you can connect an insert function to multiple destinations. Can I connect multiple insert functions to one destination? No, you can only connect one insert function to a destination. Can I have destination filters and a destination insert function in the same connection? Yes, you can have both destination filters and destination insert functions in the same connection. Are insert functions invoked before or after Destination Filters are applied? Segment’s data pipeline applies Destination Filters before invoking Insert Functions. Why am I receiving a 500 Internal Error when saving the same of the destination insert function? There is an 120-Character limit for the insert function display name. Why does the Event Delivery tab show “Unsupported Event Type” errors for events supported by the destination after I enabled an insert function? This error occurs because your insert function code might not be handling all event types (Page, Track, Identify, Alias, Group) that your destination supports. When these unlisted events pass through the function, they are rejected with the “Unsupported Event Type” error. To resolve this, verify your insert function includes handlers for all expected event types and returns the event object for each. Here’s an example of how you can structure your insert function to handle all event types: async function onTrack(event, settings) {\n    //Return event to handle page event OR Your existing code for track event\n    return event;\n}\n\nasync function onPage(event, settings) {\n    //Return event to handle page event OR Your existing code for track event\n    return event;\n}\n\nasync function onIdentify(event, settings) {\n    //Return event to handle page event OR Your existing code for track event\n    return event;\n}\n\nasync function onAlias(event, settings) {\n    //Return event to handle page event OR Your existing code for track event\n    return event;\n}\n\nasync function onGroup(event, settings) {\n  //Return event to handle page event OR Your existing code for track event\n    return event;\n}\n\n// Ensure that all expected event types are included in your function By including handlers for all the major event types, you ensure that all supported events are processed correctly, preventing the “Unsupported Event Type” error. Always test your updated code before implementing it in production. What is the maximum data size that can be displayed in console.logs() when testing a Function? The test function interface has a 4KB console logging limit. Outputs surpassing this limit won’t be visible in the user interface. This page was last modified: 18 Dec 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Create destination insert functions Code the destination insert function Runtime and dependencies Insert Functions and Actions destinations Create settings and secrets Test the destination insert function Save and deploy the destination insert function Enable the destination insert function Batching the destination insert function Caching in destination insert functions Managing destination insert functions Destination insert functions FAQs Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Destination Insert Functions"
      },
      {
        "level": 2,
        "text": "Create destination insert functions"
      },
      {
        "level": 3,
        "text": "Using the catalog"
      },
      {
        "level": 3,
        "text": "Using the Destinations tab"
      },
      {
        "level": 2,
        "text": "Code the destination insert function"
      },
      {
        "level": 3,
        "text": "Errors and error handling"
      },
      {
        "level": 2,
        "text": "Runtime and dependencies"
      },
      {
        "level": 3,
        "text": "Caching"
      },
      {
        "level": 2,
        "text": "Insert Functions and Actions destinations"
      },
      {
        "level": 2,
        "text": "Create settings and secrets"
      },
      {
        "level": 2,
        "text": "Test the destination insert function"
      },
      {
        "level": 2,
        "text": "Save and deploy the destination insert function"
      },
      {
        "level": 2,
        "text": "Enable the destination insert function"
      },
      {
        "level": 2,
        "text": "Batching the destination insert function"
      },
      {
        "level": 3,
        "text": "When to use batching"
      },
      {
        "level": 3,
        "text": "Define the batch handler"
      },
      {
        "level": 3,
        "text": "Configure the event types within a batch"
      },
      {
        "level": 3,
        "text": "Configure your batch parameters"
      },
      {
        "level": 3,
        "text": "Test the batch handler"
      },
      {
        "level": 3,
        "text": "Handling filtering in a batch"
      },
      {
        "level": 3,
        "text": "Handling batching errors"
      },
      {
        "level": 3,
        "text": "Destination insert functions error types"
      },
      {
        "level": 3,
        "text": "Destination insert functions logs"
      },
      {
        "level": 2,
        "text": "Caching in destination insert functions"
      },
      {
        "level": 2,
        "text": "Managing destination insert functions"
      },
      {
        "level": 3,
        "text": "Functions permissions"
      },
      {
        "level": 3,
        "text": "Editing and deleting functions"
      },
      {
        "level": 2,
        "text": "Destination insert functions FAQs"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/segment-app/iam/mfa/",
    "title": " Multi-Factor Authentication (MFA) | Segment Documentation",
    "content": "Home / Segment app / Iam / Multi-Factor Authentication (MFA) Multi-Factor Authentication (MFA) Free ✓ Team ✓ Business ✓ Add-on x ? MFA is available to all Segment plans, but cannot be used with SSO. See the available plans , or contact Support . On this page Enabling MFA Recovering MFA Multi-factor Authentication (MFA) provides an additional layer of security when logging into your Segment account. When MFA is enabled, users must enter their username and password, and a one-time use code. Users can either enable MFA for their own account, or workspace owners can require that all users in a workspace use MFA. These security settings are available in the workspace from the “Advanced Settings” section. You can configure your Segment workspace to send a text message code (U.S. and Canada only), or use an authentication app to generate a time-based token (for example Google Authenticator , 1Password , or Authy ). You can also log in using a recovery code in case you don’t have your MFA device available. When you configure MFA, be sure to save your recovery code in safe place so you can access your Segment account in the event you lose your MFA device. We highly recommend that you choose a strong password and also enable MFA for the email account that you use to log into Segment. If someone is able to gain access to your email, they will be able to access your Segment account even if your Segment account has MFA enabled. Who can use MFA? MFA is available to all Segment customers that are not logged in using SSO . If your company uses SSO to sign in to Segment, you should enable MFA at the SSO provider. Contact your company’s IT team if you have questions about your company’s SSO configuration. Enabling MFA Log into Segment and go to your MFA Settings page. Click either Authenticator App or Text Message and follow the instructions to set up MFA. Once MFA is enabled, Segment prompts you for one of these methods every time you log in. Recovering MFA Your recovery code can be used bypass in the event you do not have your MFA device. If you no longer have access to your recovery code, you can choose to send a recovery code to your email to re-access your Account. Enter your username and password on the login screen. Click the authenticating a different way link. Click Recovery Code . Click Send recovery code to my email . This page was last modified: 03 Aug 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Enabling MFA Recovering MFA Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Multi-Factor Authentication (MFA)"
      },
      {
        "level": 3,
        "text": "Who can use MFA?"
      },
      {
        "level": 2,
        "text": "Enabling MFA"
      },
      {
        "level": 2,
        "text": "Recovering MFA"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/privacy/portal/",
    "title": " Privacy Portal | Segment Documentation",
    "content": "Home / Privacy / Privacy Portal Privacy Portal Free ✓ Team ✓ Business ✓ Add-on x ? Privacy Portal is available for the listed account plans only. See the available plans , or contact Support . On this page Privacy Detection Privacy Inbox Privacy Inventory When preparing for new privacy regulations (like HIPAA, the GDPR, or the CCPA), the\nbest practice is to create a comprehensive data inventory which includes details\nabout what personal information you collect, where you collect it from, where\nyou store the data, and who has access to it. The Privacy Portal helps automate\nthis process for the data you collect with Segment. When you use Segment as the single point of collection for your customer data, you can use the Privacy Portal to: Automatically detect and classify your customer data to create a dynamic data inventory Monitor changes to your inventory with real-time alerts Enforce your company’s data privacy policies with standard privacy controls Streamline regulatory compliance with tools for user deletion and suppression Privacy Portal features are available to all Segment workspaces, however only workspace owners can access the Privacy Portal. Privacy Detection The Detection page in the Privacy Portal is where you can find out more about\nexactly how data is being detected and classified in your workspace. You can\nthink of it as the brain behind the entire Privacy Portal, filled with the logic\nthat detects and classifies the data in the first place. On this page, you can also modify your Detection settings and tell Segment how you want us to match data , so that it is meets your unique business needs. Default PII Matchers Out of the box, the Privacy Portal contains matchers for the most common PII\nfields. These matchers scan data coming from your Sources for PII based on both\nexact-matching (looking for an exact match, such as a field name) and\nfuzzy-matching (looking for both exact matches, and any values which are\nsimilar). In this section of Segment’s Privacy Portal, you can see the fields we match\nagainst by default. The display lists whether we match on the key (for example\nthe label “CCN”) or value (for example, the payload 123-456-7890) in the Matches On column. You can also see how we classify these matchers by\ndefault in the Default Classification column. Below is a full list of automatically detected restricted fields. Matcher Classification social security number red password red visa red veteran red disability red credit card red passport red token red race yellow birthdate yellow phone yellow address yellow gender yellow ethnicity yellow citizenship yellow name yellow street yellow city yellow zipcode yellow email yellow certificate yellow license yellow identification yellow serial yellow ip yellow photo yellow salary yellow religion yellow email yellow mac yellow sex yellow gender yellow sexual orientation yellow medication yellow allergy yellow condition yellow diagnosis yellow procedure yellow When Segment detects data that meets the criteria for one of the default\nmatchers (in the list above) in properties in your Web, Mobile, Server, or Cloud\nEvent Sources, we display it in the Privacy Portal Inbox . Default PII matchers are currently uneditable. If you want to change the behavior of a default matcher, you can create a custom PII matcher that replicates and overwrites the default matcher. Custom PII Matchers This is where you can create your very own matchers to tell Segment what to scan\nfor in your workspace. You can use this feature to detect properties that are\nunique to your company or region, or that aren’t already handled by the default\nmatchers above. You can have up to 100 custom matchers per workspace. Custom\nMatchers detect data in your Web, Mobile, Server, and Cloud Event Sources for \nfields under context , traits and properties objects, and\nthe data they detect appears in the Inbox. For example, if you have a restricted data point at your company called “SIN”\n(for “social insurance number”) you can tell Segment’s Privacy Portal how to\ntreat that property whenever it is appears in data Segment processes. To create a Custom Matcher: Click Add a Custom Matcher . Enter the Matcher Name (for example the property name, like “Social Insurance Number”). Segment matches against the Matcher Name , as well as the other context you provide in the next steps. Set the default classification: Red for highly restricted Yellow for moderately restricted Choose whether to match on a Key (for example, “SIN”, “Social Insurance Number”, “Social Insurance No.”, “SocInsNo”) or on a Value (for example. “123-456-789”, “1234567”) Select how precise the match should be, by choosing Exact or Similar match. Exact matches mean that a key matches the term exactly (for example “phone number” but never “phne number”) Similar to matches a Key that is similar to a term within a fuzzy string distance (for example “email” and “e-mail”). We built fuzzy matching using this public GitHub repository . If the score is > 0.7, then we say it’s a match. Unless the field value pattern is unique, we recommend matching on the Key. For\nexample, for Credit Card Number, it’s better to detect on Keys that look like\n“CCN” or “Credit Card Number” instead of trying to detect any values that look\nlike “1234567890”, because a 10-digit string can be found in all kinds of data\neven when it’s not an CCN. For example, the key “Product_ID” could contain a\n10-digit string, even though Product_ID does not actually contain an SSN. A\nNorth American phone number (without country code) is also ten digits. PII Access Use Access Roles to control who has access to the PII identified by your matchers. An intro to Regular expressions Custom Matchers use regular expressions (using the Golang Regex Package ) to provide you great flexibility for your matching patterns. Regular expressions (or regexes) are a way to describe to a computer a pattern\nthat we’re looking for, using a series of special symbols. For example, if we\nwant to match all Gmail emails, we’d write the following regex: @example.com This pattern matches jane@example.com , mike@example.com and so on. Regular\nexpressions can also contain special symbols. One of them is \\d and it tells\nthe computer to match a single-digit number. In that case, regular expression Number \\d would match Number 1 , Number 2 and so on. You can match multiple\ndigits by adding a plus sign ( + ) at the end: Year \\d+ . This pattern would\nmatch Year 2019 , Year 2020 , etc. If you need to match a specific word, you can type the word without any\nmodifiers. For example, a regular expression of Apple would only match strings\nthat contain Apple . You can also change it to match all Apple or Orange words, by separating the search terms with a “pipe” character, like so: Apple|Orange . Regular expressions have much more flexibility than we can describe here. Check\nout the following resources to learn more about regular expressions so you can\nbuild new custom matchers: RegExr - an online tool to experiment with regular expressions and test them RegexOne - a tutorial which takes you from regular expression basics to advanced topics Regexp Cheatsheet - a handy cheatsheet to have nearby when you’re writing regular expressions Using Synonyms Segment’s exact matching and fuzzy matching do not detect all variations in the received keys\nand for those scenarios, you can use synonyms.  For example, for the value credit card number , you can add credit card no , debit card number , debit card no , or similar variations in the synonyms section to classify those fields. Privacy Inbox The Inbox helps you keep track of new restricted data types as they are captured, quickly classify them, and build a data Inventory. Segment detects these fields by scanning data from your Web, Mobile, Server, and Cloud Event Sources to detect PII based on the default PII matchers . New properties sent into Segment appear in the Inbox in realtime. When you view the Inbox, it displays every property that was sent into Segment from Web, Mobile, Server, and Cloud Event Sources for the past 7 days. ( Object Cloud Sources and Reverse ETL Sources do not appear in the Inbox at this time.) You can click a row in the Inbox to learn more about a field and where it was collected. The expanded view shows: which events contain the field which sources are sending the field which matcher (and what type of matcher) detected the field an example code snippet containing a payload that the field appears in To streamline the classification process, Segment pre-classifies the data in the\nPrivacy Portal Inbox as Red (likely highly restricted data), Yellow (likely moderately restricted data), and Green (likely least restricted\ndata). These colors indicate how restricted the data is for your business. You\ncan also send and block data from flowing based on its color classification and\nhow restricted it is. Segment makes recommendations about how a field should be classified using\nbuilt-in PII matcher detection , however, you can always\nupdate the classification in the Inbox based on your company’s requirements. Change a recommended classification You can update the classifications to suit your needs by clicking on the color\ndropdown menu to change. For example, you might manually change a field that\ndoes not contain personal information in your implementation from a “Yellow”\nclassification to “Green.” When you’re satisfied that the fields have been classified appropriately, you\ncan click Add to Inventory to officially apply the classification to the\nfield. This moves the field into your Data Inventory ,\nwhich is a central repository of all of the properties you classified as Red,\nYellow, and Green. Any time you send this field from a Web, Mobile, Server, or\nCloud Event Source — whether from another Source or event type — the Privacy\nPortal automatically classifies it and adds it to the Inventory. Understanding Classification types: Red Classification :\nFields that are classified as ‘Red’ are masked for users that do not have PII Access enabled. These fields are also blocked if you have set Standard Controls under Privacy > Settings section. Keep in mind that if you have set Standard Controls to block fields from any of your sources, any new classifications you create in the Inbox will start to take affect immediately. For example, if you have a Privacy Control set up to block Red data from your Android source, any new fields you classify in the Inbox as Red will be blocked from entering Segment from your Android source. Yellow Classification :\nFields that are classified as ‘Yellow’ are masked for users that do not have PII Access enabled. Green Classification :\nClassifying a field as ‘Green’ does not have any impact on the behavior of masking of fields within the Segment App, it is only available for the housekeeping purposes. Once a field has been classified as “Yellow” or “Red”, marking it “Green” will not make it visible for users that don’t have PII access. Privacy Inventory The Inventory is a central repository of all of the properties you classified as Red, Yellow, and Green. Where the Inbox shows new, unclassified data with Segment’s recommended classifications, the Inventory only contains data that you explicitly applied Classifications to. The Inventory is intended to be a Single Source of Truth so you can answer common regulatory questions about the data you’re sending through Segment, for example: What data am I sending into Segment, and how frequently? How restricted is the data I’m sending through Segment? Where is the data coming from, on a property-by-property level? Where am I sending this data? Who within my organization has access to each property within Segment? Once you’ve classified the fields as Red, Yellow, and Green in the Inbox, the classified fields appear in the Inventory. You can use the filter at the top left to filter down to specific categories of data (for example, Red data, data from a production environment, data from specific sources). Click into a field (for example, ip ) in the Inventory to open the Inventory\ndetails. The details sheet displays how many times a specific field has been\nsent from each Source it comes from. You can click the Events tab to see which\nevents contained the event, along with the Sources which sent the event. The\ndata in the side sheet updates in realtime, and includes a limited historical\nview. You can click Connected Destinations to see which Destinations are\nconnected to the Source that contains the field. The Access tab displays a list\nof who within your organization has access to this field. Finally, workspace owners can use the Download CSV button to export a CSV of\ntheir data Inventory to share with their Data Protection Officer (DPO), Chief\nInformation Security Officer (CISO), legal teams, and more! Note that the CSV\ndownload button includes all data from your Inventory, and ignores any filters\nyou applied in the UI. This page was last modified: 25 Jun 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Privacy Detection Privacy Inbox Privacy Inventory Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Privacy Portal"
      },
      {
        "level": 2,
        "text": "Privacy Detection"
      },
      {
        "level": 3,
        "text": "Default PII Matchers"
      },
      {
        "level": 3,
        "text": "Custom PII Matchers"
      },
      {
        "level": 3,
        "text": "Using Synonyms"
      },
      {
        "level": 2,
        "text": "Privacy Inbox"
      },
      {
        "level": 3,
        "text": "Change a recommended classification"
      },
      {
        "level": 3,
        "text": "Understanding Classification types:"
      },
      {
        "level": 2,
        "text": "Privacy Inventory"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/sources/schema/schema-unique-limits/",
    "title": " Segment Schema Limits | Segment Documentation",
    "content": "Home / Connections / Sources / Schema / Segment Schema Limits Segment Schema Limits How many unique events can be logged in my Segment Schema table? While you can technically track unlimited events with Segment, only the first 4,000 events will be visible on the Schema page for a given Source. After you hit the 4,000 event limit, all future events will still be tracked and sent to your Destinations. They will not, however, be logged in the Segment Schema table. How many unique event properties and traits can be logged on the event details page? While you can track unlimited event properties and traits with Segment, the Schema page has the following default limits: Properties: The event details page for a specific event can only show the first 300 properties by default. Traits: The Identify page can only show the first 300 traits by default. After you hit the limit for both properties or traits, future properties and traits are still tracked and sent to your Destinations, but they won’t appear on the event details page. This limit includes nested properties in an event’s properties object. These limits can also affect the traits and properties that you can see in the Computed Trait and Audience builder tools in Engage. If expected traits or properties do not appear in these tools, contact the Segment Support team . How can I clear the Schema if I have hit the limits? If you hit any of the limits or would like to clear out old events or properties, you can clear the Schema data from your Source Settings. In your Source, navigate to Settings, then Schema Configuration. Scroll down to the Clear Schema History setting. Clearing events from the Source Schema only clears them from the Segment interface. It does not impact the data sent to your destinations or warehouses. Once you clear the events, the Schema page starts to repopulate new events. How can I remove specific events from my Source Schema? You can archive events in order to declutter the Source Schema. If your Source Schema is connected to a Tracking Plan, events need to be blocked or unplanned for you to archive them. If your Source Schema not connected to a Tracking Plan, you must disable the event to see the archive button. Archiving an event triggers an “Schema Event Archived” activity to the Audit Trail. To view archived events, you can filter your view by “Archived”. While this is particularly useful for Protocols customers that want to keep events “Unplanned yet acknowledged” and build a process to monitor for unplanned events, Protocols is not required to use this feature. How can I remove properties from my Source Schema? At this time, you cannot clear or archive old event properties individually. An alternative to this is to archive the event itself and then clear the archive. After you clear the archive, the event will re-populate in the schema with only the current properties. This page was last modified: 15 Nov 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Segment Schema Limits"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/ignore-bots/",
    "title": " Internet Bots | Segment Documentation",
    "content": "Home / Guides / Internet Bots Internet Bots On this page What’s a bot? Is it possible to ignore bad bots? If I see a massive MTU spike because of bots, can I apply for a refund? I’m seeing a lot of browser traffic from Boardman; is that from Segment or a bot? What’s a bot? If you stumbled onto this page by accident and don’t know what a bot is or are just curious to learn more, the following Wikipedia article provides an awesome summary: https://en.wikipedia.org/wiki/Internet_bot . Surprisingly, more than half of all web traffic is made up of bots. While a fraction of them are good bots with a regulated pattern, and therefore beneficial to all online businesses, the majority of them have malicious intents and are mostly unregulated. Is it possible to ignore bad bots? Segment doesn’t offer an out-of-the-box solution to filter or ignore bot traffic. As such, you generally have two options: Handle the filtering at a destination-level: Some of Segment’s destination partners, like Mixpanel , filter bots automatically. Whereas others such as Hubspot allow you to set up bot filtering manually. The advantage of filtering bots at a destination level is that it allows you to implement a robust, easy-to-maintain solution. However, as it pertains to Segment, the downside is that bot traffic will still make it to Segment, affecting your MTU count. Write custom logic that suppresses bot activity from being sent to Segment: if you want to prevent bot traffic from making it to Segment in the first place, another option is to write your own custom code. The logic, in pseudo-code, would look something like this if you know a particular characteristic of the bot traffic to filter out, such as the userAgent: var robots = [ useragent1 , useragent2 ] if ! window . navigator . userAgent in robots // send analytics calls analytics . track The benefit here is that you would be able to limit the impact that bots have on your MTU count. On the flip side, it’s much harder to implement and maintain a custom filter. If I see a massive MTU spike because of bots, can I apply for a refund? As a matter of policy, Segment doesn’t provide refunds for bot-related MTU spikes, as bot traffic is out of Segment’s control. However for extenuating circumstances, you can petition for a refund , assuming you’re able to provide proof of the bot’s effect. I’m seeing a lot of browser traffic from Boardman; is that from Segment or a bot? Segment uses Amazon’s hosting services, which are based in Boardman, Oregon. However many bots also originate from AWS in Boardman as well . One way you can confirm whether or not traffic is coming from Segment vs. a bot is to check the userAgent of the inbound call. Segment’s is: ' Mozilla/5.0 ( ' + deviceModel . slice ( 0 , - 3 ) + ' ; CPU ' + osName + ' ' + osVersion . replace ( / \\. /g , ' _ ' ) + ' like Mac OS X) AppleWebKit/600.1.4 (KHTML,\nlike Gecko) Version/ ' + osVersion . charAt ( 0 ) + ' .0 Mobile/10B329 Safari/8536.25 ' This page was last modified: 28 Oct 2022 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page What’s a bot? Is it possible to ignore bad bots? If I see a massive MTU spike because of bots, can I apply for a refund? I’m seeing a lot of browser traffic from Boardman; is that from Segment or a bot? Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Internet Bots"
      },
      {
        "level": 2,
        "text": "What’s a bot?"
      },
      {
        "level": 2,
        "text": "Is it possible to ignore bad bots?"
      },
      {
        "level": 2,
        "text": "If I see a massive MTU spike because of bots, can I apply for a refund?"
      },
      {
        "level": 2,
        "text": "I’m seeing a lot of browser traffic from Boardman; is that from Segment or a bot?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/traits/custom-traits/",
    "title": " Custom Traits | Segment Documentation",
    "content": "Home / Unify / Traits / Custom Traits Custom Traits On this page Comparing trait types Using custom traits Reserved custom traits Custom traits are user or account traits collected from the Identify calls you send to Segment. For example, these could be demographics like age or gender , account-specific like plan , or even things like whether a user has seen a particular A/B test variation. From your sources, send custom traits as pieces of information that you know about a user in an Identify call. As opposed to computed traits which are computed from your source data, or SQL Traits which are computed from warehouse data, custom traits are created from source events you pass into Segment and have no trait limits. Comparing trait types View the table below to better understand how Segment collects custom, computed, and SQL traits. You can use the Profile explorer ( Unify > Profile explorer ) to view traits attached to a profile. Trait type Description Custom traits Traits created from source events you pass into Segment. From your sources, send custom traits as pieces of information that you know about a user in an Identify call. Computed traits Traits collected from computations off of event and event property data from your sources. Create user or account-level calculations like most_viewed_page or total_num_orders for a customer. Learn more by viewing types of computed traits . SQL traits Traits created by running SQL queries on data in your warehouse. SQL traits are a type of computed trait. SQL traits help you import traits from your data warehouse back into Segment to build audiences or enhance data that you send to other destinations. Using custom traits Here’s the payload of a typical Identify call with custom traits (with most common fields removed): { \"type\" : \"identify\" , \"traits\" : { \"name\" : \"John Smith\" , \"email\" : \"john@example.com\" , \"plan\" : \"premium\" , \"logins\" : 5 }, \"userId\" : \"97980cfea0067\" } And here’s the corresponding JavaScript event that would generate the above payload: analytics . identify ( \" 97980cfea0067 \" , { name : \" John Smith \" , email : \" john@example.com \" , plan : \" premium \" , logins : 5 }); Any source event where there’s a traits object and key value pairs generates custom traits. Custom traits are mutable and update to the latest value seen by the user’s Identify events. When an audience that previously generated Identify events is deleted, the data for the audience key is still attached to profiles that entered the audience and becomes visible in Segment as a custom trait. Reserved custom traits Segment has reserved some custom traits that have semantic meanings for users, and will handle them in special ways. For example, Segment always expects email to be a string of the user’s email address. Segment sends this on to destinations like Mailchimp that require an email address for their tracking. Only use reserved custom traits for their intended meaning. Reserved custom traits Segment has standardized: Trait Type Description address Object Street address of a user optionally containing: city , country , postalCode , state , or street age Number Age of a user avatar String URL to an avatar image for the user birthday Date User’s birthday company Object Company the user represents, optionally containing: name (String), id (String or Number), industry (String), employee_count (Number) or plan (String) createdAt Date Date the user’s account was first created. Segment recommends using ISO-8601 date strings. description String Description of the user email String Email address of a user firstName String First name of a user gender String Gender of a user id String Unique ID in your database for a user lastName String Last name of a user name String Full name of a user. If you only pass a first and last name Segment automatically fills in the full name for you. phone String Phone number of a user title String Title of a user, usually related to their position at a specific company. Example: “VP of Engineering” username String User’s username. This should be unique to each user, like the usernames of Twitter or GitHub. website String Website of a user To learn more about using an Identify call to tie custom traits to profiles, visit Segment’s Identify documentation . This page was last modified: 12 Apr 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Comparing trait types Using custom traits Reserved custom traits Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Custom Traits"
      },
      {
        "level": 2,
        "text": "Comparing trait types"
      },
      {
        "level": 2,
        "text": "Using custom traits"
      },
      {
        "level": 2,
        "text": "Reserved custom traits"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/sources/debugger/",
    "title": " Using the Source Debugger | Segment Documentation",
    "content": "Home / Connections / Sources / Using the Source Debugger Using the Source Debugger The Source Debugger is a real-time tool that helps you confirm that API calls made from your website, mobile app, or servers arrive to your Segment Source, so you can troubleshoot your Segment set up even quicker. With the Debugger, you can check that calls are sent in the expected format without having to wait for any data processing. The Source Debugger’s event order may not reflect how events send downstream or are received by connected destinations. The Debugger primarily confirms incoming data and provides a basic view of its structure. For a reliable record of the data you send to Segment, Segment advises you to attach a raw storage destination to your sources. The Debugger is separate from your workspace’s data pipeline and is not an exhaustive view of all the events ever sent to your Segment workspace. The Debugger only shows a sample of the events that the Source receives in real time, with a cap of 500 events. The Debugger is a great way to test specific parts of your implementation to validate that events are being fired successfully and arriving to your Source. To see a more complete view of all your events, Segment recommends that you set up a warehouse or an S3 destination . The Debugger shows a live stream of sampled events arriving into the Source, but you can also pause the stream from displaying new events by toggling “Live” to “Pause”. Events continue to arrive to your Source while you Pause the stream. You can search in the Debugger to find a specific payload using any information you know is available in the event’s raw payload. You can also use advanced search options to limit the results to a specific event. Two views are available when viewing a payload: The Pretty view is an approximate recreation of the API call you made that was sent to Segment. The format shown depends on the library used at the source, and the data displayed may not account for a particular workspace’s unique configuration settings (for example, the region in the API request). The Raw view is the complete JSON object Segment received from the calls you sent. These calls include all the details about what is being tracked: timestamps, properties, traits, ids, and contextual information Segment automatically collects the moment the data is sent. This page was last modified: 11 Apr 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Using the Source Debugger"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/spec/ecommerce/v2/",
    "title": " Spec: V2 Ecommerce Events | Segment Documentation",
    "content": "Home / Connections / Spec / Ecommerce / Spec: V2 Ecommerce Events Spec: V2 Ecommerce Events On this page Event lifecycles Browsing Promotions Core Ordering Coupons Wishlisting Sharing Reviewing Segment’s e-commerce spec helps define the journey for a customer as they browse your store, click on promotions, view products, add those products to a cart, and complete a purchase. Note Not all destinations support every event listed here and accept arrays as properties. Refer to individual destination documentation for more information on supported events and properties. Event lifecycles Here is a list of supported events for our various categories within the customer journey. Browsing overview Action Description Products Searched User searched for products Product List Viewed User viewed a product list or category Product List Filtered User filtered a product list or category Promotions overview Action Description Promotion Viewed User viewed promotion Promotion Clicked User clicked on promotion Core ordering overview Action Description Product Clicked User clicked on a product Product Viewed User viewed a product details Product Added User added a product to their shopping cart Product Removed User removed a product from their shopping cart Cart Viewed User viewed their shopping cart Checkout Started User initiated the order process (a transaction is created) Checkout Step Viewed User viewed a checkout step Checkout Step Completed User completed a checkout step Payment Info Entered User added payment information Order Completed User completed the order Order Updated User updated the order Order Refunded User refunded the order Order Cancelled User cancelled the order Coupons overview Action Description Coupon Entered User entered a coupon on a shopping cart or order Coupon Applied Coupon was applied on a user’s shopping cart or order Coupon Denied Coupon was denied from a user’s shopping cart or order Coupon Removed User removed a coupon from a cart or order Wishlisting overview Action Description Product Added to Wishlist User added a product to the wish list Product Removed from Wishlist User removed a product from the wish list Wishlist Product Added to Cart User added a wishlist product to the cart Sharing overview Action Description Product Shared Shared a product with one or more friends Cart Shared Shared the cart with one or more friends Reviewing overview Action Description Product Reviewed User reviewed a product The following sections list more detail for each lifecycle event as well as an example API call. Browsing Browsing lifecycle events represent key events that a customer might have while browsing your apps. Products Searched Fire this event when a visitor searches for products. This event supports the following semantic properties: Property Type Description query String | Object Query the user searched with Example: analytics . track ( ' Products Searched ' , { query : ' blue roses ' }); Product List Viewed Fire this event when a visitor views a product list or category. Note Not all destinations accept arrays as properties. Refer to individual destination documentation for more information on supported events and properties. This event supports the following semantic properties: Property Type Description list_id String Product list being viewed category String Product category being viewed products Array<Product> Products displayed in the product list products.$.product_id String Product id displayed on the list products.$.sku String Sku of the product being viewed products.$.category String Product category being viewed products.$.name String Name of the product being viewed products.$.brand String Brand associated with the product products.$.variant String Variant of the product products.$.price Number Price ($) of the product being viewed products.$.quantity Number Quantity of a product products.$.coupon String Coupon code associated with a product (for example, MAY_DEALS_3) products.$.position Number Position in the product list (ex. 3) products.$.url String URL of the product page products.$.image_url String Image url of the product Example: analytics . track ( ' Product List Viewed ' , { list_id : ' hot_deals_1 ' , category : ' Deals ' , products : [ { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' 45790-32 ' , name : ' Monopoly: 3rd Edition ' , price : 19 , position : 1 , category : ' Games ' , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }, { product_id : ' 505bd76785ebb509fc183733 ' , sku : ' 46493-32 ' , name : ' Uno Card Game ' , price : 3 , position : 2 , category : ' Games ' } ] }); Note The Product List Viewed event is aliased to the Viewed Product Category event (from e-commerce v1 spec). Product List Filtered Send this event when a visitor filters a product list or category. Note Not all destinations accept arrays as properties. Refer to individual destination docs for more information on supported events and properties. This event supports the following semantic properties: Property Type Description list_id String Product list being viewed category String Product category being viewed filters Array Product filters that the customer is using filters.$.type String Id of the filter type that the customer is using filters.$.value String Id of the selection that the customer chose sorts Array<Sort> Product sorting that the customer is using sorts.$.type String Id of the sort type that the customer is using sorts.$.value String Id of the selection type the the customer is using (ascending, descending) products Array Products displayed in the product list products.$.product_id String Product id displayed on the list products.$.sku String Sku of the product being viewed products.$.category String Product category being viewed products.$.name String Name of the product being viewed products.$.brand String Brand associated with the product products.$.variant String Variant of the product products.$.price Number Price ($) of the product being viewed products.$.quantity Number Quantity of a product products.$.coupon String Coupon code associated with a product (for example, MAY_DEALS_3) products.$.position Number Position in the product list (ex. 3) products.$.url String URL of the product page products.$.image_url String Image url of the product Example: analytics . track ( ' Product List Filtered ' , { list_id : ' todays_deals_may_11_2019 ' , filters : [ { type : ' department ' , value : ' beauty ' }, { type : ' price ' , value : ' under-$25 ' }, ], sorts : [ { type : ' price ' , value : ' desc ' } ], products : [ { product_id : ' 507f1f77bcf86cd798439011 ' , sku : ' 45360-32 ' , name : ' Special Facial Soap ' , price : 12.60 , position : 1 , category : ' Beauty ' , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }, { product_id : ' 505bd76785ebb509fc283733 ' , sku : ' 46573-32 ' , name : ' Fancy Hairbrush ' , price : 7.60 , position : 2 , category : ' Beauty ' } ] }); Promotions Promotion view and click events help you gather analytics on internal offers within your web or mobile app. For example, when a banner advertisement is shown in your web or app’s home page, you can fire a Viewed Promotion event. If the user proceeds to click the advertisement, fire the Clicked Promotion event. Promotion Viewed Fire this event when a user views a promotion. This event supports the following semantic properties: Property Type Description Example promotion_id String Promotion’s ID promo_1 creative String Promotion’s creative top_banner_2 name String Promotion’s name 75% store-wide shoe sale position String Promotion’s position home_banner_top Example: analytics . track ( ' Promotion Viewed ' , { promotion_id : ' promo_1 ' , creative : ' top_banner_2 ' , name : ' 75% store-wide shoe sale ' , position : ' home_banner_top ' }); Note The Promotion Viewed event is aliased to the Viewed Promotion event . Promotion Clicked Fire this event when a visitor clicks an internal offer promotion. This event supports the following semantic properties: Property Type Description Example promotion_id String Promotion’s ID promo_1 creative String Promotion’s creative top_banner_2 name String Promotion’s name 75% store-wide shoe sale position String Promotion’s position home_banner_top Example: analytics . track ( ' Promotion Clicked ' , { promotion_id : ' promo_1 ' , creative : ' top_banner_2 ' , name : ' 75% store-wide shoe sale ' , position : ' home_banner_top ' }); Note The Promotion Clicked event is aliased to the Clicked Promotion event . Core Ordering These events represent the customer journey in regards to product ordering. Product Clicked Fire this event when a visitor clicks a product. This event supports the following semantic properties: Property Type Description product_id String Database id of the product being viewed sku String Sku of the product being viewed category String Product category being viewed name String Name of the product being viewed brand String Brand associated with the product variant String Variant of the product price Number Price of the product being viewed quantity Number Quantity of a product coupon String Coupon code associated with a product (for example, MAY_DEALS_3) position Number Position in the product list (ex. 3) url String URL of the product page image_url String Image url of the product Example: analytics . track ( ' Product Clicked ' , { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' G-32 ' , category : ' Games ' , name : ' Monopoly: 3rd Edition ' , brand : ' Hasbro ' , variant : ' 200 pieces ' , price : 18.99 , quantity : 1 , coupon : ' MAYDEALS ' , position : 3 , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . The Product Clicked event is aliased to the Clicked Product event from e-commerce v1 spec . Product Viewed Fire this event when a visitor views a product. That view might happen on a page, screen, or preview modal. This event supports the following semantic properties: Property Type Description product_id String Database id of the product being viewed sku String Sku of the product being viewed category String Product category being viewed name String Name of the product being viewed brand String Brand associated with the product variant String Variant of the product price Number Price ($) of the product being viewed quantity Number Quantity of a product coupon String Coupon code associated with a product (for example, MAY_DEALS_3) currency String Currency of the transaction position Number Position in the product list (ex. 3) value Number Total value of the product after quantity url String URL of the product page image_url String Image url of the product Example: analytics . track ( ' Product Viewed ' , { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' G-32 ' , category : ' Games ' , name : ' Monopoly: 3rd Edition ' , brand : ' Hasbro ' , variant : ' 200 pieces ' , price : 18.99 , quantity : 1 , coupon : ' MAYDEALS ' , currency : ' usd ' , position : 3 , value : 18.99 , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . The Product Viewed event is aliased to the Viewed Product event from e-commerce v1 spec . Product Added Fire this event when a visitor adds a product to their shopping cart. This event supports the following semantic properties: Property Type Description cart_id String Cart ID to which the product was added to product_id String Database id of the product being viewed sku String Sku of the product being viewed category String Product category being viewed name String Name of the product being viewed brand String Brand associated with the product variant String Variant of the product price Number Price ($) of the product being viewed quantity Number Quantity of a product coupon String Coupon code associated with a product (for example, MAY_DEALS_3) position Number Position in the product list (ex. 3) url String URL of the product page image_url String Image url of the product Example: analytics . track ( ' Product Added ' , { cart_id : ' skdjsidjsdkdj29j ' , product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' G-32 ' , category : ' Games ' , name : ' Monopoly: 3rd Edition ' , brand : ' Hasbro ' , variant : ' 200 pieces ' , price : 18.99 , quantity : 1 , coupon : ' MAYDEALS ' , position : 3 , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . The Product Added event is aliased to the Added Product event from e-commerce v1 spec . Product Removed Fire this event when a visitor removes a product from their shopping cart. This event supports the following semantic properties: Property Type Description cart_id String Cart ID to which the product was removed from product_id String Database id of the product being viewed sku String Sku of the product being viewed category String Product category being viewed name String Name of the product being viewed brand String Brand associated with the product variant String Variant of the product price Number Price ($) of the product being viewed quantity Number Quantity of a product coupon String Coupon code associated with a product (for example, MAY_DEALS_3) position Number Position in the product list (ex. 3) url String URL of the product page image_url String Image url of the product Example: analytics . track ( ' Product Removed ' , { cart_id : ' ksjdj92dj29dj92d2j ' , product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' G-32 ' , category : ' Games ' , name : ' Monopoly: 3rd Edition ' , brand : ' Hasbro ' , variant : ' 200 pieces ' , price : 18.99 , quantity : 1 , coupon : ' MAYDEALS ' , position : 3 , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . The Product Removed event is aliased to the Removed Product event from e-commerce v1 spec . Cart Viewed Fire this event when a visitor views a shopping cart. Note Not all destinations accept arrays as properties. Refer to individual destination documentation for more information on supported events and properties. This event supports the following semantic properties: Property Type Description cart_id String Shopping cart ID products Array Products displayed in the product list products.$.product_id String Product ID displayed on the list products.$.sku String Sku of the product being viewed products.$.category String Product category being viewed products.$.name String Name of the product being viewed products.$.brand String Brand associated with the product products.$.variant String Variant of the product products.$.price Number Price ($) of the product being viewed products.$.quantity Number Quantity of a product products.$.coupon String Coupon code associated with a product (for example, MAY_DEALS_3) products.$.position Number Position in the product list (ex. 3) products.$.url String URL of the product page products.$.image_url String Image url of the product Example: analytics . track ( ' Cart Viewed ' , { cart_id : ' d92jd29jd92jd29j92d92jd ' , products : [ { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' 45790-32 ' , name : ' Monopoly: 3rd Edition ' , price : 19 , position : 1 , category : ' Games ' , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }, { product_id : ' 505bd76785ebb509fc183733 ' , sku : ' 46493-32 ' , name : ' Uno Card Game ' , price : 3 , position : 2 , category : ' Games ' } ] }); Checkout Started Fire this event whenever an order/transaction was started. Fire on the page that the customer lands on after they press the checkout button. Note Not all destinations accept arrays as properties. Refer to individual destination documentation for more information on supported events and properties. Be sure to include all items in the cart as event properties , with the same properties from the previous calls, like so: This event supports the following semantic properties: Property Type Description order_id String Order/transaction ID affiliation String Store or affiliation from which this transaction occurred (for example, Google Store) value Number Revenue ($) with discounts and coupons added in. For better flexibility and total control over tracking, we let you decide how to calculate how coupons and discounts are applied revenue Number Revenue ($) associated with the transaction (excluding shipping and tax) shipping Number Shipping cost associated with the transaction tax Number Total tax associated with the transaction discount Number Total discount associated with the transaction coupon String Transaction coupon redeemed with the transaction currency String Currency code associated with the transaction products Array Products in the order products.$.product_id String Database id of the product being viewed products.$.sku String Sku of the product being viewed products.$.category String Product category being viewed products.$.name String Name of the product being viewed products.$.brand String Brand associated with the product products.$.variant String Variant of the product products.$.price Number Price ($) of the product being viewed products.$.quantity Number Quantity of a product products.$.coupon String Coupon code associated with a product (for example, MAY_DEALS_3) products.$.position Number Position in the product list (ex. 3) products.$.url String URL of the product page products.$.image_url String Image url of the product Example: analytics . track ( ' Checkout Started ' , { order_id : ' 50314b8e9bcf000000000000 ' , affiliation : ' Google Store ' , value : 30 , revenue : 25.00 , shipping : 3 , tax : 2 , discount : 2.5 , coupon : ' hasbros ' , currency : ' USD ' , products : [ { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' 45790-32 ' , name : ' Monopoly: 3rd Edition ' , price : 19 , quantity : 1 , category : ' Games ' , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }, { product_id : ' 505bd76785ebb509fc183733 ' , sku : ' 46493-32 ' , name : ' Uno Card Game ' , price : 3 , quantity : 2 , category : ' Games ' } ] }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . The Checkout Started event is aliased to the Started Order event from Segment’s GA Enhanced E-Commerce destinations . Checkout Step Viewed Fire this event whenever a checkout step is viewed. This event supports the following semantic properties: Property Type Description checkout_id String Checkout transaction ID step Number Number representing a step in the checkout process shipping_method String String representing the shipping the method chosen payment_method String String representing the payment method chosen Example: analytics . track ( ' Checkout Step Viewed ' , { checkout_id : ' 50314b8e9bcf000000000000 ' , step : 2 , shipping_method : ' Fedex ' , payment_method : ' Visa ' }); Note shipping_method and payment_method are semantic properties. If you want to send that information, do so in this exact spelling. You can have as many or as few steps in the checkout funnel as you’d like. Note that you’ll still need to track the Order Completed event per Segment’s standard e-commerce tracking API after you’ve tracked the checkout steps. Note The Checkout Step Viewed event is aliased to the Viewed Checkout Step event from Segment’s GA Enhanced E-Commerce destinations . Checkout Step Completed Fire this event whenever a checkout step is completed. This event supports the following semantic properties: Property Type Description checkout_id String Checkout transaction ID step Number Number representing a step in the checkout process shipping_method String String representing the shipping the method chosen payment_method String String representing the payment method chosen Example: analytics . track ( ' Checkout Step Completed ' , { checkout_id : ' 50314b8e9bcf000000000000 ' , step : 2 , shipping_method : ' Fedex ' , payment_method : ' Visa ' }); Note shipping_method and payment_method are semantic properties. If you want to send that information, do so in this exact spelling. You can have as many or as few steps in the checkout funnel as you’d like. Note that you’ll still need to track the Order Completed event per Segment’s standard e-commerce tracking API after you’ve tracked the checkout steps. Note The Checkout Step Completed event is aliased to the Completed Checkout Step event from Segment’s GA Enhanced E-Commerce destinations . Payment Info Entered Fire this event whenever payment information has been successfully entered. This event supports the following semantic properties: Property Type Description checkout_id String Checkout transaction ID order_id String Order ID (optional) step Number Number representing a step in the checkout process shipping_method String String representing the shipping the method chosen payment_method String String representing the payment method chosen Example: analytics . track ( ' Payment Info Entered ' , { checkout_id : ' 39f39fj39f3jf93fj9fj39fj3f ' , order_id : ' dkfsjidfjsdifsdfksdjfkdsfjsdfkdsf ' }); Note shipping_method and payment_method are semantic properties. If you want to send that information, do so in this exact spelling. You can have as many or as few steps in the checkout funnel as you’d like. Note that you’ll still need to track the Order Completed event per Segment’s standard e-commerce tracking API after you’ve tracked the checkout steps. Order Updated Fire this event whenever an order/transaction was updated. Note Not all destinations accept arrays as properties. Refer to individual destination documentation for more information on supported events and properties. Be sure to include all items in the cart as event properties , with the same properties from the previous calls, like so: This event supports the following semantic properties: Property Type Description order_id String Order/transaction ID affiliation String Store or affiliation from which this transaction occurred (for example, Google Store) total Number Revenue ($) with discounts and coupons added in Note that our Google Analytics Ecommerce destination accepts total or revenue , but not both. For better flexibility and total control over tracking, we let you decide how to calculate how coupons and discounts are applied revenue Number Revenue ($) associated with the transaction (excluding shipping and tax) shipping Number Shipping cost associated with the transaction tax Number Total tax associated with the transaction discount Number Total discount associated with the transaction coupon String Transaction coupon redeemed with the transaction currency String Currency code associated with the  transaction products Array Products in the order products.$.product_id String Database id of the product being viewed products.$.sku String Sku of the product being viewed products.$.category String Product category being viewed products.$.name String Name of the product being viewed products.$.brand String Brand associated with the product products.$.variant String Variant of the product products.$.price Number Price ($) of the product being viewed products.$.quantity Number Quantity of a product products.$.coupon String Coupon code associated with a product (for example, MAY_DEALS_3) products.$.position Number Position in the product list (ex. 3) products.$.url String URL of the product page products.$.image_url String Image url of the product Example: analytics . track ( ' Order Updated ' , { order_id : ' 50314b8e9bcf000000000000 ' , affiliation : ' Google Store ' , total : 27.50 , revenue : 25.00 , shipping : 3 , tax : 2 , discount : 2.5 , coupon : ' hasbros ' , currency : ' USD ' , products : [ { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' 45790-32 ' , name : ' Monopoly: 3rd Edition ' , price : 19 , quantity : 1 , category : ' Games ' , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }, { product_id : ' 505bd76785ebb509fc183733 ' , sku : ' 46493-32 ' , name : ' Uno Card Game ' , price : 3 , quantity : 2 , category : ' Games ' } ] }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . The Order Updated event is aliased to the Updated Order event from Segment’s GA Enhanced E-Commerce destinations . Order Completed Fire this event whenever an order/transaction was successfully completed by the customer. Note Not all destinations accept arrays as properties. Refer to individual destination documentation for more information on supported events and properties. Be sure to include all items in the cart as event properties , with the same properties from the previous calls, like so: This event supports the following semantic properties: Property Type Description checkout_id String Checkout ID order_id String Order/transaction ID affiliation String Store or affiliation from which this transaction occurred (for example, Google Store) subtotal Number Order total after discounts but before taxes and shipping total Number Subtotal ($) with shipping and taxes added in. Note that our Google Analytics Ecommerce destination accepts total or revenue , but not both. For better flexibility and total control over tracking, we let you decide how to calculate how coupons and discounts are applied revenue Number Revenue ($) associated with the transaction (including discounts, but excluding shipping and taxes) shipping Number Shipping cost associated with the transaction tax Number Total tax associated with the transaction discount Number Total discount associated with the transaction coupon String Transaction coupon redeemed with the transaction currency String Currency code associated with the transaction products Array Products in the order products.$.product_id String Database id of the product being viewed products.$.sku String Sku of the product being viewed products.$.category String Product category being viewed products.$.name String Name of the product being viewed products.$.brand String Brand associated with the product products.$.variant String Variant of the product products.$.price Number Price ($) of the product being viewed products.$.quantity Number Quantity of a product products.$.coupon String Coupon code associated with a product (for example, MAY_DEALS_3) products.$.position Number Position in the product list (ex. 3) products.$.url String URL of the product page products.$.image_url String Image url of the product Example: analytics . track ( ' Order Completed ' , { checkout_id : ' fksdjfsdjfisjf9sdfjsd9f ' , order_id : ' 50314b8e9bcf000000000000 ' , affiliation : ' Google Store ' , total : 27.50 , subtotal : 22.50 , revenue : 22.50 , shipping : 3 , tax : 2 , discount : 2.5 , coupon : ' hasbros ' , currency : ' USD ' , products : [ { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' 45790-32 ' , name : ' Monopoly: 3rd Edition ' , price : 19 , quantity : 1 , category : ' Games ' , url : ' https://www.example.com/product/path ' , image_url : ' https:///www.example.com/product/path.jpg ' }, { product_id : ' 505bd76785ebb509fc183733 ' , sku : ' 46493-32 ' , name : ' Uno Card Game ' , price : 3 , quantity : 2 , category : ' Games ' } ] }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . The Order Completed event is aliased to the Completed Order event from E-Commerce spec v1 - 5/11/16 . Order Refunded Fire this event whenever an order/transaction was refunded. Be sure to include all items in the cart as event properties , with the same properties from the previous “Order Completed” call. This event supports the following semantic properties: Property Type Description order_id String Order/transaction ID Example: analytics . track ( ' Order Refunded ' , { order_id : ' 50314b8e9bcf000000000000 ' , total : 30 , currency : ' USD ' , products : [ { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' 45790-32 ' , name : ' Monopoly: 3rd Edition ' , price : 19 , quantity : 1 , category : ' Games ' , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }, { product_id : ' 505bd76785ebb509fc183733 ' , sku : ' 46493-32 ' , name : ' Uno Card Game ' , price : 3 , quantity : 2 , category : ' Games ' } ] }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . Order Cancelled Fire this event whenever an order/transaction was cancelled. Note Not all destinations accept arrays as properties. Refer to individual destination documentation for more information on supported events and properties. Be sure to include all items in the cart as event properties , with the same properties from the previous calls. This event supports the following semantic properties: Property Type Description order_id String Order/transaction ID affiliation String Store or affiliation from which this transaction occurred (for example, Google Store) total Number Revenue ($) with discounts and coupons added in. revenue Number Revenue ($) associated with the transaction (excluding shipping and tax) shipping Number Shipping cost associated with the transaction tax Number Total tax associated with the transaction discount Number Total discount associated with the transaction coupon String Transaction coupon redeemed with the transaction currency String Currency code associated with the transaction products Array Products in the order products.$.product_id String Database id of the product being viewed products.$.sku String Sku of the product being viewed products.$.category String Product category being viewed products.$.name String Name of the product being viewed products.$.brand String Brand associated with the product products.$.variant String Variant of the product products.$.price Number Price ($) of the product being viewed products.$.quantity Number Quantity of a product products.$.coupon String Coupon code associated with a product (for example, MAY_DEALS_3) products.$.position Number Position in the product list (ex. 3) products.$.url String URL of the product page products.$.image_url String Image url of the product Example: analytics . track ( ' Order Cancelled ' , { order_id : ' 50314b8e9bcf000000000000 ' , affiliation : ' Google Store ' , total : 30 , revenue : 25.00 , shipping : 3 , tax : 2 , discount : 2.5 , coupon : ' hasbros ' , currency : ' USD ' , products : [ { product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' 45790-32 ' , name : ' Monopoly: 3rd Edition ' , price : 19 , quantity : 1 , category : ' Games ' , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }, { product_id : ' 505bd76785ebb509fc183733 ' , sku : ' 46493-32 ' , name : ' Uno Card Game ' , price : 3 , quantity : 2 , category : ' Games ' } ] }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . Coupons These are events that might occur when dealing with coupons in your ecommerce. Coupon Entered Fire this event whenever a coupon is entered either on a cart or on an order/transaction. This event supports the following semantic properties: Property Type Description order_id String Order/transaction ID, if applicable cart_id String Cart ID, if applicable coupon_id String Coupon ID Example: analytics . track ( ' Coupon Entered ' , { order_id : ' 50314b8e9bcf000000000000 ' , cart_id : ' 923923929jd29jd92dj9j93fj3 ' , coupon_id : ' may_deals_2016 ' }); Note This has no effect in GA enhanced e-commerce, as that destination pulls from the coupon field on the order events. Refer to Segment’s Google Analytic documentation for more information. Coupon Applied Fire this event whenever a coupon is successfully applied to either a cart or an order/transaction. This event supports the following semantic properties: Property Type Description order_id String Order/transaction ID, if applicable cart_id String Cart ID, if applicable coupon_id String Coupon ID coupon_name String Coupon name discount Number Monetary discount applied through the coupon Example: analytics . track ( ' Coupon Applied ' , { order_id : ' 50314b8e9bcf000000000000 ' , cart_id : ' 923923929jd29jd92dj9j93fj3 ' coupon_id : ' may_deals_2016 ' , coupon_name : ' May Deals 2016 ' , discount : 23.32 }); Note This has no effect in GA enhanced e-commerce, as that destination pulls from the coupon field on the order events. Refer to Segment’s Google Analytic documentation for more information. Coupon Denied Fire this event whenever a coupon is denied from either a cart or an order/transaction. This event supports the following semantic properties: Property Type Description order_id String Order/transaction ID, if applicable cart_id String Cart ID, if applicable coupon_id String Coupon ID coupon_name String Coupon name reason String Reason the coupon was denied Example: analytics . track ( ' Coupon Denied ' , { order_id : ' 50314b8e9bcf000000000000 ' , cart_id : ' 923923929jd29jd92dj9j93fj3 ' coupon : ' may_deals_2016 ' , reason : ' Coupon expired ' }); Note This has no effect in GA enhanced e-commerce, as that destination pulls from the coupon field on the order events. Refer to Segment’s Google Analytic documentation for more information. Coupon Removed Fire this event whenever a coupon is removed from either a cart or an order/transaction. This event supports the following semantic properties: Property Type Description order_id String Order/transaction ID, if applicable cart_id String Cart ID, if applicable coupon_id String Coupon ID coupon_name String Coupon name discount Number Monetary discount applied through the coupon Example: analytics . track ( ' Coupon Removed ' , { order_id : ' 50314b8e9bcf000000000000 ' , cart_id : ' 923923929jd29jd92dj9j93fj3 ' coupon_id : ' may_deals_2016 ' , coupon_name : ' May Deals 2016 ' , discount : 23.32 }); Note This has no effect in GA enhanced e-commerce, as that destination pulls from the coupon field on the order events. Refer to Segment’s Google Analytic documentation for more information. Wishlisting These events may occur if your ecommerce supports wishlist features. Product Added to Wishlist Fire this event when a customer adds a product to their wish list. This event supports the following semantic properties: Property Type Description wishlist_id String Wishlist ID to which the product was added to wishlist_name String Wishlist name to which the product was added to product_id String Database id of the product being viewed sku String Sku of the product being viewed category String Product category being viewed name String Name of the product being viewed brand String Brand associated with the product variant String Variant of the product price Number Price ($) of the product being viewed quantity Number Quantity of a product coupon String Coupon code associated with a product (for example, MAY_DEALS_3) position Number Position in the product list (ex. 3) url String URL of the product page image_url String Image url of the product Example: analytics . track ( ' Product Added to Wishlist ' , { wishlist_id : ' skdjsidjsdkdj29j ' , wishlist_name : ' Loved Games ' , product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' G-32 ' , category : ' Games ' , name : ' Monopoly: 3rd Edition ' , brand : ' Hasbro ' , variant : ' 200 pieces ' , price : 18.99 , quantity : 1 , coupon : ' MAYDEALS ' , position : 3 , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }); Note The sku and product_id do not have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . Product Removed from Wishlist Fire this event when a customer removes a product from their wish list. This event supports the following semantic properties: Property Type Description wishlist_id String Wishlist ID to which the product was added to wishlist_name String Wishlist name to which the product was added to product_id String Database id of the product being viewed sku String Sku of the product being viewed category String Product category being viewed name String Name of the product being viewed brand String Brand associated with the product variant String Variant of the product price Number Price ($) of the product being viewed quantity Number Quantity of a product coupon String Coupon code associated with a product (for example, MAY_DEALS_3) position Number Position in the product list (ex. 3) url String URL of the product page image_url String Image url of the product Example: analytics . track ( ' Product Removed from Wishlist ' , { wishlist_id : ' skdjsidjsdkdj29j ' , wishlist_name : ' Loved Games ' , product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' G-32 ' , category : ' Games ' , name : ' Monopoly: 3rd Edition ' , brand : ' Hasbro ' , variant : ' 200 pieces ' , price : 18.99 , quantity : 1 , coupon : ' MAYDEALS ' , position : 3 , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . Wishlist Product Added to Cart Fire this event when a customer moves a product from their wish list to their cart. This event supports the following semantic properties: Property Type Description wishlist_id String Wishlist ID to which the product was added to wishlist_name String Wishlist name to which the product was added to cart_id String Cart ID to which this product was added to product_id String Database ID of the product being viewed sku String Sku of the product being viewed category String Product category being viewed name String Name of the product being viewed brand String Brand associated with the product variant String Variant of the product price Number Price ($) of the product being viewed quantity Number Quantity of a product coupon String Coupon code associated with a product (for example, MAY_DEALS_3) position Number Position in the product list (ex. 3) url String URL of the product page image_url String Image url of the product Example: analytics . track ( ' Wishlist Product Added to Cart ' , { wishlist_id : ' skdjsidjsdkdj29j ' , wishlist_name : ' Loved Games ' , cart_id : ' 99j2d92j9dj29dj29d2d ' , product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' G-32 ' , category : ' Games ' , name : ' Monopoly: 3rd Edition ' , brand : ' Hasbro ' , variant : ' 200 pieces ' , price : 18.99 , quantity : 1 , coupon : ' MAYDEALS ' , position : 3 , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . Sharing With many ecommerce stores integrating with social apps or other sharing capabilities, these events might be useful if you are tracking customers sharing product information. Product Shared Fire this event when a customer shares a product. This event supports the following semantic properties: Property Type Description share_via String Method of sharing share_message String Message that the sender sent recipient String Recipient of the sharing product_id String Database ID of the product being viewed sku String Sku of the product being viewed category String Product category being viewed name String Name of the product being viewed brand String Brand associated with the product variant String Variant of the product price Number Price ($) of the product being viewed url String URL of the product page image_url String Image url of the product Example: analytics . track ( ' Product Shared ' , { share_via : ' email ' , share_message : ' Hey, check out this item ' , recipient : ' friend@example.com ' , product_id : ' 507f1f77bcf86cd799439011 ' , sku : ' G-32 ' , category : ' Games ' , name : ' Monopoly: 3rd Edition ' , brand : ' Hasbro ' , variant : ' 200 pieces ' , price : 18.99 , url : ' https://www.example.com/product/path ' , image_url : ' https://www.example.com/product/path.jpg ' }); Note The sku and product_id don’t have to be different. If they are different, typically the product_id is a database identifier, like 9714107479 and the sku is a public-facing identifier like SEG-02 . Cart Shared Fire this event when a customer shares a shopping cart. Note Not all destinations accept arrays as properties. Refer to individual destination docs for more information on supported events and properties. This event supports the following semantic properties: Property Type Description share_via String Method of sharing share_message String Message that the sender sent recipient String Recipient of the sharing cart_id String Shopping cart ID products Array Products displayed in the product list products.$.product_id String Product id displayed on the list Example: analytics . track ( ' Cart Shared ' , { share_via : ' email ' , share_message : ' Hey, check out this item ' , recipient : ' friend@example.com ' , cart_id : ' d92jd29jd92jd29j92d92jd ' , products : [ { product_id : ' 507f1f77bcf86cd799439011 ' }, { product_id : ' 505bd76785ebb509fc183733 ' } ] }); Reviewing These events can be useful for tracking product related reviews. Product Reviewed Fire this event when a customer reviews a product. This event supports the following semantic properties: Property Type Description product_id String Product’s ID review_id String Review ID review_body String Review body rating String Review rating Example: analytics . track ( ' Product Reviewed ' , { product_id : ' 507f1f77bcf86cd799439011 ' , review_id : ' kdfjrj39fj39jf3 ' , review_body : ' I love this product ' , rating : ' 5 ' }); This page was last modified: 17 Apr 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Event lifecycles Browsing Promotions Core Ordering Coupons Wishlisting Sharing Reviewing Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Spec: V2 Ecommerce Events"
      },
      {
        "level": 2,
        "text": "Event lifecycles"
      },
      {
        "level": 3,
        "text": "Browsing overview"
      },
      {
        "level": 3,
        "text": "Promotions overview"
      },
      {
        "level": 3,
        "text": "Core ordering overview"
      },
      {
        "level": 3,
        "text": "Coupons overview"
      },
      {
        "level": 3,
        "text": "Wishlisting overview"
      },
      {
        "level": 3,
        "text": "Sharing overview"
      },
      {
        "level": 3,
        "text": "Reviewing overview"
      },
      {
        "level": 2,
        "text": "Browsing"
      },
      {
        "level": 3,
        "text": "Products Searched"
      },
      {
        "level": 3,
        "text": "Product List Viewed"
      },
      {
        "level": 3,
        "text": "Product List Filtered"
      },
      {
        "level": 2,
        "text": "Promotions"
      },
      {
        "level": 3,
        "text": "Promotion Viewed"
      },
      {
        "level": 3,
        "text": "Promotion Clicked"
      },
      {
        "level": 2,
        "text": "Core Ordering"
      },
      {
        "level": 3,
        "text": "Product Clicked"
      },
      {
        "level": 3,
        "text": "Product Viewed"
      },
      {
        "level": 3,
        "text": "Product Added"
      },
      {
        "level": 3,
        "text": "Product Removed"
      },
      {
        "level": 3,
        "text": "Cart Viewed"
      },
      {
        "level": 3,
        "text": "Checkout Started"
      },
      {
        "level": 3,
        "text": "Checkout Step Viewed"
      },
      {
        "level": 3,
        "text": "Checkout Step Completed"
      },
      {
        "level": 3,
        "text": "Payment Info Entered"
      },
      {
        "level": 3,
        "text": "Order Updated"
      },
      {
        "level": 3,
        "text": "Order Completed"
      },
      {
        "level": 3,
        "text": "Order Refunded"
      },
      {
        "level": 3,
        "text": "Order Cancelled"
      },
      {
        "level": 2,
        "text": "Coupons"
      },
      {
        "level": 3,
        "text": "Coupon Entered"
      },
      {
        "level": 3,
        "text": "Coupon Applied"
      },
      {
        "level": 3,
        "text": "Coupon Denied"
      },
      {
        "level": 3,
        "text": "Coupon Removed"
      },
      {
        "level": 2,
        "text": "Wishlisting"
      },
      {
        "level": 3,
        "text": "Product Added to Wishlist"
      },
      {
        "level": 3,
        "text": "Product Removed from Wishlist"
      },
      {
        "level": 3,
        "text": "Wishlist Product Added to Cart"
      },
      {
        "level": 2,
        "text": "Sharing"
      },
      {
        "level": 3,
        "text": "Product Shared"
      },
      {
        "level": 3,
        "text": "Cart Shared"
      },
      {
        "level": 2,
        "text": "Reviewing"
      },
      {
        "level": 3,
        "text": "Product Reviewed"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/identity-resolution/ecommerce-example/",
    "title": " Identity Resolution eCommerce Example | Segment Documentation",
    "content": "Home / Unify / Identity resolution / Identity Resolution eCommerce Example Identity Resolution eCommerce Example Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Anonymous to known identification Cross-device identification Cross-app identification Conclusion Identity Resolution helps to create a unified view of the user across devices, apps, and unique identifiers. Take the example of a sneaker company called SegmentKicks which has an eCommerce app called SegKicks as well as a running app called SegRuns. This example follows Jane Doe through her customer journey from an anonymous user to a registered buyer on one app, SegKicks, to her use of the same app on a different device, and finally to her use of a different app belonging to the same company, SegRuns. Anonymous to known identification Identity Resolution can connect a user’s anonymous behaviors to a user’s post-account registration activity. Take this example using the eCommerce app, SegKicks: Jane Doe downloads the app on her iPhone but doesn’t yet register for an account. { \" anonymousId \" : \" anon_123 \" , \" context \" : { \" app \" : \" SegKicks \" , \" device \" : { \" id \" : \" ios_abc123 \" , \" type \" : \" ios \" }, }, \" event \" : \" App Opened \" , \" type \" : \" track \" } She then clicks on a few different types of shoes, ShoeA, ShoeB, and ShoeC but doesn’t add them to a cart. Because she hasn’t yet registered for an account, all of these events will be sent through with an anonymousID and an ios deviceID. { \" anonymousId \" : \" anon_123 \" , \" context \" : { \" app \" : \" SegKicks \" , \" device \" : { \" id \" : \" ios_abc123 \" , \" type \" : \" ios \" }, }, \" event \" : \" ShoeA Clicked \" , \" type \" : \" track \" } She then decides to add ShoeD to her cart. Upon checkout, she creates a new user profile with her email and purchases the shoe. At the point of account creation she is assigned a userID and the events of her purchase are sent through with an email. { \" anonymousId \" : \" anon_123 \" , \" context \" : { \" app \" : \" SegKicks \" , \" device \" : { \" id \" : \" ios_abc123 \" , \" type \" : \" ios \" }, }, \" userId \" : \" abc123def \" , \" type \" : \" identify \" } By linking the original anonymous events to Jane’s logged-in activity, the app’s marketing team can now begin to map out her customer journey on a single app, understand her preferences, and re-target her with highly personalized emails about the shoes she didn’t complete purchasing. Her identifiers will now contain the original anonymous_id, her email, and her user_id: Cross-device identification Users can have multiple touch points with an app ecosystem through more than one device. For example, users might interact with an eCommerce app through both a native app, a mobile browser, and a web browser. Continuing with the example of Jane Doe, she now views the same mobile app SegKicks on her Android phone. Jane logs into the Android phone with the same email janedoe@example.com . { \" anonymousId \" : \" anon_456 \" , \" context \" : { \" app \" : \" SegKicks \" , \" device \" : { \" id \" : \" and_1a2b3c4d \" , \" type \" : \" android \" }, }, \" type \" : \" identify \" , \" userId \" : \" abc123def \" } Her new User Profile identities will now contains an android.id : Cross-app identification A company’s product ecosystem may also spread out across multiple apps. For example, SegmentKicks also has a running app SegRuns. When Jane downloads the Android app SegRuns and views a workout: { \" anonymousId \" : \" anon_789 \" , \" context \" : { \" app \" : \" SegRuns \" , \" device \" : { \" id \" : \" and_1a2b3c4d \" , \" type \" : \" android \" }, }, \" type \" : \" identify \" , \" userId \" : \" abc123def \" } Her final identifiers now have a new anonymous_id from the SegRuns app: Conclusion By combining the events throughout Jane’s entire customer journey from anonymous to known user, cross-device, and cross-app identification, SegKicks and SegRuns can now work together to understand how to give Jane the best customer experience possible while increasing her LTV across the entire SegmentKicks ecosystem. For example, if Jane looked at ShoeC on her iPhone and completed checkout for ShoeC on her Android, SegKicks will now know to exclude her from a cart abandonment email for ShoeC. This wouldn’t be possible if SegKicks had only looked at her activity on the iPhone. Additionally, most shoes need to be replaced every 300 to 400 miles. By understanding her activity on SegRuns, SegKicks will now be able to more effectively remind Jane to repurchase ShoeC or ShoeD once she’s reached that mileage. This page was last modified: 28 Mar 2023 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Anonymous to known identification Cross-device identification Cross-app identification Conclusion Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Identity Resolution eCommerce Example"
      },
      {
        "level": 2,
        "text": "Anonymous to known identification"
      },
      {
        "level": 2,
        "text": "Cross-device identification"
      },
      {
        "level": 2,
        "text": "Cross-app identification"
      },
      {
        "level": 2,
        "text": "Conclusion"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/guides/intro-impl/",
    "title": " Segment for Developers | Segment Documentation",
    "content": "Home / Guides / Segment for Developers Segment for Developers On this page What does Segment do? Types of Segment messages Anatomy of a Segment message Message schemas, Blocks, and Specs Sources and Destinations Connection modes Planning your Segment implementation How do I test if it’s working? How do I filter my data? Troubleshooting Segment Terraform Provider This guide explains all you need to know to get started with your Segment implementation, and directs you to more resources depending on your specific needs. If you haven’t already, you should read the detailed explanation of Segment on the previous page! Segment University: Segment in Action See a quick example of Segment working on an ecommerce website. (Must be logged in to access.) What does Segment do? Segment sends messages about activities in your mobile apps, websites or servers, receives those messages, and translates and forwards the message content to Destination tools. It also can send the contents of those messages to a bulk storage destination for archiving. In more complicated implementations, Segment can serve as a wrapper to trigger messages directly to other APIs, and can inspect, correct, classify and block the message contents. Types of Segment messages Segment’s libraries generate and send messages to our tracking API in JSON format, and provide a standard structure for the basic API calls. We also provide recommended JSON structure (also known as a schema, or ‘Spec’) that helps keep the most important parts of your data consistent, while allowing great flexibility in what other information you collect and where. There are six calls in the basic tracking API, which answer specific questions: Identify : Who is the user? Track : What are they doing? Page : What web page are they on? Screen : What app screen are they on? Group : What account or organization are they part of? Alias : What was their past identity? Among these calls, you can think of Identify, Group, and Alias as similar types of calls, all to do with updating our understanding of the user who is triggering Segment messages. You can think of these calls as adding information to, or updating an object record in a database. Objects are described using “traits”, which you can collect as part of your calls. The other three, Track, Page, and Screen, can be considered as increasingly specific types of events. Events can occur multiple times, but generate separate records which append to a list, instead of being updated over time. A Track call is the most basic type of call, and can represent any type of event. Page and Screen are similar and are triggered by a user viewing a page or screen, however Page calls can come from both web and mobile-web views, while Screen calls only occur on mobile devices. Because of the difference in platform, the context information collected is very different between the two types of calls. Tip ! Segment recommends that you always use the Page and Screen calls when recording a page-view, rather than creating a “Page Viewed” event, because the Page/Screen calls automatically collect much better context information. Anatomy of a Segment message The most basic Segment message requires only a userID or anonymousID ; all other fields are optional to allow for maximum flexibility. However, a normal Segment message has three main parts: the common fields , the “context” object , and the properties (if it’s an event) or traits (if it’s an object). The common fields include information specific to how the call was generated, like the timestamp and library name and version. The fields in the context object are usually generated by the library, and include information about the environment in which the call was generated: page path, user agent, OS, locale settings, etc. The properties and traits are optional and are where you customize the information you want to collect for your implementation. Another common part of a Segment message is the integrations object , which you can use to explicitly filter which destinations the call is forwarded to. However this object is optional, and is often omitted in favor of non-code based filtering options. Message schemas, Blocks, and Specs The Segment “Specs” provide recommended message schemas - the information we recommend that you collect - for each type of call. These are recommendations not requirements, but if you follow these schema guidelines the Segment servers can more easily identify parts of your messages, and translate them to downstream tools. In addition to the recommended message schemas, Segment also provides “blocks”: recommendations on what information to collect and how to format it, for different industries and use cases. These are recommendations only, but by collecting all of the information in these blocks, you can ensure that common tools used in that use-case have the information they need to function. A third section of the Spec is the “industry specs” which provide recommendations that include an explicit translation or mapping in the Segment servers, to best power the downstream Destinations commonly used in these industries. Sources and Destinations When you start out, you create a Workspace, which serves as a container for all of your Sources and Destinations. Segment has Sources and Destinations . Sources send data into Segment, while Destinations receive data from Segment. Segment has five types of sources: Web (Analytics.js), Mobile, Server, and Cloud App, plus a fifth type: User-created Source Functions . Web, Mobile, and Server sources send first-party data from your digital properties. Cloud-app sources send data about your users from your connected web apps, for example a ticketing system such as Zendesk , a payments system such as Stripe , or a marketing tool like Braze . Connection modes Segment has several types of sources, and many destinations can accept data from all of them. However, some are only compatible with specific source types (for example, web only, or server only). To find out which source types a specific destination can accept data from, check the documentation for that destination for a “Supported Sources and Connection Modes” section. Segment’s web source (Analytics.js), and native client-side libraries (iOS, Android, React-native) allow you to choose how you send data to Segment from your website or app. There are two ways to send data: Cloud-mode : The sources send data directly to the Segment servers, which then translate it for each connected downstream destination, and send it on. Translation is done on the Segment servers, keeping your page size, method count, and load time small. Healthcare and Life Sciences (HLS) customers can encrypt data flowing into their destinations HLS customers with a HIPAA eligible workspace can encrypt data in fields marked as Yellow in the Privacy Portal before they flow into an event stream, cloud-mode destination. To learn more about data encryption, see the HIPAA Eligible Segment documentation Device-mode : You include additional code on your website or mobile app which allows Segment to use the data you collect on the device to make calls directly to the destination tool’s API, without sending it to the Segment servers first . (You still send your data to the Segment servers, but this occurs asynchronously.) This is also called wrapping or bundling , and it might be required when the source has to be loaded on the page to work, or loaded directly on the device to function correctly. When you use Analytics.js, you can change the device-mode destinations that a specific source sends from within the Segment web app, without touching any code. If you use Server source libraries, they only send data directly to Segment in Cloud-mode. Server library implementations operate in the server backend, and can't load additional destination SDKs. To learn more about connection modes and when you should use each, see the details in the Destinations docs . Planning your Segment implementation The journey of a thousand miles begins, ideally, with a plan. Regardless of if you’re a new company just implementing analytics for the first time, or a multi–national corporation modernizing your analytics stack, it’s a great idea to start with a Tracking Plan . For new implementations, this can be as simple as a document where you write down these four things for each item you track: What am I tracking? (What is the event name or type?) Why am I tracking it? (What questions does this data answer?) For whom am I tracking it? (Who owns this question, tool, or business area?) Where (which destination tools) do I want to send this data to? If you’re a large or long-established organization and you’re replacing existing tools, you’ll want to spend more time on this to maintain analytic parity and continuity of tooling. We highly recommend reading up on tracking plans and schemas for Protocols , our tool for managing and sharing tracking plans and enforcing schemas. Regardless of your organization’s size or age, you’ll want to take an inventory of the destination tools you’ll be using with Segment, and make a list of the connection modes each one accepts. This makes it easier to check off when you’ve implemented each one, so you’re not missing anything. How do I test if it’s working? There are several ways to check if your data is flowing. One is the Debugger tab in each Source in the Segment web app, where you can see data coming from a source into Segment. Another is the Event Delivery tool which shows which data is arriving at specific destinations. For monitoring purposes, you’ll also see alerts in the Workspace Health tool if your sources or destinations produce repeated errors. How do I filter my data? There are several different ways to ensure that you can collect your data once, but filter it out of specific destinations. See Filtering Data for a list of the available methods and descriptions. Troubleshooting If you’re seeing errors thrown by your destinations, you might have an implementation issue. See the Integration Error Codes list or contact our Success engineering team for help. Have suggestions for things to add to this guide? Drop us a line . Segment Terraform Provider Segment has a Terraform provider, powered by the Public API, that you can use to manage Segment resources, automate cloud deployments, and change control. Take a look at the Segment provider documentation on Terraform to see what’s supported. This page was last modified: 09 Apr 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page What does Segment do? Types of Segment messages Anatomy of a Segment message Message schemas, Blocks, and Specs Sources and Destinations Connection modes Planning your Segment implementation How do I test if it’s working? How do I filter my data? Troubleshooting Segment Terraform Provider Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Segment for Developers"
      },
      {
        "level": 2,
        "text": "What does Segment do?"
      },
      {
        "level": 2,
        "text": "Types of Segment messages"
      },
      {
        "level": 2,
        "text": "Anatomy of a Segment message"
      },
      {
        "level": 2,
        "text": "Message schemas, Blocks, and Specs"
      },
      {
        "level": 2,
        "text": "Sources and Destinations"
      },
      {
        "level": 2,
        "text": "Connection modes"
      },
      {
        "level": 2,
        "text": "Planning your Segment implementation"
      },
      {
        "level": 2,
        "text": "How do I test if it’s working?"
      },
      {
        "level": 2,
        "text": "How do I filter my data?"
      },
      {
        "level": 2,
        "text": "Troubleshooting"
      },
      {
        "level": 2,
        "text": "Segment Terraform Provider"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/identity-resolution/identity-resolution-settings/",
    "title": " Identity Resolution Settings | Segment Documentation",
    "content": "Home / Unify / Identity resolution / Identity Resolution Settings Identity Resolution Settings Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Configure Identity Graph rules ExternalIDs Flat matching logic Identity Resolution rules The steps in this guide pertain to spaces created before September 27th, 2020. For spaces created after September 27th, 2020, please refer to the Identity Resolution Onboarding docs. Configure Identity Graph rules Before you connect a source to Unify, Segment recommends that you first review the default Identity settings and configure custom rules as needed. Segment applies configuration updates to all new data flowing through the space after you save your changes. As a result, if this is your first time setting up your Identity Graph, Segment recommends that you get started with a Dev space in the Space Setup docs. Workspace owners and users with the Identity Admin role can edit the Identity Resolution table. Changing Identity Resolution rules Making a space’s Identity Resolution rules less restrictive by changing the limit shouldn’t cause any issues to existing or future profiles. However, making a space’s rules more restrictive might have an impact existing profiles that don’t adhere to the new rules (for example, decreasing an identifier’s limit or changing the priority of identifiers). Segment recommends to get started with a Dev space in the Space Setup docs, test the rules with the expected data, and then create an identical Production space with those rules. Document any changes to a space’s Identity Resolution rules, and don’t update rules to be more restrictive after profiles already exist outside the bounds of those new rules. ExternalIDs Segment creates and merges user profiles based on externalIDs used as identifiers. You can view these externalIDs in the Identities tab of a User Profile in the Profile explorer. By default, Segment promotes the following traits and IDs in track and identify calls to externalIDs: External ID Type Message Location in Track or Identify Call user_id userId email traits.email or context.traits.email android.id context.device.id when context.device.type = ‘android’ android.idfa context.device.advertisingId when context.device.type = ‘android’ AND context.device.adTrackingEnabled = true android.push_token context.device.token when context.device.type = ‘android’ anonymous_id anonymousId braze_id context.Braze.braze_id or context.Braze.braze_id when Braze is connected as a destination cross_domain_id cross_domain_id when XID is enabled for the workspace ga_client_id context.integrations[‘Google Analytics’].clientId when explicitly captured by users ios.id context.device.id when context.device.type = ‘ios’ ios.idfa context.device.advertisingId when context.device.type = ‘ios’ AND context.device.adTrackingEnabled = true ios.push_token context.device.token when context.device.type = ‘ios’ You’ll notice that these identifiers have the Default label next to it under Identifier Type . To create your own custom externalID, click Add Identifier , and add the following: Identifier Name Value Limit Blocked Values These custom identifiers must be sent in the custom externalIds field in the context object of any call to the Segment API. The four fields below are all required: Key Value id value of the externalID type name of externalID type ( app_id , ecommerce_id , shopify_id , and more) collection users if a user-level identifier or accounts if a group-level identifier encoding none The following example payload adds a custom phone externalID type: analytics . track ( ' Subscription Upgraded ' , { plan : ' Pro ' , mrr : 99.99 }, { externalIds : [ { id : ' 123-456-7890 ' , type : ' phone ' , collection : ' users ' , encoding : ' none ' } ] }) Segment recommends that you add custom externalIDs to the Identity Resolution table before events containing this identifier flow through the space. Once an event with a new type of externalID flows into the space, the externalID is automatically added to the table if it wasn’t manually added. When the externalID is automatically added, it defaults to the preset priority and limit, as explained below. Flat matching logic When a new event flows into Unify, Segment looks for profiles that match any of the identifiers on the event. Based on the existence of a match, one of three actions can occur: 1: Create a new profile When there are no pre-existing profiles that have matching identifiers to the event, Segment creates a new user profile. 2: Add to existing profile When there is one profile that matches all identifiers in an event, Segment attempts to map the traits, identifiers, and events on the call to that existing profile. If there’s an excess of any identifier on the final profile, Segment defers to the Identity Resolution rules outlined below. 3: Merge existing profiles When there are multiple profiles that match the identifiers in an event, Segment checks the Identity Resolution rules outlined below, and attempts to merge profiles. One common example of a use-case that can cause inaccurate merges is the Shared iPad setup. For example, many companies now have iPads available in-store for customers to register for an account or submit order information. If different users submit information on the same device, there will now be multiple events sent with the same deviceID. Without Identity Resolution rules in place, Segment might see all these different users merged into the same user profile based on this common identifier. Segment’s three Identity Resolution rules allow Identity Admins to block incorrect values from causing incorrect merges, to set the maximum number of values allowed per externalID, and to customize the priority of these externalIDs. Identity Resolution rules The following rules exist to increase the likelihood that identities are resolved correctly. Blocked values Segment recommends that you proactively block certain values from being used as identifiers. While these values will remain in the payload on the event itself, they are not promoted to the externalID object Segment uses to determine user profiles. This is important when developers have a hard-coded value for fields like user_id during QA or development that then erroneously makes it production. This can cause hundreds of profiles to merge incorrectly and can have costly consequences when these spaces are already feeding data into a production email marketing tool or push notification tool downstream. In the past, certain default values cause large amounts of profiles to merge incorrectly. Segment suggests that for every externalID, customers opt into automatically blocking the following suggested values: Value Type Zeroes and Dashes (^[0-]*$) Pattern (REGEX) -1 Exact Match null Exact Match anonymous Exact Match Before sending data through, Segment also recommends adding any default hard-coded values that your team uses during the development process, such as void or abc123 . Limit Identity Admins can specify the total number of values allowed per identifier type on a profile during a certain period. For example, in the image below, the anonymous_id field has a limit of 5 Weekly . This will vary depending on how companies define a user today. In most cases, companies rely on user_id to distinguish user profiles and Segment defaults to the following configurations: Identifier Limit user_id 1 all other identifiers 5 Specific cases may deviate from this default. For example, a case where a user can have more than one user_id but one email, like when shopify_id and an internal UUID define a user. In this case, an example configuration may be: Identifier Limit email 1 user_id 2 all other identifiers 5 When you choose the limit on an identifier, ask the following questions about each of the identifiers you send to Segment: Is it an immutable ID? An immutable ID, such as user_id , should have 1 ever per user profile. Is it a constantly changing ID? A constantly changing ID, such as anonymous_id or ga_client_id , should have a short sliding window, such as 5 weekly or 5 monthly , depending on how often your application automatically logs out the user. Is it an ID that updates on a yearly basis? Most customers will have around five emails or devices at any one time, but can update these over time. For identifiers like email , android.id , or ios.id , Segment recommends a longer limit like 5 annually . Priority Segment considers the priority of an identifier once that identifier exceeds the limit on the final profile. For example, consider a Unify space with the following Identity Resolution configurations: Identifier Limit Priority user_id 1 1 email 5 2 anonymous_id 5 3 A profile already exists with user_id abc123 and email jane@example1.com . A new event comes in with new user_id abc456 but the same email jane@example1.com . If this event maps to this profile, the resulting profile would then contain two user_id values and one email . Given that user_id has a limit of 1, this exceeds the limit of that identifier. As a result, Segment checks the priority of the user_id identifier. Because email and user_id are the two identifiers on the event and email ranks lower than user_id , Segment demotes email as an identifier on the incoming event and tries again. At this point, the event searches for any profiles that match just the identifier user_id abc456 . Now there are no existing profiles with this identifier, so Segment creates a new profile with user_id abc456 . By default, Segment explicitly orders user_id and email as rank 1 and 2 , respectively. All other identifiers are in alphabetical order beginning from rank 3 . This means that if the identifiers sent with events flowing into profiles are user_id, email, anonymous_id, and ga_client_id, the rank would be as follows: Identifier Priority user_id 1 email 2 anonymous_id 3 ga_client_id 4 If a new android.id identifier appeared without first giving it explicit order, the order would automatically reshuffle to: Identifier Priority user_id 1 email 2 android.id 3 anonymous_id 4 ga_client_id 5 If you require an explicit order for all identifiers, configure this in the Identity Resolution settings page before sending in events. When choosing the priority of your identifier, ask the following questions about each of the identifiers you send to Segment: Is it an immutable ID? Give immutable IDs, such as user_id, highest priority. Are they unique IDs? Give Unique IDs such as email higher priority than possibly shared identifiers like android.id or ios.id. Does it temporarily identify a user? Identifiers such as anonymous_id, ios.idfa, and ga_client_id are constantly updated or expired for a user. Generally speaking, rank these lower than identifiers that permanently identify a user. This page was last modified: 07 Nov 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Configure Identity Graph rules ExternalIDs Flat matching logic Identity Resolution rules Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Identity Resolution Settings"
      },
      {
        "level": 2,
        "text": "Configure Identity Graph rules"
      },
      {
        "level": 2,
        "text": "ExternalIDs"
      },
      {
        "level": 2,
        "text": "Flat matching logic"
      },
      {
        "level": 2,
        "text": "Identity Resolution rules"
      },
      {
        "level": 3,
        "text": "Blocked values"
      },
      {
        "level": 3,
        "text": "Limit"
      },
      {
        "level": 3,
        "text": "Priority"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/connections/spec/common/",
    "title": " Spec: Common Fields | Segment Documentation",
    "content": "Home / Connections / Spec / Spec: Common Fields Spec: Common Fields On this page Structure Context Context fields automatically collected Integrations Timestamps FAQ In the Segment Spec all the API calls have a common structure, and a few common fields. However, not all destinations accept all fields included in the Spec. Not sure which fields a destination accepts? Refer to the destination’s documentation page, or check out the open-source destination code on GitHub . Segment University: The Segment Methods Check out our high-level overview of these APIs in Segment University. (Must be logged in to access.) Structure Every API call has the same core structure and fields. These fields describe user identity, timestamping, and mechanical aides like API version. Here’s an example of these common fields in raw JSON: { \"anonymousId\" : \"507f191e810c19729de860ea\" , \"context\" : { \"active\" : true , \"app\" : { \"name\" : \"InitechGlobal\" , \"version\" : \"545\" , \"build\" : \"3.0.1.545\" , \"namespace\" : \"com.production.segment\" }, \"campaign\" : { \"name\" : \"TPS Innovation Newsletter\" , \"source\" : \"Newsletter\" , \"medium\" : \"email\" , \"term\" : \"tps reports\" , \"content\" : \"image link\" }, \"device\" : { \"id\" : \"B5372DB0-C21E-11E4-8DFC-AA07A5B093DB\" , \"advertisingId\" : \"7A3CBEA0-BDF5-11E4-8DFC-AA07A5B093DB\" , \"adTrackingEnabled\" : true , \"manufacturer\" : \"Apple\" , \"model\" : \"iPhone7,2\" , \"name\" : \"maguro\" , \"type\" : \"ios\" , \"token\" : \"ff15bc0c20c4aa6cd50854ff165fd265c838e5405bfeb9571066395b8c9da449\" }, \"ip\" : \"8.8.8.8\" , \"library\" : { \"name\" : \"analytics.js\" , \"version\" : \"2.11.1\" }, \"locale\" : \"en-US\" , \"network\" : { \"bluetooth\" : false , \"carrier\" : \"T-Mobile US\" , \"cellular\" : true , \"wifi\" : false }, \"os\" : { \"name\" : \"iPhone OS\" , \"version\" : \"8.1.3\" }, \"page\" : { \"path\" : \"/academy/\" , \"referrer\" : \"\" , \"search\" : \"\" , \"title\" : \"Analytics Academy\" , \"url\" : \"https://segment.com/academy/\" }, \"referrer\" : { \"id\" : \"ABCD582CDEFFFF01919\" , \"type\" : \"dataxu\" }, \"screen\" : { \"width\" : 320 , \"height\" : 568 , \"density\" : 2 }, \"groupId\" : \"12345\" , \"timezone\" : \"Europe/Amsterdam\" , \"userAgent\" : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\" , \"userAgentData\" : { \"brands\" : [ { \"brand\" : \"Google Chrome\" , \"version\" : \"113\" }, { \"brand\" : \"Chromium\" , \"version\" : \"113\" }, { \"brand\" : \"Not-A.Brand\" , \"version\" : \"24\" } ], \"mobile\" : false , \"platform\" : \"macOS\" } }, \"integrations\" : { \"All\" : true , \"Mixpanel\" : false , \"Salesforce\" : false }, \"event\" : \"Report Submitted\" , \"messageId\" : \"022bb90c-bbac-11e4-8dfc-aa07a5b093db\" , \"receivedAt\" : \"2015-12-10T04:08:31.909Z\" , \"sentAt\" : \"2015-12-10T04:08:31.581Z\" , \"timestamp\" : \"2015-12-10T04:08:31.905Z\" , \"type\" : \"track\" , \"userId\" : \"97980cfea0067\" , \"version\" : 2 } In more detail these common fields for every API call are: Field Type Description anonymousId required; optional if userID is set instead String A pseudo-unique substitute for a User ID, for cases when you don’t have an absolutely unique identifier. A userId or an anonymousId is required.\n\n  See the Identities docs for more details. context optional Object Dictionary of extra information that provides useful context about a message, but is not directly related to the API call like ip address or locale See the Context field docs for more details. integrations optional Object Dictionary of destinations to either enable or disable\n\n  See the Destinations field docs for more details. messageId implicit String Automatically collected by Segment, a unique identifier for each message that lets you find an individual message across the API. This field is limited to 100 characters. receivedAt implicit Date Automatically set by Segment, the timestamp of when a message is received by Segment\n\n  It is an ISO-8601 date string.  See the Timestamps fields docs for more detail. sentAt optional Date Timestamp of when a message is sent to Segment, used for clock skew correction\n\n    It is set automatically by the Segment tracking libraries. It is an ISO-8601 date string. See the Timestamps fields docs for more detail. timestamp optional Date Timestamp when the message itself took place, defaulted to the current time by the Segment Tracking API, as a ISO-8601 format date string.\n\n  If the event just happened, leave it out and we’ll use the server’s time. If you’re importing data from the past, make sure you to provide a timestamp .See the Timestamps fields docs for more detail. type implicit String Type of message, corresponding to the API method: 'identify' , 'group' , 'track' , 'page' , 'screen' or 'alias' . userId required; optional if anonymousID is set instead String Unique identifier for the user in your database.\n\n  A userId or an anonymousId is required.\n\n  See the Identities docs for more details. version implicit Number Version of the Tracking API that received the message, automatically set by Segment. Beyond this common structure, each API call adds a few specialized top-level fields. Context Context is a dictionary of extra information that provides useful context about a datapoint, for example the user’s ip address or locale . You should only use Context fields for their intended meaning. Field Type Description active Boolean Whether a user is active. This is usually used to flag an .identify() call to just update the traits but not “last seen.” app Object dictionary of information about the current application, containing name , version , and build . This is collected automatically from the mobile libraries when possible. campaign Object Dictionary of information about the campaign that resulted in the API call, containing name , source , medium , term , content , and any other custom UTM parameter. This maps directly to the common UTM campaign parameters. device Object Dictionary of information about the device, containing id , advertisingId , manufacturer , model , name , type , and version . Note: If you collect information about iOS devices, note that the model value set by Apple might not exactly correspond to an iPhone model number. For example, an iPhone 15 Pro Max has a model value of iPhone16,2 . ip String Current user’s IP address. library Object Dictionary of information about the library making the requests to the API, containing name and version . locale String Locale string for the current user, for example en-US . network Object Dictionary of information about the current network connection, containing bluetooth , carrier , cellular , and wifi . If the context.network.cellular and context.network.wifi fields are empty, then the user is offline. os Object Dictionary of information about the operating system, containing name and version . page Object Dictionary of information about the current page in the browser, containing path , referrer , search , title and url . This is automatically collected by Analytics.js . referrer Object Dictionary of information about the way the user was referred to the website or app, containing type , name , url , and link . screen Object Dictionary of information about the device’s screen, containing density , height , and width . timezone String Timezones are sent as tzdata strings to add user timezone information which might be stripped from the timestamp, for example America/New_York . groupId String Group / Account ID. This is useful in B2B use cases where you need to attribute your non-group calls to a company or account. It is relied on by several Customer Success and CRM tools. traits Object Dictionary of traits of the current user. This is useful in cases where you need to track an event, but also associate information from a previous Identify call. You should fill this object the same way you would fill traits in an identify call . userAgent String User agent of the device making the request. userAgentData Object The user agent data of the device making the request. This always contains brands , mobile , platform , and may contain bitness , model , platformVersion , uaFullVersion , fullVersionList , wow64 , if requested and available. This populates if the Client Hints API is available on the browser. This may contain more information than is available in the userAgent in some cases. channel String where the request originated from: server, browser or mobile Context fields automatically collected Below is a chart that shows you which context variables are populated automatically by the iOS, Android, and analytics.js libraries. Other libraries only collect context.library , any other context variables must be sent manually. Context Field Analytics.js Analytics-ios Analytics-android app.name ✅ ✅ app.version ✅ ✅ app.build ✅ ✅ campaign.name ✅ campaign.source ✅ campaign.medium ✅ campaign.term ✅ campaign.content ✅ device.type ✅ ✅ device.id ✅ ✅ device.advertisingId ✅ ✅ device.adTrackingEnabled ✅ ✅ device.manufacturer ✅ ✅ device.model ✅ ✅ device.name ✅ ✅ library.name ✅ ✅ ✅ library.version ✅ ✅ ✅ ip* ✅ ✅ ✅ locale ✅ ✅ ✅ network.bluetooth ✅ network.carrier ✅ ✅ network.cellular ✅ ✅ network.wifi ✅ ✅ os.name ✅ ✅ os.version ✅ ✅ page.path ✅ page.referrer ✅ page.search ✅ page.title ✅ page.url ✅ screen.density ✅ screen.height ✅ ✅ screen.width ✅ ✅ traits ✅ ✅ userAgent ✅ ✅ userAgentData* ✅ timezone ✅ ✅ ✅ IP Address isn’t collected by Segment’s libraries, but is instead filled in by Segment’s servers when it receives a message for client side events only . IPv6 Segment doesn’t support automatically collecting IPv6 addresses. The Android library collects screen.density with this method . userAgentData is only collected if the Client Hints API is available on the browser. Segment doesn’t collect or append to the context of subsequent calls in the new mobile libraries (Swift, Kotlin, and React Native). To pass the context variables which are not automatically collected by Segment’s libraries, you must manually include them in the event payload. The following code shows how to pass groupId as the context field of Analytics.js’s .track() event: analytics . track ( \" Report Submitted \" , {}, { context : { groupId : \" 1234 \" } }); To add fields to the context object in the new mobile libraries, you must utilize a custom plugin. Documentation for creating plugins for each library can be found here: React Native Swift Kotlin Integrations A dictionary of destination names that the message should be sent to. 'All' is a special key that applies when no key for a specific destination is found. Integrations defaults to the following: { All : true , Salesforce : false , } This is because Salesforce has strict limits on API calls. Sending data to the rest of Segment’s destinations is opt-out so if you don’t specify the destination as false in this object, it will be sent to rest of the destinations that can accept it. Timestamps Every API call has four timestamps, originalTimestamp , timestamp , sentAt , and receivedAt. They’re used for very different purposes. All timestamps are ISO-8601 date strings, and are in the UTC timezone. To see the user’s timezone information, check the timezone field that’s automatically collected by client-side libraries . You must use ISO-8601 date strings that include timezones when you use timestamps with Engage . If you send custom traits without a timezone, Segment doesn’t save the timestamp value. Timestamp overview Timestamp Calculated Description originalTimestamp Time on the client device when call was invoked OR The timestamp value manually passed in through server-side libraries. Used by Segment to calculate timestamp . Note: originalTimestamp is not useful for analysis since it’s not always trustworthy as it can be easily adjusted and affected by clock skew. sentAt Time on client device when call was sent. OR sentAt value manually passed in. Used by Segment to calculate timestamp . Note: sentAt is not useful for analysis since it’s not always trustworthy as it can be easily adjusted and affected by clock skew. receivedAt Time on Segment server clock when call was received Used by Segment to calculate timestamp , and used as sort key in Warehouses. Note: For max query speed, receivedAt is the recommended timestamp for analysis when chronology does not matter as chronology is not ensured. timestamp Calculated by Segment to correct client-device clock skew using the following formula: receivedAt - ( sentAt - originalTimestamp ) Used by Segment to send to downstream destinations, and used for historical replays. Note: Recommended timestamp for analysis when chronology does matter. originalTimestamp The originalTimestamp tells you when call was invoked on the client device or the value of timestamp that you manually passed in. Note: The originalTimestamp timestamp is not useful for any analysis since it’s not always trustworthy as it can be easily adjusted and affected by clock skew. sentAt The sentAt timestamp specifies the clock time for the client’s device when the network request was made to the Segment API. For libraries and systems that send batched requests, there can be a long gap between a datapoint’s timestamp and sentAt . Combined with receivedAt , Segment uses sentAt to correct the original timestamp in situations where a user’s device clock cannot be trusted (mobile phones and browsers). The sentAt and receivedAt timestamps are assumed to occur at the same time (maximum a few hundred milliseconds), and therefore the difference is the user’s device clock skew, which can be applied back to correct the timestamp . Note: The sentAt timestamp is not useful for any analysis since it’s tainted by user’s clock skew. Segment now adds `sentAt` to a payload when the batch is complete and initially tried to the Segment API for the Swift, Kotlin, and C# mobile libraries This update changes the value of the Segment-calculated timestamp to align closer with the receivedAt value rather than the originalTimestamp value. For most users who are online when events are sent, this does not significantly impact their data. However, if your application utilizes an offline mode where events are queued up for any period of time, the timestamp value for those users now more closely reflects when Segment received the events rather than the time they occurred on the users’ devices. receivedAt The receivedAt timestamp is added to incoming messages as soon as they hit the API. It’s used in combination with sentAt to correct clock skew, and also to aid with debugging libraries and systems that deliver events in batches. The receivedAt timestamp is most important as the sort key in Segment’s Warehouses product. Use this for max query speed when retrieving data from your Warehouse. Note: Chronological order of events is not ensured with receivedAt . timestamp The timestamp timestamp specifies when the data point occurred, corrected for client-device clock skew. This is the timestamp that is passed to downstream destinations and used for historical replays. It is important to use this timestamp for importing historical data to the API. If you are using the Segment server Source libraries, or passing calls directly to the HTTP API endpoint, you can manually set the timestamp field. This change updates the originalTimestamp field of the Segment event. If you use a Segment Source in device mode, the library generates timestamp and you cannot manually set one directly in the call payload. Segment calculates timestamp as timestamp = receivedAt - (sentAt - originalTimeStamp) . For client-side tracking it’s possible for the client to spoof the originalTimeStamp , which may result in a calculated timestamp value set in the future. FAQ Why Are Events Received with Timestamps Set in the Past or Future? If you’re using one of Segment’s client-side libraries, please note that several factors can cause timestamp discrepancies in your event data. Overriding Timestamp Value: When a manual timestamp is set in the payload with a date in the past, it can cause events to appear as if they were sent earlier than they actually were. Analytics.js Source with Retries Enabled: The Retries feature supports offline traffic by queuing events in Analytics.js. These events are sent or retried later when an internet connection is available, keeping the original timestamp intact. Mobile App Backgrounded or Closed: If a user closes the app, events may be queued within the app. These queued events won’t be sent until the app is re-opened, potentially in the future, leading to timestamp discrepancies. Inaccurate Browser/Device Clock Settings: Timestamps can be incorrect if the client’s device time is inaccurate, as the originalTimestamp relies on the client device’s clock, which can be manually adjusted. Traffic from Internet Bots: Internet Bots can sometimes send requests with unusual timestamps, either intentionally or due to incorrect settings, leading to discrepancies. This page was last modified: 30 Oct 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Structure Context Context fields automatically collected Integrations Timestamps FAQ Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Spec: Common Fields"
      },
      {
        "level": 2,
        "text": "Structure"
      },
      {
        "level": 2,
        "text": "Context"
      },
      {
        "level": 2,
        "text": "Context fields automatically collected"
      },
      {
        "level": 2,
        "text": "Integrations"
      },
      {
        "level": 2,
        "text": "Timestamps"
      },
      {
        "level": 3,
        "text": "Timestamp overview"
      },
      {
        "level": 3,
        "text": "originalTimestamp"
      },
      {
        "level": 3,
        "text": "sentAt"
      },
      {
        "level": 3,
        "text": "receivedAt"
      },
      {
        "level": 3,
        "text": "timestamp"
      },
      {
        "level": 2,
        "text": "FAQ"
      },
      {
        "level": 3,
        "text": "Why Are Events Received with Timestamps Set in the Past or Future?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/segment-app/iam/audit-trail/",
    "title": " Audit Trail | Segment Documentation",
    "content": "Home / Segment app / Iam / Audit Trail Audit Trail Free x Team x Business ✓ Add-on x ? Audit Trail is only available in Business plan workspaces. See the available plans , or contact Support . On this page Audit Trail events Filtering events Audit forwarding Frequently asked questions The Audit Trail allows you to view the last 90 days of user and system activity, filter activity for specific actions or actors, and export your data to an event streams source or CSV file. For any requests exceeding the 90-day timeframe, contact Segment Support for assistance. Viewing the Audit Trail requires Workspace Owner permissions You must have the Workspace Owner role to view the Audit Trail page. For more information about roles and permissions within Segment, see the Roles documentation . To view the Audit Trail: From the Segment app, select Settings . From the Settings tab, select Admin . Audit Trail events The Audit Trail returns information about the following Segment product areas: Sources Functions Warehouses Destinations Storage Consent Management Tracking Plans Destination Filters Transformations Audiences Computed Traits Engage Warehouse Sources Profiles Sync Spaces Users Journeys Broadcasts Workspace To view a list of all events Segment surfaces in the Audit Trail, open the Audit Trail, click Filters , and select the Events dropdown. Filtering events Use the Filters dropdown to refine your search results and filter by actions or actors to see who made changes on specific resources in the app. Actors include both logged-in users and access tokens. Audit forwarding You can forward events in your workspace to an event streams source to set up real-time alerts and quickly revert changes (like a user unintentionally disabling a warehouse) that could cause unwanted downstream effects. Segment recommends creating a dedicated source for Audit Trail events Segment recommends forwarding all events to an instance of the HTTP API source.  Segment passes all forwarded events through its entire processing pipeline. This ensures that Tracking Plans, Filters, and other features work with the audit events, and also ensures you can send those events to multiple downstream destinations. To forward Audit Trail events to an event streams source: Navigate to Settings > Workspace Settings > Audit Forwarding . Select or create an event streams source to which you’ll forward workspace events. Toggle the setting to On and click Save Changes . When you forward audit events to a source, Segment passes those events through its entire processing pipeline. This ensures that tracking plans, filters, and other features work with the audit events, and also ensures you can send those events to multiple downstream destinations. Frequently asked questions Engage Why am I getting alerts about an audience/computed trait sync failure, but when I look at the specific audience/computed trait it shows a successful sync? An audience/computed trait Run or a Sync may fail on its first attempt, but Engage will retry up to 5 times before considering it a hard failure and display on that audience/compute trait’s Overview page. As long as the runs/syncs within the specific Audience’s Overview page say they are successful, then these can be safely ignored. How things work internally: Segment Engage scheduler fetches audiences/traits from compute service and then handles the logic of generating tasks. These compute/sync tasks get scheduled and executed by another worker. Essentially, these tasks are a list of steps to be executed. Each task has a series of steps that are marked as complete by saving a timestamp for the completion. If the worker is disrupted, it picks up at the latest step, which has no completed_at timestamp. In some cases, the step may fail or the entire task may fail (for example, due to timeout or the worker disruption as there are many moving parts). In either case, these failures will be retried. These tasks are a part of internal Segment process, and there are systems in place to retry failed tasks. In most cases, it is not necessary to track these failures, as long as there are no actual computation or sync failures. The Audit Trail logic, however, is configured to notify you about every task failure, even if it then later succeeds. If you would like to avoid receiving the notifications for transient failures, reach out to support to request enabling a setting to reduce the number of notifications your workspace receives. This page was last modified: 06 Aug 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Audit Trail events Filtering events Audit forwarding Frequently asked questions Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Audit Trail"
      },
      {
        "level": 2,
        "text": "Audit Trail events"
      },
      {
        "level": 2,
        "text": "Filtering events"
      },
      {
        "level": 2,
        "text": "Audit forwarding"
      },
      {
        "level": 2,
        "text": "Frequently asked questions"
      },
      {
        "level": 3,
        "text": "Engage"
      },
      {
        "level": 3,
        "text": "Why am I getting alerts about an audience/computed trait sync failure, but when I look at the specific audience/computed trait it shows a successful sync?"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/engage/journeys/",
    "title": " Journeys Overview | Segment Documentation",
    "content": "Home / Engage / Journeys Overview Journeys Overview Free x Team x Business ✓ + Engage Foundations ✓ ? Engage Foundations requires a Business tier account and includes Unify. See the available plans , or contact Support . On this page Get started Send data to your destinations Best practices and FAQ Journeys use cases Journeys glossary Journeys Product Limits Journeys, a feature of Engage, provides a way for marketers to personalize experiences through planning how and when to engage customers with the right campaigns and messages. Journeys enable you to define steps in a user’s journey based on event behavior and traits. You can build Journeys from your tracking events, traits, computed traits, or audiences. At each step of a journey, you can send your list of users to any Engage-compatible destination. Get started Start with the visual builder to define entrance criteria, build out conditional branching logic, then focus messaging to drive conversion. Repeat purchase campaigns, trial conversions, and onboarding flows are great examples to get started from. For more information, see Build a Journey . Send data to your destinations Connect destinations to your Journey to send events or user lists when users reach the corresponding step in the Journey. For more information, see Send Journeys data to a Destination . Best practices and FAQ For information about best practices for getting started with Journeys, and to view frequently asked questions about Journeys, see Best Practices and FAQ . Journeys use cases See Examples Journeys Use Cases for examples of ways you can use Journeys in your marketing workflow. Journeys glossary For a list of key terms related to Journeys, see Journeys Key Terms . Journeys Product Limits For information about Product Limits related to Journeys, see Product Limits - Journeys . This page was last modified: 27 Sep 2022 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Get started Send data to your destinations Best practices and FAQ Journeys use cases Journeys glossary Journeys Product Limits Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Journeys Overview"
      },
      {
        "level": 2,
        "text": "Get started"
      },
      {
        "level": 2,
        "text": "Send data to your destinations"
      },
      {
        "level": 2,
        "text": "Best practices and FAQ"
      },
      {
        "level": 2,
        "text": "Journeys use cases"
      },
      {
        "level": 2,
        "text": "Journeys glossary"
      },
      {
        "level": 2,
        "text": "Journeys Product Limits"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/identity-resolution/externalids/",
    "title": " Identity Resolution ExternalIDs | Segment Documentation",
    "content": "Home / Unify / Identity resolution / Identity Resolution ExternalIDs Identity Resolution ExternalIDs Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Default externalIDs Custom externalIDs Viewing promoted externalIDs Example The steps in this guide pertain to spaces created before September 27th, 2020. For spaces created after September 27th, 2020, please refer to the Identity onboarding guide . Default externalIDs The Identity Graph creates or merges profiles based on externalIDs. ExternalIDs will become the identities attached to a user profile in the Profile explorer. Navigate to Unify > Profile explorer to view identities attached to a profile, along with custom traits, event history, and more. Segment automatically promotes the following traits and IDs in track and identify calls to externalIDs: External ID Type Message Location in Track or Identify Call user_id userId email traits.email, context.traits.email or properties.email android.id context.device.id when context.device.type = ‘android’ android.idfa context.device.advertisingId when context.device.type = ‘android’ AND context.device.adTrackingEnabled = true android.push_token context.device.token when context.device.type = ‘android’ anonymous_id anonymousId ga_client_id context.integrations[‘Google Analytics’].clientId when explicitly captured by users ios.id context.device.id when context.device.type = ‘ios’ ios.idfa context.device.advertisingId when context.device.type = ‘ios’ ios.push_token context.device.token when context.device.type = ‘ios’ The Google clientID(ga_clientid) is a unique value created for each browser-device pair and will exist for 2 years if the cookie is not cleared. The analytics.reset() call should be triggered from Segment end when the user logs off. This call will clear the cookies and local Storage created by Segment. It doesn’t clear data from other integrated tools. So on the next login, the user will be assigned with a new unique anonymous_id, but the same ga_clientid will remain if this cookie is not cleared. Hence, the profiles with different anonymous_id but with same ga_clientid will get merged. Custom externalIDs Unify resolves identity for any other externalIDs that you bind to users - such as a phone number or any custom identifier that you support. As long as you’ve configured custom externalIDs, such as phone , in your Space’s Identity Resolution rules, you can include it with the context.externalIds array, the properties object, or the context.traits object. As seen in the example below, you can send custom externalIds in the context object of any call to Segment’s API. The four fields below (id, type, collection, encoding) are all required: Key Value id value of the externalID type name of externalID type ( app_id , ecommerce_id , shopify_id , and more) collection users if a user-level identifier or accounts if a group-level identifier encoding none As an example: analytics . track ( ' Subscription Upgraded ' , { plan : ' Pro ' , mrr : 99.99 }, { externalIds : [ { id : ' 123-456-7890 ' , type : ' phone ' , collection : ' users ' , encoding : ' none ' } ] }) Additionally, adding phone with the properties object gets picked up by Unify and applied as an externalID: analytics . track ( ' Subscription Upgraded ' , { plan : ' Pro ' , mrr : 99.99 , phone : ' 123-456-7890 ' }) You can also include phone using the context.traits object and Unify adds it as an externalID to the profile. analytics . track ( ' Subscription Upgraded ' , { plan : ' Pro ' , mrr : 99.99 }, { traits : { phone_number : ' 123-456-7890 ' }}) Unify creates a user (user_id: use_123 )  with the custom externalID (phone: 123-456-7890 ). Query the user’s phone record by using the externalID (phone: 123-456-7890 ), or update the profile with that externalID going forward. (Note: externalIDs must be lower-case.) Viewing promoted externalIDs Users can view which externalIDs are promoted on each event by viewing the raw payload on Events in the User Profile in the “external_ids” object. For example, the following user had anonymous_id and user_id promoted as identifiers from the Course Clicked track call: Example For example, a new anonymous user visits your Pricing page: analytics . page ( ' Pricing ' , { anonymousId : ' anon_123 ' title : ' Acme Pricing ' , url : ' https://acme.com/pricing ' , referrer : ' https://google.com/ ' }); At this point, the Identity Graph will create a new user with external id (anonymous_id: anon_123 ) and a persistent and globally unique segment_id, in this case: use_4paotyretuj4Ta2bEYQ0vKOq1e7 . Any new events received with the same external id (anonymous_id: anon_123 ) are appended to same user use_4paotyretuj4Ta2bEYQ0vKOq1e7 . Next, the user goes to a sign up form and signs up: analytics . track ( ' User Signup ' , { userId : ' use_123 ' , anonymousId : ' anon_123 ' }); At this point, the Identity Graph associates external ID (user_id: use_123 ) with the same user use_4paotyretuj4Ta2bEYQ0vKOq1e7 . This page was last modified: 07 Nov 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Default externalIDs Custom externalIDs Viewing promoted externalIDs Example Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Identity Resolution ExternalIDs"
      },
      {
        "level": 2,
        "text": "Default externalIDs"
      },
      {
        "level": 2,
        "text": "Custom externalIDs"
      },
      {
        "level": 2,
        "text": "Viewing promoted externalIDs"
      },
      {
        "level": 2,
        "text": "Example"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  },
  {
    "url": "https://segment.com/docs/unify/data-graph//",
    "title": " Data Graph | Segment Documentation",
    "content": "Home / Unify / Data Graph Data Graph Free x Team x Business ✓ + Unify ✓ ? Unify requires a Business tier account and is included with Engage. See the available plans , or contact Support . On this page Prerequisites Step 1: Set up Data Graph permissions in your data warehouse Step 2: Connect your warehouse to the Data Graph Step 3: Build your Data Graph Step 4: Validate your Data Graph Edit and manage your Data Graph The Data Graph acts as a semantic layer that allows businesses to define relationships between various entity datasets in the warehouse — such as accounts, subscriptions, households, and products — with the Segment Profile. It makes these relational datasets easily accessible to business teams for targeted and personalized customer engagements. Linked Audiences : Empowers marketers to effortlessly create targeted audiences by combining behavioral data from the Segment Profile and warehouse entity data within a self-serve, no-code interface. This tool accelerates audience creation, enabling precise targeting, enhanced customer personalization, and optimized marketing spend without the need for constant data team support. Linked Events : Allows data teams to enrich event streams in real time using datasets from data warehouses or lakes, and send these enriched events to any destination. Linked Events is available for both Destination Actions and Functions. Prerequisites To use the Data Graph, you’ll need the following: A supported data warehouse with the appropriate Data Graph permissions Workspace Owner or Unify Read-only/Admin and Entities Admin permissions For Linked Audiences, set up Profiles Sync in a Unify space with ready-to-use data models and tables in your warehouse. When setting up selective sync, Segment recommends the following settings: Under Profile materialized tables , select all the tables ( user_identifier , user_traits , profile_merges ) for faster and more cost-efficient Linked Audiences computations in your data warehouse. Under Track event tables , select Sync all Track Call Tables to enable filtering on event history for Linked Audiences conditions. Step 1: Set up Data Graph permissions in your data warehouse Data Graph, Reverse ETL, and Profiles Sync require different warehouse permissions. Data Graph currently only supports workspaces in the United States. To get started with the Data Graph, set up the required permissions in your warehouse. Segment supports the following: Linked Audiences: BigQuery , Databricks , and Snowflake Linked Events: BigQuery , Databricks , Redshift , and Snowflake To track the data sent to Segment on previous syncs, Segment uses Reverse ETL infrastructure to store diffs in tables within a dedicated schema called _segment_reverse_etl in your data warehouse. You can choose which database or project in your warehouse this data lives in. Step 2: Connect your warehouse to the Data Graph To connect your warehouse to the Data Graph: Navigate to Unify > Data Graph . This should be a Unify space with Profiles Sync already set up. Click Add warehouse . Select your warehouse type. Enter your warehouse credentials. Test your connection, then click Save . Step 3: Build your Data Graph The Data Graph is a semantic layer that represents a subset of relevant business data that marketers and business stakeholders can use for audience targeting and personalization in downstream tools. Use the configuration language spec and the following features to build your Data Graph: Use the Warehouse access tab to view the warehouse tables you’ve granted Segment access to Begin typing to autopopulate the configuration spec within the editor, as well as to autocomplete your warehouse schema Validate your Data Graph using the Preview tab Key steps to build your Data Graph First, define your entities. An entity corresponds to a table in your warehouse. Segment flexibly supports tables, views and materialized views. Then, define the profile block. This is a special class of entity that represents Segment Profiles, which corresponds to the Profiles Sync tables and models. For Linked Audiences, this allows marketers to filter on profile traits, event history, and so on. Finally, define how your datasets are related to each other. The Data Graph preserves these relationships and carries this rich context to the destinations to unlock personalization. Defining Relationships Similar to the concept of cardinality in data modeling , the Data Graph supports 3 types of relationships: Profile-to-entity relationship: This is a relationship between your entity table and the Segment Profiles tables, and is the first level of relationship. 1:many relationship: For example, an account can have many carts , but each cart can only be associated with one account . many:many relationship: For example, a user can have many carts , and each cart can have many products . However, these products can also belong to many carts . The Data Graph currently supports 6 levels of depth (or nodes) starting from the profile. For example, relating the profile to the accounts table to the carts table is 3 levels of depth. There are no limits on the width of your Data Graph or the number of entities. Relationships are nested under the profile. Refer to the example below. Data Graph Example data_graph { version = \" v1.0.0 \" # Define entities entity \" account-entity \" { name = \" account \" table_ref = \" PRODUCTION.CUST.ACCOUNT \" primary_key = \" ID \" } entity \" product-entity \" { name = \" product \" table_ref = \" PRODUCTION.PROD.PRODUCT_SKUS \" primary_key = \" SKU \" } entity \" cart-entity \" { name = \" cart \" table_ref = \" PRODUCTION.CUST.CART \" primary_key = \" ID \" enrichment_enabled = true } entity \" household-entity \" { name = \" household \" table_ref = \" PRODUCTION.CUST.HOUSEHOLD \" primary_key = \" HOUSEHOLD_ID \" } entity \" subscription-entity \" { name = \" subscription \" table_ref = \" PRODUCTION.CUST.SUBSCRIPTION \" primary_key = \" SUB_ID \" } # Define the profile entity, which corresponds to Segment Profiles tables synced via Profiles Sync # Recommend setting up Profiles Sync materialized views to optimize warehouse compute costs profile { profile_folder = \" PRODUCTION.SEGMENT \" type = \" segment:materialized \" # First branch - relate accounts table to the profile # This is a unique type of relationship between an entity and the profile block relationship \" user-accounts \" { name = \" Premium Accounts \" related_entity = \" account-entity \" # Join the profile entity with an identifier (e.g. email) on the related entity table # Option to replace with the traits block below to join with a profile trait on the entity table instead external_id { type = \" email \" join_key = \" EMAIL_ID \" } # Define 1:many relationship between accounts and carts # e.g. an account can be associated with many carts relationship \" user-carts \" { name = \" Shopping Carts \" related_entity = \" cart-entity \" join_on = \" account-entity.ID = cart-entity.ACCOUNT_ID \" # Define many:many relationship between carts and products # e.g. there can be multiple carts, and each cart can be associated with multiple products relationship \" products \" { name = \" Purchased Products \" related_entity = \" product-entity \" junction_table { primary_key = \" ID \" table_ref = \" PRODUCTION.CUSTOMER.CART_PRODUCT \" left_join_on = \" cart-entity.ID = CART_ID \" right_join_on = \" PRODUCT_ID = product-entity.SKU \" } } } } # Second branch - relate households table to the profile by joining with an external ID block relationship \" user-households \" { name = \" Households \" related_entity = \" household-entity \" external_id { type = \" email \" join_key = \" EMAIL_ID \" } # Define 1:many relationship between households and subscriptions # e.g. a household can be associated with multiple subscriptions relationship \" user-subscriptions \" { name = \" Subscriptions \" related_entity = \" subscription-entity \" join_on = \" household-entity.SUB_ID = subscription-entity.HOUSEHOLD_ID \" } } 3a: Define entities The first step in creating a Data Graph is to define your entities. An entity corresponds to a table in the warehouse. Parameters Definition entity An immutable slug for the entity, and will be treated as a delete if you make changes. The slug must be in all lowercase, and supports dashes or underscores (e.g account-entity or account_entity ). name A label displayed throughout your Segment space for Linked Events, Linked Audiences, etc. This name can be modified at any time. table_ref Defines the fully qualified table reference: [database name].[schema name].[table name] . Segment flexibly supports tables, views and materialized views. primary_key The unique identifier for the given table. Must be a column with unique values per row. (If applicable) enrichment_enabled = true Add this if you plan to reference the entity table for Linked Events use cases. Example: data_graph { entity \" account-entity \" { name = \" account \" table_ref = \" PRODUCTION.CUST.ACCOUNT \" primary_key = \" ID \" } entity \" cart-entity \" { name = \" cart \" table_ref = \" PRODUCTION.CUST.CART \" primary_key = \" ID \" enrichment_enabled = true } } 3b: Define the profile Segments recommends that you select materialized views under the Profiles Selective Sync settings to optimize warehouse compute costs. Next, define the profile. This is a special class of entity that represents Segment Profiles, which corresponds to the Profiles Sync tables and models. For Linked Audiences, this allows marketers to filter on profile traits, event history, etc. There can only be one profile for a Data Graph. Parameters Definition profile_folder Define the fully qualified path of the folder or schema location for the profile tables. type Identify the materialization method of the profile tables defined in your Profiles Sync configuration under Selective Sync settings : segment:unmaterialized or segment:materialized . Example: data_graph { # Define entities ... # Define the profile entity, which corresponds to Segment Profiles tables synced via Profiles Sync # Recommend setting up Profiles Sync materialized views to optimize warehouse compute costs profile { profile_folder = \" PRODUCTION.SEGMENT \" type = \" segment:materialized \" } } 3c: Define relationships Now define your relationships between your entities. Similar to the concept of cardinality in data modeling , the Data Graph supports 3 types of relationships below. All relationship types require you to define the relationship slug, name, and related entity. Each type of relationship has unique join on conditions. Profile-to-entity relationship : This is a relationship between your entity table and the Segment Profiles tables, and is the first level of relationship. 1:many relationship : For example, an account can have many carts , but each cart can only be associated with one account . many:many relationship : For example, a user can have many carts , and each cart can have many products . However, these products can also belong to many carts . Define profile-to-entity relationship This is the first level of relationships and a unique type of relationship between the Segment profile entity and a related entity. Parameters Definition relationship An immutable slug for the relationship, and will be treated as a delete if you make changes. The slug must be in all lowercase, and supports dashes or underscores (e.g. user-account or user_account ) name A label displayed throughout your Segment space for Linked Events, Linked Audiences, etc. This name can be modified at any time related_entity References your already defined entity To define a profile-to-entity relationship, reference your entity table and depending on your table columns, choose to join on one of the following: Option 1 (Most common) - Join on an external ID: Use the external_id block to join the profile entity with an entity table using external IDs from your Unify ID resolution settings. Typically these identifiers are user_id , email , or phone depending on the column in the entity table that you want to join with. type : Represents the external ID type ( email , phone , user_id ) in your id-res settings. Depending on if you are using materialized or unmaterialized profiles, these correspond to different columns in your Profiles Sync warehouse tables: Materialized (Recommended): This corresponds to the type column in your Profiles Sync user_identifiers table. Unmaterialized : This corresponds to the external_id_type column in your Profiles Sync external_id_mapping_updates table. join_key : This is the column on the entity table that you are matching to the external identifier. Option 2 - Join on a profile trait: Use the traits block to join the profile entity with an entity table using Profile Traits . name : Represents a trait name in your Unify profiles. Depending on if you are using materialized or unmaterialized profiles, these correspond to different columns in your Profiles Sync warehouse tables: Materialized (Recommended): The trait name corresponds to a unique value of the name column in your Profiles Sync user_traits table. Unmaterialized : This corresponds to a column in the Profile Sync profile_trait_updates table. join_key : This is the column on the entity table that you are matching to the trait. Example: data_graph { entity \" account-entity \" { name = \" account \" table_ref = \" PRODUCTION.CUST.ACCOUNT \" primary_key = \" ID \" } # Define additional entities... # Note: Relationships are nested profile { profile_folder = \" PRODUCTION.SEGMENT \" type = \" segment:materialized \" # Relate accounts table to the profile relationship \" user-accounts \" { name = \" Premium Accounts \" related_entity = \" account-entity \" # Option 1: Join the profile entity with an identifier (e.g. email) on the related entity table external_id { type = \" email \" join_key = \" EMAIL_ID \" } # Option 2: Join the profile entity with a profile trait on the related entity table trait { name = \" cust_id \" join_key = \" ID \" } } } } Define a 1:many relationship For 1:many relationships, define the join on between the two entity tables using the spec below. Parameters Definition relationship An immutable slug for the relationship, and will be treated as a delete if you make changes. The slug must be in all lowercase, and supports dashes or underscores (e.g. user-account or user_account ) name A label displayed throughout your Segment space for Linked Events, Linked Audiences, and so on. This name can be modified at any time related_entity References your already defined entity join_on Defines relationship between the two entity tables [lefty entity slug].[column name] = [right entity slug].[column name] . Note that since you’re referencing the entity slug for the join on, you do not need to define the full table reference Example: data_graph { entity \" cart-entity \" { name = \" cart \" table_ref = \" PRODUCTION.CUST.CART \" primary_key = \" ID \" } # Define additional entities... # Note: Relationships are nested profile { profile_folder = \" PRODUCTION.SEGMENT \" type = \" segment:materialized \" relationship \" user-accounts \" { ... # Define 1:many relationship between accounts and carts relationship \" user-carts \" { name = \" Shopping Carts \" related_entity = \" carts-entity \" join_on = \" account-entity.ID = cart-entity.ACCOUNT_ID \" } } } } Define many:many relationship For many:many relationships, define the join on between the two entity tables with the junction_table . Attributes from a junction table are not referenceable via the Linked Audience builder. If a marketer would like to filter upon a column on the junction table, you must define the junction as an entity and define a relationship. Parameters Definition relationship An immutable slug for the relationship, and will be treated as a delete if you make changes. The slug must be in all lowercase, and supports dashes or underscores (e.g. user-account or user_account ) name A label displayed throughout your Segment space for Linked Events, Linked Audiences, and so on. This name can be modified at any time related_entity References your already defined entity Junction table spec Parameters Definition table_ref Defines the fully qualified table reference to the join table: [database name].[schema name].[table name] . Segment flexibly supports tables, views and materialized views primary_key The unique identifier for the given table. Must be a column with unique values per row left_join_on Define the relationship between the left entity table and the junction table: [left entity slug].[column name] = [junction table column name] . Note that schema and table are implied within the junction table column name, so you do not need to define it again right_join_on Define the relationship between the junction table and the right entity table: [junction table column name] = [right entity slug].[column name] . Note that schema and table are implied within the junction table column name, so you do not need to define it again Example: data_graph { # Define entities # Note: Relationships are nested profile { # Define profile relationship \" user-accounts \" { ... relationship \" user-carts \" { ... # Define many:many relationship between carts and products relationship \" products \" { name = \" Purchased Products \" related_entity = \" product-entity \" junction_table { table_ref = \" PRODUCTION.CUSTOMER.CART_PRODUCT \" primary_key = \" ID \" left_join_on = \" cart-entity.ID = CART_ID \" right_join_on = \" PRODUCT_ID = product-entity.SKU \" } } } } } } Step 4: Validate your Data Graph You can validate your Data Graph using the preview, then click Save. After you’ve set up your Data Graph, your partner teams can start leveraging these datasets with with Linked Events and Linked Audiences . Edit and manage your Data Graph To edit your Data Graph: Navigate to Unify > Data Graph . Select the Overview tab, and click Edit Data Graph . View Data Graph data consumers A data consumer refers to a Segment feature like Linked Events and Linked Audiences that are referencing datasets, such as entities and/or relationships, from the Data Graph. You can view a list of data consumers in two places: Under Unify > Data Graph , click the Data consumers tab Under Unify > Data Graph > Overview or the Data Graph editor > Preview , click into a node on the Data Graph preview and a side sheet will pop up with the list of data consumers for the respective relationship Understand changes that may cause breaking and potential breaking changes Upon editing and saving changes to your Data Graph, a modal will pop up to warn of breaking and/or potential breaking changes to your data consumers. You must acknowledge and click Confirm and save in order to proceed. Definite breaking change : Occurs when deleting an entity or relationship that is being referenced by a data consumer. Data consumers affected by breaking changes will fail on the next run. Note: The entity and relationship slug are immutable and treated as a delete if you make changes. You can modify the label. Potential breaking change : Some changes such as updating the entity table_ref or primary_key , may lead to errors with data consumers. If there’s a breaking change, the data consumer will fail on the next run. Unaffected data consumers will continue to work. Detect warehouse breaking changes Segment has a service that regularly scans and monitors the Data Graph for changes that occur in your warehouse that may break components of the Data Graph, like when the table being referenced by the Data Graph gets deleted from your warehouse or when the primary key column no longer exists. An alert banner will be displayed on the Data Graph landing page. The banner will be removed once the issues are resolved in your warehouse and/or the Data Graph. You will also have the option to trigger a manual sync of your warehouse schema. Receive alerts for warehouse breaking changes Configure alerts for breaking changes to receive notifications over Slack, email, or in-app notification whenever Segment detects a breaking change in your warehouse. To configure alerts for breaking changes: Open your workspace and navigate to Settings > User Preferences > Activity Notifications . Select Data Graph . Select one of the following notification methods: Email : Select this to receive notifications at either the email address associated with your account or another email address that you enter into this field. Slack : Select this and enter a Slack webhook URL and channel name to send alerts to a channel in your Slack workspace. In-app : Select this to receive notifications in the Segment app. To view your notifications, select the bell next to your user icon in the Segment app. Click Save . This page was last modified: 05 Dec 2024 Need support? Questions? Problems? Need more info? Contact Segment Support for assistance! Visit our Support page Help improve these docs! Edit this page Request docs change Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback! Get started with Segment Segment is the easiest way to integrate your websites & mobile apps data to over 300 analytics and growth tools. Request Demo or Create free account Edit this page Request docs change On this page Prerequisites Step 1: Set up Data Graph permissions in your data warehouse Step 2: Connect your warehouse to the Data Graph Step 3: Build your Data Graph Step 4: Validate your Data Graph Edit and manage your Data Graph Was this page helpful? Yes No Thanks for your feedback! Can we improve this doc? Send us feedback!",
    "headings": [
      {
        "level": 1,
        "text": "Data Graph"
      },
      {
        "level": 2,
        "text": "Prerequisites"
      },
      {
        "level": 2,
        "text": "Step 1: Set up Data Graph permissions in your data warehouse"
      },
      {
        "level": 2,
        "text": "Step 2: Connect your warehouse to the Data Graph"
      },
      {
        "level": 2,
        "text": "Step 3: Build your Data Graph"
      },
      {
        "level": 3,
        "text": "Key steps to build your Data Graph"
      },
      {
        "level": 3,
        "text": "3a: Define entities"
      },
      {
        "level": 3,
        "text": "3b: Define the profile"
      },
      {
        "level": 3,
        "text": "3c: Define relationships"
      },
      {
        "level": 2,
        "text": "Step 4: Validate your Data Graph"
      },
      {
        "level": 2,
        "text": "Edit and manage your Data Graph"
      },
      {
        "level": 3,
        "text": "View Data Graph data consumers"
      },
      {
        "level": 3,
        "text": "Understand changes that may cause breaking and potential breaking changes"
      },
      {
        "level": 3,
        "text": "Detect warehouse breaking changes"
      },
      {
        "level": 3,
        "text": "Receive alerts for warehouse breaking changes"
      },
      {
        "level": 3,
        "text": "Need support?"
      },
      {
        "level": 3,
        "text": "Help improve these docs!"
      },
      {
        "level": 3,
        "text": "Was this page helpful?"
      },
      {
        "level": 3,
        "text": "Get started with Segment"
      }
    ]
  }
]